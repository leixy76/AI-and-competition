{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11a620b1",
   "metadata": {},
   "source": [
    "## Created by <a href=\"https://github.com/yunsuxiaozi\">yunsuxiaozi</a> 2024/6/18"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5750a2f",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f75552e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd#导入csv文件的库\n",
    "import numpy as np#进行矩阵运算的库\n",
    "from tqdm import tqdm#加载进度条的库\n",
    "import warnings#避免一些可以忽略的报错\n",
    "warnings.filterwarnings('ignore')#filterwarnings()方法是用于设置警告过滤器的方法，它可以控制警告信息的输出方式和级别。\n",
    "\n",
    "import random#提供了一些用于生成随机数的函数\n",
    "#设置随机种子,保证模型可以复现\n",
    "def seed_everything(seed):\n",
    "    np.random.seed(seed)#numpy的随机种子\n",
    "    random.seed(seed)#python内置的随机种子\n",
    "seed_everything(seed=2024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3aba0b",
   "metadata": {},
   "source": [
    "### read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30477f64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X.shape:(37549, 2, 180)\n",
      "train_y.shape:(37549,)\n",
      "test_X.shape:(1155, 2, 180)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label\n",
       "0   0      0\n",
       "1   1      0\n",
       "2   2      0\n",
       "3   3      0\n",
       "4   4      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#样本数量*(血氧和心率)*采样为3hz,180个数据总共60秒\n",
    "path=\"\"#这里需要改成你自己的文件路径\n",
    "train_X=np.load(path+\"训练集\\\\train_x.npy\")\n",
    "print(f\"train_X.shape:{train_X.shape}\")\n",
    "train_y=np.load(path+\"训练集\\\\train_y.npy\")\n",
    "print(f\"train_y.shape:{train_y.shape}\")\n",
    "test_X=np.load(path+\"测试集A\\\\test_x_A.npy\")\n",
    "print(f\"test_X.shape:{test_X.shape}\")\n",
    "submission=pd.read_csv(path+\"测试集A\\\\submit_example_A.csv\")\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1baa04dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(total_index):12341\n",
      "label:0,4600\n",
      "label:1,3221\n",
      "label:2,4520\n"
     ]
    }
   ],
   "source": [
    "#为了和测试集保持一致,并测试模型对测试集的效果,label=0的样本随机选择4600个,比label1和label2稍微多一点。\n",
    "zero_index=list(np.where(train_y==0)[0])\n",
    "np.random.shuffle(zero_index)\n",
    "total_index=zero_index[:4600]+list(np.where(train_y!=0)[0])\n",
    "train_X=train_X[total_index]\n",
    "train_y=train_y[total_index]\n",
    "print(f\"len(total_index):{len(total_index)}\")\n",
    "for i in range(3):\n",
    "    print(f\"label:{i},{np.sum(train_y==i)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b866eac5",
   "metadata": {},
   "source": [
    "### Feature engineer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72e9873e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 12341/12341 [05:21<00:00, 38.40it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1155/1155 [00:29<00:00, 39.74it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_血氧/秒</th>\n",
       "      <th>mean_心率/秒</th>\n",
       "      <th>mean_血氧/秒_shift1</th>\n",
       "      <th>mean_血氧/秒_gap1</th>\n",
       "      <th>mean_血氧/秒_shift2</th>\n",
       "      <th>mean_血氧/秒_gap2</th>\n",
       "      <th>mean_血氧/秒_shift4</th>\n",
       "      <th>mean_血氧/秒_gap4</th>\n",
       "      <th>mean_血氧/秒_shift8</th>\n",
       "      <th>mean_血氧/秒_gap8</th>\n",
       "      <th>...</th>\n",
       "      <th>median_心率/秒_gap2</th>\n",
       "      <th>median_心率/秒_shift4</th>\n",
       "      <th>median_心率/秒_gap4</th>\n",
       "      <th>median_心率/秒_shift8</th>\n",
       "      <th>median_心率/秒_gap8</th>\n",
       "      <th>median_心率/秒_shift16</th>\n",
       "      <th>median_心率/秒_gap16</th>\n",
       "      <th>median_心率/秒_shift30</th>\n",
       "      <th>median_心率/秒_gap30</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>92.683333</td>\n",
       "      <td>49.383333</td>\n",
       "      <td>92.627119</td>\n",
       "      <td>0.084746</td>\n",
       "      <td>92.586207</td>\n",
       "      <td>0.155172</td>\n",
       "      <td>92.500000</td>\n",
       "      <td>0.303571</td>\n",
       "      <td>92.346154</td>\n",
       "      <td>0.519231</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>49.833333</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96.000000</td>\n",
       "      <td>63.011111</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>62.166667</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>95.000000</td>\n",
       "      <td>57.700000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>58.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>58.333333</td>\n",
       "      <td>-1.166667</td>\n",
       "      <td>58.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>95.400000</td>\n",
       "      <td>53.250000</td>\n",
       "      <td>95.406780</td>\n",
       "      <td>0.050847</td>\n",
       "      <td>95.413793</td>\n",
       "      <td>0.091954</td>\n",
       "      <td>95.428571</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>95.461538</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>52.833333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>52.666667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>52.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>97.183333</td>\n",
       "      <td>70.033333</td>\n",
       "      <td>97.169492</td>\n",
       "      <td>0.033898</td>\n",
       "      <td>97.155172</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>97.125000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>97.038462</td>\n",
       "      <td>0.326923</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>68.833333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>67.500000</td>\n",
       "      <td>4.833333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 131 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_血氧/秒  mean_心率/秒  mean_血氧/秒_shift1  mean_血氧/秒_gap1  mean_血氧/秒_shift2  \\\n",
       "0  92.683333  49.383333         92.627119        0.084746         92.586207   \n",
       "1  96.000000  63.011111         96.000000        0.000000         96.000000   \n",
       "2  95.000000  57.700000         95.000000        0.000000         95.000000   \n",
       "3  95.400000  53.250000         95.406780        0.050847         95.413793   \n",
       "4  97.183333  70.033333         97.169492        0.033898         97.155172   \n",
       "\n",
       "   mean_血氧/秒_gap2  mean_血氧/秒_shift4  mean_血氧/秒_gap4  mean_血氧/秒_shift8  \\\n",
       "0        0.155172         92.500000        0.303571         92.346154   \n",
       "1        0.000000         96.000000        0.000000         96.000000   \n",
       "2        0.000000         95.000000        0.000000         95.000000   \n",
       "3        0.091954         95.428571        0.125000         95.461538   \n",
       "4        0.068966         97.125000        0.142857         97.038462   \n",
       "\n",
       "   mean_血氧/秒_gap8  ...  median_心率/秒_gap2  median_心率/秒_shift4  \\\n",
       "0        0.519231  ...          0.000000           50.000000   \n",
       "1        0.000000  ...          0.000000           63.000000   \n",
       "2        0.000000  ...          0.000000           58.000000   \n",
       "3        0.083333  ...          0.000000           52.833333   \n",
       "4        0.326923  ...         -0.166667           70.000000   \n",
       "\n",
       "   median_心率/秒_gap4  median_心率/秒_shift8  median_心率/秒_gap8  \\\n",
       "0          0.000000           50.666667          0.666667   \n",
       "1          0.000000           63.000000          0.666667   \n",
       "2          0.000000           58.166667          0.000000   \n",
       "3          0.000000           52.666667          0.166667   \n",
       "4         -0.333333           70.000000          0.000000   \n",
       "\n",
       "   median_心率/秒_shift16  median_心率/秒_gap16  median_心率/秒_shift30  \\\n",
       "0            49.833333           1.500000            48.000000   \n",
       "1            63.000000           1.000000            62.166667   \n",
       "2            58.333333          -1.166667            58.166667   \n",
       "3            52.333333           0.666667            52.000000   \n",
       "4            68.833333           1.000000            67.500000   \n",
       "\n",
       "   median_心率/秒_gap30  label  \n",
       "0           3.833333      0  \n",
       "1           1.500000      0  \n",
       "2           0.000000      0  \n",
       "3           2.166667      0  \n",
       "4           4.833333      0  \n",
       "\n",
       "[5 rows x 131 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#通过train_X和test_X来构造特征\n",
    "def get_feats(data):\n",
    "    feats=[]\n",
    "    for i in tqdm(range(len(data))):\n",
    "        #data[i]是2*180 血氧和心率\n",
    "        data[i][0],data[i][1]\n",
    "        #由于是3hz,所以按照秒来提取特征\n",
    "        origin_feats=pd.DataFrame({\"血氧/秒\":data[i][0].reshape(-1,3).mean(axis=1),\"心率/秒\":data[i][1].reshape(-1,3).mean(axis=1)})\n",
    "        for col in ['血氧/秒',\"心率/秒\"]:\n",
    "            for gap in [1,2,4,8,16,30]:\n",
    "                origin_feats[f\"{col}_shift{gap}\"]=origin_feats[col].shift(gap)\n",
    "                origin_feats[f\"{col}_gap{gap}\"]=origin_feats[col]-origin_feats[f\"{col}_shift{gap}\"]\n",
    "        feats.append(list(origin_feats.mean(axis=0).values)+list(origin_feats.max(axis=0).values)+\\\n",
    "                     list(origin_feats.min(axis=0).values)+list(origin_feats.std(axis=0).values)+\\\n",
    "                     list(origin_feats.median(axis=0).values)\n",
    "                    )\n",
    "    feats=pd.DataFrame(feats)\n",
    "    origin_cols=list(origin_feats.columns)\n",
    "    feats.columns=[f\"mean_{col}\"for col in origin_cols]+[f\"max_{col}\"for col in origin_cols]\\\n",
    "                   +[f\"min_{col}\"for col in origin_cols]+[f\"std_{col}\"for col in origin_cols]+\\\n",
    "                   [f\"median_{col}\"for col in origin_cols]\n",
    "    return feats\n",
    "train_feats=get_feats(train_X)\n",
    "train_feats['label']=train_y\n",
    "test_feats=get_feats(test_X)\n",
    "train_feats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc6dfa8",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3d013da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name lgb,fold:0\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.704301\n",
      "[200]\tvalid_0's multi_logloss: 0.686409\n",
      "[300]\tvalid_0's multi_logloss: 0.678001\n",
      "[400]\tvalid_0's multi_logloss: 0.673091\n",
      "[500]\tvalid_0's multi_logloss: 0.668517\n",
      "[600]\tvalid_0's multi_logloss: 0.665939\n",
      "[700]\tvalid_0's multi_logloss: 0.663869\n",
      "[800]\tvalid_0's multi_logloss: 0.662662\n",
      "[900]\tvalid_0's multi_logloss: 0.661497\n",
      "[1000]\tvalid_0's multi_logloss: 0.661133\n",
      "[1100]\tvalid_0's multi_logloss: 0.660287\n",
      "[1200]\tvalid_0's multi_logloss: 0.659414\n",
      "[1300]\tvalid_0's multi_logloss: 0.659015\n",
      "[1400]\tvalid_0's multi_logloss: 0.659026\n",
      "[1500]\tvalid_0's multi_logloss: 0.658531\n",
      "[1600]\tvalid_0's multi_logloss: 0.658765\n",
      "Early stopping, best iteration is:\n",
      "[1508]\tvalid_0's multi_logloss: 0.658277\n",
      "name lgb,fold:1\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.72123\n",
      "[200]\tvalid_0's multi_logloss: 0.702182\n",
      "[300]\tvalid_0's multi_logloss: 0.691399\n",
      "[400]\tvalid_0's multi_logloss: 0.683737\n",
      "[500]\tvalid_0's multi_logloss: 0.679033\n",
      "[600]\tvalid_0's multi_logloss: 0.674514\n",
      "[700]\tvalid_0's multi_logloss: 0.671347\n",
      "[800]\tvalid_0's multi_logloss: 0.667995\n",
      "[900]\tvalid_0's multi_logloss: 0.665037\n",
      "[1000]\tvalid_0's multi_logloss: 0.663276\n",
      "[1100]\tvalid_0's multi_logloss: 0.661124\n",
      "[1200]\tvalid_0's multi_logloss: 0.660037\n",
      "[1300]\tvalid_0's multi_logloss: 0.658191\n",
      "[1400]\tvalid_0's multi_logloss: 0.657359\n",
      "[1500]\tvalid_0's multi_logloss: 0.655476\n",
      "[1600]\tvalid_0's multi_logloss: 0.654549\n",
      "[1700]\tvalid_0's multi_logloss: 0.653858\n",
      "[1800]\tvalid_0's multi_logloss: 0.653394\n",
      "[1900]\tvalid_0's multi_logloss: 0.652039\n",
      "[2000]\tvalid_0's multi_logloss: 0.651329\n",
      "[2100]\tvalid_0's multi_logloss: 0.650739\n",
      "[2200]\tvalid_0's multi_logloss: 0.650396\n",
      "[2300]\tvalid_0's multi_logloss: 0.650024\n",
      "[2400]\tvalid_0's multi_logloss: 0.649636\n",
      "Early stopping, best iteration is:\n",
      "[2348]\tvalid_0's multi_logloss: 0.649555\n",
      "name lgb,fold:2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.698135\n",
      "[200]\tvalid_0's multi_logloss: 0.678384\n",
      "[300]\tvalid_0's multi_logloss: 0.670606\n",
      "[400]\tvalid_0's multi_logloss: 0.665394\n",
      "[500]\tvalid_0's multi_logloss: 0.661957\n",
      "[600]\tvalid_0's multi_logloss: 0.659473\n",
      "[700]\tvalid_0's multi_logloss: 0.656928\n",
      "[800]\tvalid_0's multi_logloss: 0.654736\n",
      "[900]\tvalid_0's multi_logloss: 0.653377\n",
      "[1000]\tvalid_0's multi_logloss: 0.651986\n",
      "[1100]\tvalid_0's multi_logloss: 0.651069\n",
      "[1200]\tvalid_0's multi_logloss: 0.650048\n",
      "[1300]\tvalid_0's multi_logloss: 0.649362\n",
      "[1400]\tvalid_0's multi_logloss: 0.648406\n",
      "[1500]\tvalid_0's multi_logloss: 0.647711\n",
      "[1600]\tvalid_0's multi_logloss: 0.647653\n",
      "[1700]\tvalid_0's multi_logloss: 0.647045\n",
      "[1800]\tvalid_0's multi_logloss: 0.646682\n",
      "Early stopping, best iteration is:\n",
      "[1776]\tvalid_0's multi_logloss: 0.646413\n",
      "name lgb,fold:3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.745294\n",
      "[200]\tvalid_0's multi_logloss: 0.723932\n",
      "[300]\tvalid_0's multi_logloss: 0.714146\n",
      "[400]\tvalid_0's multi_logloss: 0.705944\n",
      "[500]\tvalid_0's multi_logloss: 0.699579\n",
      "[600]\tvalid_0's multi_logloss: 0.694506\n",
      "[700]\tvalid_0's multi_logloss: 0.691188\n",
      "[800]\tvalid_0's multi_logloss: 0.688066\n",
      "[900]\tvalid_0's multi_logloss: 0.686456\n",
      "[1000]\tvalid_0's multi_logloss: 0.684809\n",
      "[1100]\tvalid_0's multi_logloss: 0.683228\n",
      "[1200]\tvalid_0's multi_logloss: 0.681649\n",
      "[1300]\tvalid_0's multi_logloss: 0.680944\n",
      "[1400]\tvalid_0's multi_logloss: 0.680139\n",
      "[1500]\tvalid_0's multi_logloss: 0.680116\n",
      "[1600]\tvalid_0's multi_logloss: 0.67919\n",
      "[1700]\tvalid_0's multi_logloss: 0.678082\n",
      "[1800]\tvalid_0's multi_logloss: 0.677826\n",
      "Early stopping, best iteration is:\n",
      "[1765]\tvalid_0's multi_logloss: 0.677701\n",
      "name lgb,fold:4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.721801\n",
      "[200]\tvalid_0's multi_logloss: 0.702028\n",
      "[300]\tvalid_0's multi_logloss: 0.691476\n",
      "[400]\tvalid_0's multi_logloss: 0.683836\n",
      "[500]\tvalid_0's multi_logloss: 0.678426\n",
      "[600]\tvalid_0's multi_logloss: 0.67422\n",
      "[700]\tvalid_0's multi_logloss: 0.670884\n",
      "[800]\tvalid_0's multi_logloss: 0.667678\n",
      "[900]\tvalid_0's multi_logloss: 0.665105\n",
      "[1000]\tvalid_0's multi_logloss: 0.662746\n",
      "[1100]\tvalid_0's multi_logloss: 0.660758\n",
      "[1200]\tvalid_0's multi_logloss: 0.658943\n",
      "[1300]\tvalid_0's multi_logloss: 0.657223\n",
      "[1400]\tvalid_0's multi_logloss: 0.65647\n",
      "[1500]\tvalid_0's multi_logloss: 0.655771\n",
      "[1600]\tvalid_0's multi_logloss: 0.654806\n",
      "[1700]\tvalid_0's multi_logloss: 0.653854\n",
      "[1800]\tvalid_0's multi_logloss: 0.653436\n",
      "[1900]\tvalid_0's multi_logloss: 0.65327\n",
      "[2000]\tvalid_0's multi_logloss: 0.6527\n",
      "[2100]\tvalid_0's multi_logloss: 0.652072\n",
      "[2200]\tvalid_0's multi_logloss: 0.651597\n",
      "[2300]\tvalid_0's multi_logloss: 0.650908\n",
      "[2400]\tvalid_0's multi_logloss: 0.651039\n",
      "Early stopping, best iteration is:\n",
      "[2317]\tvalid_0's multi_logloss: 0.650671\n",
      "name lgb,fold:5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.747448\n",
      "[200]\tvalid_0's multi_logloss: 0.729605\n",
      "[300]\tvalid_0's multi_logloss: 0.720136\n",
      "[400]\tvalid_0's multi_logloss: 0.713169\n",
      "[500]\tvalid_0's multi_logloss: 0.708154\n",
      "[600]\tvalid_0's multi_logloss: 0.704069\n",
      "[700]\tvalid_0's multi_logloss: 0.701452\n",
      "[800]\tvalid_0's multi_logloss: 0.699605\n",
      "[900]\tvalid_0's multi_logloss: 0.698541\n",
      "[1000]\tvalid_0's multi_logloss: 0.697277\n",
      "[1100]\tvalid_0's multi_logloss: 0.69559\n",
      "[1200]\tvalid_0's multi_logloss: 0.694796\n",
      "[1300]\tvalid_0's multi_logloss: 0.695679\n",
      "Early stopping, best iteration is:\n",
      "[1203]\tvalid_0's multi_logloss: 0.69468\n",
      "name lgb,fold:6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.706165\n",
      "[200]\tvalid_0's multi_logloss: 0.689015\n",
      "[300]\tvalid_0's multi_logloss: 0.680888\n",
      "[400]\tvalid_0's multi_logloss: 0.675696\n",
      "[500]\tvalid_0's multi_logloss: 0.671986\n",
      "[600]\tvalid_0's multi_logloss: 0.669646\n",
      "[700]\tvalid_0's multi_logloss: 0.667501\n",
      "[800]\tvalid_0's multi_logloss: 0.665484\n",
      "[900]\tvalid_0's multi_logloss: 0.663935\n",
      "[1000]\tvalid_0's multi_logloss: 0.662532\n",
      "[1100]\tvalid_0's multi_logloss: 0.662434\n",
      "Early stopping, best iteration is:\n",
      "[1043]\tvalid_0's multi_logloss: 0.66206\n",
      "name lgb,fold:7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.705645\n",
      "[200]\tvalid_0's multi_logloss: 0.682818\n",
      "[300]\tvalid_0's multi_logloss: 0.672784\n",
      "[400]\tvalid_0's multi_logloss: 0.666212\n",
      "[500]\tvalid_0's multi_logloss: 0.661573\n",
      "[600]\tvalid_0's multi_logloss: 0.657639\n",
      "[700]\tvalid_0's multi_logloss: 0.655245\n",
      "[800]\tvalid_0's multi_logloss: 0.652771\n",
      "[900]\tvalid_0's multi_logloss: 0.651098\n",
      "[1000]\tvalid_0's multi_logloss: 0.649245\n",
      "[1100]\tvalid_0's multi_logloss: 0.647459\n",
      "[1200]\tvalid_0's multi_logloss: 0.646708\n",
      "[1300]\tvalid_0's multi_logloss: 0.646451\n",
      "[1400]\tvalid_0's multi_logloss: 0.645563\n",
      "[1500]\tvalid_0's multi_logloss: 0.644838\n",
      "[1600]\tvalid_0's multi_logloss: 0.644341\n",
      "[1700]\tvalid_0's multi_logloss: 0.644489\n",
      "Early stopping, best iteration is:\n",
      "[1614]\tvalid_0's multi_logloss: 0.644097\n",
      "name lgb,fold:8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.712087\n",
      "[200]\tvalid_0's multi_logloss: 0.691694\n",
      "[300]\tvalid_0's multi_logloss: 0.682639\n",
      "[400]\tvalid_0's multi_logloss: 0.675665\n",
      "[500]\tvalid_0's multi_logloss: 0.671097\n",
      "[600]\tvalid_0's multi_logloss: 0.668422\n",
      "[700]\tvalid_0's multi_logloss: 0.665623\n",
      "[800]\tvalid_0's multi_logloss: 0.66405\n",
      "[900]\tvalid_0's multi_logloss: 0.662495\n",
      "[1000]\tvalid_0's multi_logloss: 0.662215\n",
      "[1100]\tvalid_0's multi_logloss: 0.661327\n",
      "Early stopping, best iteration is:\n",
      "[1091]\tvalid_0's multi_logloss: 0.660995\n",
      "name lgb,fold:9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.717289\n",
      "[200]\tvalid_0's multi_logloss: 0.700601\n",
      "[300]\tvalid_0's multi_logloss: 0.692342\n",
      "[400]\tvalid_0's multi_logloss: 0.686667\n",
      "[500]\tvalid_0's multi_logloss: 0.683012\n",
      "[600]\tvalid_0's multi_logloss: 0.679597\n",
      "[700]\tvalid_0's multi_logloss: 0.676828\n",
      "[800]\tvalid_0's multi_logloss: 0.674905\n",
      "[900]\tvalid_0's multi_logloss: 0.674092\n",
      "[1000]\tvalid_0's multi_logloss: 0.673409\n",
      "[1100]\tvalid_0's multi_logloss: 0.672145\n",
      "[1200]\tvalid_0's multi_logloss: 0.670768\n",
      "[1300]\tvalid_0's multi_logloss: 0.670022\n",
      "[1400]\tvalid_0's multi_logloss: 0.668904\n",
      "[1500]\tvalid_0's multi_logloss: 0.668818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1600]\tvalid_0's multi_logloss: 0.667612\n",
      "[1700]\tvalid_0's multi_logloss: 0.667209\n",
      "[1800]\tvalid_0's multi_logloss: 0.667317\n",
      "[1900]\tvalid_0's multi_logloss: 0.667087\n",
      "Early stopping, best iteration is:\n",
      "[1883]\tvalid_0's multi_logloss: 0.666779\n",
      "accuracy_score:0.7106393323069443\n",
      "lgb_test_pred[:10]:[2 2 2 0 1 0 1 1 2 1]\n"
     ]
    }
   ],
   "source": [
    "#model lgb分类模型,日志评估,早停防止过拟合\n",
    "from  lightgbm import LGBMClassifier,log_evaluation,early_stopping\n",
    "#metric:准确率\n",
    "from sklearn.metrics import accuracy_score\n",
    "#KFold是直接分成k折,StratifiedKFold还要考虑每种类别的占比\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "choose_cols=[col for col in test_feats.columns]\n",
    "def fit_and_predict(train_feats=train_feats,test_feats=test_feats,model=None,num_folds=10,seed=2024,name='lgb'):\n",
    "    X=train_feats[choose_cols].copy()\n",
    "    y=train_feats['label'].copy()\n",
    "    oof_pred=np.zeros((len(X)))\n",
    "    test_X=test_feats[choose_cols].copy()\n",
    "    test_pred_pro=np.zeros((num_folds,len(test_X),3))#3是num_classes\n",
    "     \n",
    "    #10折交叉验证\n",
    "    skf = StratifiedKFold(n_splits=num_folds,shuffle=True)\n",
    "    for fold, (train_index, valid_index) in (enumerate(skf.split(X,y))):\n",
    "        print(f\"name {name},fold:{fold}\")\n",
    "\n",
    "        X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n",
    "        y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n",
    "        \n",
    "        model.fit(X_train,y_train,eval_set=[(X_valid, y_valid)],\n",
    "                      callbacks=[log_evaluation(100),early_stopping(100)]\n",
    "                     )\n",
    "        \n",
    "        oof_pred[valid_index]=model.predict(X_valid)\n",
    "        test_pred_pro[fold]=model.predict_proba(test_X)\n",
    "        \n",
    "    print(f\"accuracy_score:{accuracy_score(y.values,oof_pred)}\")\n",
    "    #(len(test_X),3)\n",
    "    test_pred_pro=test_pred_pro.mean(axis=0)\n",
    "    \n",
    "    test_preds=np.argmax(test_pred_pro,axis=1)\n",
    "    return oof_pred,test_preds\n",
    "lgb_params={\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"objective\": \"multi_class\",\n",
    "    \"metric\": \"multi_logloss\",\n",
    "    \"max_depth\": 6,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"n_estimators\":10000,\n",
    "    \"colsample_bytree\": 0.2,\n",
    "    \"colsample_bynode\": 0.2,\n",
    "    \"verbose\": -1,\n",
    "    \"random_state\": 2024,\n",
    "    \"reg_alpha\": 0.1,\n",
    "    \"reg_lambda\": 10,\n",
    "    \"extra_trees\":True,\n",
    "    'num_leaves':127,\n",
    "    \"verbose\": -1,\n",
    "    \"max_bin\":225,\n",
    "    }\n",
    "\n",
    "lgb_oof_pred_pro,lgb_test_pred=fit_and_predict(model=LGBMClassifier(**lgb_params),num_folds=10,seed=2024,name='lgb')\n",
    "print(f\"lgb_test_pred[:10]:{lgb_test_pred[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401aa1d6",
   "metadata": {},
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b2f9f8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label\n",
       "0   0      2\n",
       "1   1      2\n",
       "2   2      2\n",
       "3   3      0\n",
       "4   4      1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission['label']=lgb_test_pred\n",
    "submission.to_csv(path+\"baseline.csv\",index=None)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf05fd0",
   "metadata": {},
   "source": [
    "### 后续改进方向:\n",
    "\n",
    "#### 1.可以用上全部的数据,这样的问题就是训练数据和测试数据分布不一致,线下CV不具有参考意义。\n",
    "\n",
    "#### 2.构造统计特征的时候加上q25,q75,skew,kurt等特征。\n",
    "\n",
    "#### 3.考虑构造血氧和心率的交叉特征(加减乘除),并对交叉特征采用统计方法建模。\n",
    "\n",
    "#### 4.尝试融合模型(lgb,xgb,cat)\n",
    "\n",
    "#### 5.采用深度学习的方法并结合赛题背景进行建模。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bda1db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
