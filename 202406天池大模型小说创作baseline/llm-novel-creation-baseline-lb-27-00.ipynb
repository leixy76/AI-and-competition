{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b9d0e09",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.004275,
     "end_time": "2024-06-20T13:36:19.646404",
     "exception": false,
     "start_time": "2024-06-20T13:36:19.642129",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Created by <a href=\"https://github.com/yunsuxiaozi\">yunsuxiaozi</a> 2024/6/21\n",
    "\n",
    "#### 这是优酷x天池 「酷文」小说创作大模型挑战赛的baseline.我这里使用的是谷歌的Gemma模型(pytorch-2b-it-V2)。使用这个模型作为baseline没有什么理由,就是因为我是大模型的初学者,对这块了解的不多,目前所掌握的大模型调用只会这一个,Gemma模型刚出的时候感兴趣就学了一下,仅此而已。后续我也会学习NLP包括大模型的相关知识。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77045a3",
   "metadata": {
    "papermill": {
     "duration": 0.003477,
     "end_time": "2024-06-20T13:36:19.653920",
     "exception": false,
     "start_time": "2024-06-20T13:36:19.650443",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 导入库,并读取测试数据,这个测试数据和普通的json文件读取方式不同,后面保存提交文件也和普通的json文件保存方式不同。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b12087d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T13:36:19.662803Z",
     "iopub.status.busy": "2024-06-20T13:36:19.662514Z",
     "iopub.status.idle": "2024-06-20T13:36:20.423186Z",
     "shell.execute_reply": "2024-06-20T13:36:20.422443Z"
    },
    "papermill": {
     "duration": 0.767808,
     "end_time": "2024-06-20T13:36:20.425508",
     "exception": false,
     "start_time": "2024-06-20T13:36:19.657700",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd#导入csv文件的库\n",
    "import json#用于读取和写入json数据格式\n",
    "test=[]\n",
    "with open(\"/kaggle/input/llmnovel/write novels  LLM/test.json\",'r',encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        test.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52938ca6",
   "metadata": {
    "papermill": {
     "duration": 0.003772,
     "end_time": "2024-06-20T13:36:20.433447",
     "exception": false,
     "start_time": "2024-06-20T13:36:20.429675",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 查看数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce19ff05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T13:36:20.442547Z",
     "iopub.status.busy": "2024-06-20T13:36:20.442145Z",
     "iopub.status.idle": "2024-06-20T13:36:20.448737Z",
     "shell.execute_reply": "2024-06-20T13:36:20.447879Z"
    },
    "papermill": {
     "duration": 0.013506,
     "end_time": "2024-06-20T13:36:20.450769",
     "exception": false,
     "start_time": "2024-06-20T13:36:20.437263",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_Instruction:,sample_input:现代励志故事，一个失业青年如何克服生活困境，终于实现自我突破，成为行业翘楚的心路历程。,sample_output:\n"
     ]
    }
   ],
   "source": [
    "Instruction=[test[i]['instruction'] for i in range(len(test))]\n",
    "Input=[test[i]['input'] for i in range(len(test))]\n",
    "Output=[test[i]['output'] for i in range(len(test))]\n",
    "print(f\"sample_Instruction:{Instruction[0]},sample_input:{Input[0]},sample_output:{Output[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b399ac",
   "metadata": {
    "papermill": {
     "duration": 0.003722,
     "end_time": "2024-06-20T13:36:20.458867",
     "exception": false,
     "start_time": "2024-06-20T13:36:20.455145",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Gemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c51905c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T13:36:20.468288Z",
     "iopub.status.busy": "2024-06-20T13:36:20.467735Z",
     "iopub.status.idle": "2024-06-20T13:36:37.018794Z",
     "shell.execute_reply": "2024-06-20T13:36:37.017580Z"
    },
    "papermill": {
     "duration": 16.5586,
     "end_time": "2024-06-20T13:36:37.021539",
     "exception": false,
     "start_time": "2024-06-20T13:36:20.462939",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'gemma_pytorch'...\r\n",
      "remote: Enumerating objects: 177, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (109/109), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (61/61), done.\u001b[K\r\n",
      "remote: Total 177 (delta 64), reused 68 (delta 46), pack-reused 68\u001b[K\r\n",
      "Receiving objects: 100% (177/177), 2.16 MiB | 23.32 MiB/s, done.\r\n",
      "Resolving deltas: 100% (91/91), done.\r\n",
      "mv: target '/kaggle/working/gemma/' is not a directory\r\n"
     ]
    }
   ],
   "source": [
    "# 尝试使用gemma https://www.kaggle.com/code/shresthshukla/gemma-using-pytorch\n",
    "#安装 -q(减少输出信息) -U是升级,不可变的字典 Byte Pair Encoding, BPE的分词库\n",
    "!pip install -q -U immutabledict sentencepiece\n",
    "#克隆github 的gemma_pytorch仓库\n",
    "!git clone https://github.com/google/gemma_pytorch.git\n",
    "#将克隆来的全部东西移动到本地\n",
    "!mv /kaggle/working/gemma_pytorch/gemma/* /kaggle/working/gemma/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02772750",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T13:36:37.034109Z",
     "iopub.status.busy": "2024-06-20T13:36:37.033280Z",
     "iopub.status.idle": "2024-06-20T13:36:40.503175Z",
     "shell.execute_reply": "2024-06-20T13:36:40.502378Z"
    },
    "papermill": {
     "duration": 3.478584,
     "end_time": "2024-06-20T13:36:40.505460",
     "exception": false,
     "start_time": "2024-06-20T13:36:37.026876",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys#允许python开发者与python解释器进行交互\n",
    "#如果你尝试导入一个模块,如果模块不在其他目录下,还会在新添加的目录进行查找\n",
    "sys.path.append(\"/kaggle/working/gemma_pytorch/\") \n",
    "#获取7b模型的参数和获取2b模型的参数\n",
    "from gemma.config import get_config_for_7b, get_config_for_2b\n",
    "#Causal Language Model，简称 CLM,因果语言模型\n",
    "from gemma.model import GemmaForCausalLM\n",
    "#导入gemma的分词器\n",
    "from gemma.tokenizer import Tokenizer\n",
    "import contextlib#简化上下文管理器\n",
    "#pytorch\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc17d8d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T13:36:40.516822Z",
     "iopub.status.busy": "2024-06-20T13:36:40.516421Z",
     "iopub.status.idle": "2024-06-20T13:36:40.569228Z",
     "shell.execute_reply": "2024-06-20T13:36:40.568515Z"
    },
    "papermill": {
     "duration": 0.060549,
     "end_time": "2024-06-20T13:36:40.571136",
     "exception": false,
     "start_time": "2024-06-20T13:36:40.510587",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random#提供了一些用于生成随机数的函数\n",
    "VARIANT = \"2b-it\" #选择模型的名字\n",
    "weights_dir = '/kaggle/input/gemma/pytorch/2b-it/2' #模型参数的路径\n",
    "device='cuda' if torch.cuda.is_available() else\"cpu\"\n",
    "ckpt_path = f'{weights_dir}/gemma-{VARIANT}.ckpt'#checkpoint,深度学习模型在训练过程中的状态\n",
    "def seed_everything(seed):\n",
    "    torch.backends.cudnn.deterministic = True#将cuda加速的随机数生成器设为确定性模式\n",
    "    torch.backends.cudnn.benchmark = True#关闭CuDNN框架的自动寻找最优卷积算法的功能，以避免不同的算法对结果产生影响\n",
    "    torch.manual_seed(seed)#pytorch的随机种子\n",
    "    random.seed(seed)#python内置的随机种子\n",
    "seed_everything(seed=2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0950ec13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T13:36:40.582450Z",
     "iopub.status.busy": "2024-06-20T13:36:40.581946Z",
     "iopub.status.idle": "2024-06-20T13:37:14.206075Z",
     "shell.execute_reply": "2024-06-20T13:37:14.205149Z"
    },
    "papermill": {
     "duration": 33.632038,
     "end_time": "2024-06-20T13:37:14.208269",
     "exception": false,
     "start_time": "2024-06-20T13:36:40.576231",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_config:GemmaConfig(vocab_size=256000, max_position_embeddings=8192, num_hidden_layers=18, num_attention_heads=8, num_key_value_heads=1, hidden_size=2048, intermediate_size=16384, head_dim=256, rms_norm_eps=1e-06, dtype='bfloat16', quant=False, tokenizer='/kaggle/input/gemma/pytorch/2b-it/2/tokenizer.model')\n",
      "model_config.get_dtype():torch.bfloat16\n",
      "This is the model structure. : \n",
      " GemmaForCausalLM(\n",
      "  (embedder): Embedding()\n",
      "  (model): GemmaModel(\n",
      "    (layers): ModuleList(\n",
      "      (0-17): 18 x GemmaDecoderLayer(\n",
      "        (self_attn): GemmaAttention(\n",
      "          (qkv_proj): Linear()\n",
      "          (o_proj): Linear()\n",
      "        )\n",
      "        (mlp): GemmaMLP(\n",
      "          (gate_proj): Linear()\n",
      "          (up_proj): Linear()\n",
      "          (down_proj): Linear()\n",
      "        )\n",
      "        (input_layernorm): RMSNorm()\n",
      "        (post_attention_layernorm): RMSNorm()\n",
      "      )\n",
      "    )\n",
      "    (norm): RMSNorm()\n",
      "  )\n",
      "  (sampler): Sampler()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model weights loaded.\n",
      "Model Configuraiton Done\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "kimi chat\n",
    "bfloat16 半精度浮点数 8位指数7位尾数(小数部分) 数据范围大,精度低\n",
    "float16是5位指数,10位尾数 数据范围小,精度高\n",
    "硬件兼容性：并非所有的硬件都支持 bfloat16。在某些情况下，尤其是在推理时，硬件可能只支持标准的 float32 格式。因此，为了确保模型能够在这些硬件上运行，可能需要将权重从 bfloat16 转换为 float32。\n",
    "\n",
    "精度要求：尽管 bfloat16 在训练时可以提供足够的精度，但在某些应用场景中，可能需要更高的精度来确保推理结果的准确性。在这种情况下，使用 float32 可以提供更高的数值精度。\n",
    "\n",
    "软件支持：某些深度学习框架或库可能在处理 bfloat16 数据类型时存在限制或不足，这可能需要开发者在部署模型时将权重转换为 float32。\n",
    "\n",
    "性能考虑：在某些情况下，使用 float32 进行推理可能比使用 bfloat16 更高效，尤其是在硬件对 float32 有优化的情况下。\n",
    "\n",
    "通用性：float32 是深度学习中最常用的数据类型，许多库和工具都是围绕 float32 设计的。为了提高模型的通用性和兼容性，开发者可能会选择在推理时使用 float32。\n",
    "\"\"\"\n",
    "#如果使用2b的模型就使用2b的参数,否则使用7b的参数\n",
    "model_config = get_config_for_2b() if \"2b\" in VARIANT else get_config_for_7b()\n",
    "#导入分词器\n",
    "model_config.tokenizer = f\"{weights_dir}/tokenizer.model\"\n",
    "print(f\"model_config:{model_config}\")\n",
    "\n",
    "\n",
    "print(f\"model_config.get_dtype():{model_config.get_dtype()}\") \n",
    "@contextlib.contextmanager#将函数转换成一个上下文管理器,临时更改数据的类型\n",
    "def _set_default_tensor_type(dtype: torch.dtype):\n",
    "    \"\"\"Sets the default torch dtype to the given dtype.\"\"\"\n",
    "    torch.set_default_dtype(dtype)\n",
    "    yield\n",
    "    torch.set_default_dtype(torch.float)\n",
    "with _set_default_tensor_type(model_config.get_dtype()):\n",
    "    #传入模型的结构,创建模型\n",
    "    model = GemmaForCausalLM(model_config)\n",
    "    print(\"This is the model structure. : \\n\", model)\n",
    "    #根据路径去加载模型的权重\n",
    "    model.load_weights(ckpt_path)\n",
    "    print(\"Model weights loaded.\")\n",
    "    #模型移动到CPU并转成评估模式.\n",
    "    model = model.to(device).eval()\n",
    "print(\"Model Configuraiton Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c42b173",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T13:37:14.221401Z",
     "iopub.status.busy": "2024-06-20T13:37:14.221053Z",
     "iopub.status.idle": "2024-06-20T13:37:14.226274Z",
     "shell.execute_reply": "2024-06-20T13:37:14.225342Z"
    },
    "papermill": {
     "duration": 0.014536,
     "end_time": "2024-06-20T13:37:14.228692",
     "exception": false,
     "start_time": "2024-06-20T13:37:14.214156",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function generate in module gemma.model:\n",
      "\n",
      "generate(self, prompts: Union[str, Sequence[str]], device: Any, output_len: int = 100, temperature: Optional[float] = 0.95, top_p: float = 1.0, top_k: int = 100) -> Union[str, Sequence[str]]\n",
      "    Generates responses for given prompts using Gemma model.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#查看相关的参数\n",
    "help(GemmaForCausalLM.generate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74cac1d",
   "metadata": {
    "papermill": {
     "duration": 0.00586,
     "end_time": "2024-06-20T13:37:14.240455",
     "exception": false,
     "start_time": "2024-06-20T13:37:14.234595",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 为了考虑程序的运行时间,这里对2条测试数据共用一个预测结果。由于字数太少会扣分,这里对生成文本进行了微调。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "159bee10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T13:37:14.253671Z",
     "iopub.status.busy": "2024-06-20T13:37:14.253312Z",
     "iopub.status.idle": "2024-06-20T20:46:53.518806Z",
     "shell.execute_reply": "2024-06-20T20:46:53.517764Z"
    },
    "papermill": {
     "duration": 25779.318799,
     "end_time": "2024-06-20T20:46:53.565143",
     "exception": false,
     "start_time": "2024-06-20T13:37:14.246344",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 is ok,len(output):796\n",
      "2 is ok,len(output):766\n",
      "4 is ok,len(output):809\n",
      "6 is ok,len(output):793\n",
      "8 is ok,len(output):740\n",
      "10 is ok,len(output):650\n",
      "12 is ok,len(output):2854\n",
      "14 is ok,len(output):665\n",
      "16 is ok,len(output):823\n",
      "18 is ok,len(output):800\n",
      "20 is ok,len(output):820\n",
      "22 is ok,len(output):829\n",
      "24 is ok,len(output):931\n",
      "26 is ok,len(output):686\n",
      "28 is ok,len(output):679\n",
      "30 is ok,len(output):777\n",
      "32 is ok,len(output):817\n",
      "34 is ok,len(output):1249\n",
      "36 is ok,len(output):858\n",
      "38 is ok,len(output):728\n",
      "40 is ok,len(output):831\n",
      "42 is ok,len(output):887\n",
      "44 is ok,len(output):565\n",
      "46 is ok,len(output):762\n",
      "48 is ok,len(output):2929\n",
      "50 is ok,len(output):694\n",
      "52 is ok,len(output):2977\n",
      "54 is ok,len(output):803\n",
      "56 is ok,len(output):759\n",
      "58 is ok,len(output):814\n",
      "60 is ok,len(output):920\n",
      "62 is ok,len(output):711\n",
      "64 is ok,len(output):820\n",
      "66 is ok,len(output):838\n",
      "68 is ok,len(output):849\n",
      "70 is ok,len(output):738\n",
      "72 is ok,len(output):969\n",
      "74 is ok,len(output):823\n",
      "76 is ok,len(output):3577\n",
      "78 is ok,len(output):821\n",
      "80 is ok,len(output):881\n",
      "82 is ok,len(output):3196\n",
      "84 is ok,len(output):708\n",
      "86 is ok,len(output):759\n",
      "88 is ok,len(output):757\n",
      "90 is ok,len(output):2946\n",
      "92 is ok,len(output):674\n",
      "94 is ok,len(output):821\n",
      "96 is ok,len(output):770\n",
      "98 is ok,len(output):870\n",
      "100 is ok,len(output):896\n",
      "102 is ok,len(output):803\n",
      "104 is ok,len(output):733\n",
      "106 is ok,len(output):784\n",
      "108 is ok,len(output):631\n",
      "110 is ok,len(output):765\n",
      "112 is ok,len(output):734\n",
      "114 is ok,len(output):666\n",
      "116 is ok,len(output):808\n",
      "118 is ok,len(output):818\n",
      "120 is ok,len(output):1067\n",
      "122 is ok,len(output):761\n",
      "124 is ok,len(output):821\n",
      "126 is ok,len(output):2780\n",
      "128 is ok,len(output):642\n",
      "130 is ok,len(output):639\n",
      "132 is ok,len(output):828\n",
      "134 is ok,len(output):940\n",
      "136 is ok,len(output):685\n",
      "138 is ok,len(output):807\n",
      "140 is ok,len(output):3018\n",
      "142 is ok,len(output):2830\n",
      "144 is ok,len(output):889\n",
      "146 is ok,len(output):907\n",
      "148 is ok,len(output):784\n",
      "150 is ok,len(output):851\n",
      "152 is ok,len(output):754\n",
      "154 is ok,len(output):811\n",
      "156 is ok,len(output):652\n",
      "158 is ok,len(output):707\n",
      "160 is ok,len(output):783\n",
      "162 is ok,len(output):719\n",
      "164 is ok,len(output):1041\n",
      "166 is ok,len(output):798\n",
      "168 is ok,len(output):802\n",
      "170 is ok,len(output):747\n",
      "172 is ok,len(output):692\n",
      "174 is ok,len(output):752\n",
      "176 is ok,len(output):781\n",
      "178 is ok,len(output):566\n",
      "180 is ok,len(output):847\n",
      "182 is ok,len(output):677\n",
      "184 is ok,len(output):581\n",
      "186 is ok,len(output):919\n",
      "188 is ok,len(output):811\n",
      "190 is ok,len(output):797\n",
      "192 is ok,len(output):672\n",
      "194 is ok,len(output):769\n",
      "196 is ok,len(output):665\n",
      "198 is ok,len(output):730\n",
      "200 is ok,len(output):1029\n",
      "202 is ok,len(output):1230\n",
      "204 is ok,len(output):837\n",
      "206 is ok,len(output):832\n",
      "208 is ok,len(output):826\n",
      "210 is ok,len(output):525\n",
      "212 is ok,len(output):650\n",
      "214 is ok,len(output):855\n",
      "216 is ok,len(output):732\n",
      "218 is ok,len(output):804\n",
      "220 is ok,len(output):1081\n",
      "222 is ok,len(output):831\n",
      "224 is ok,len(output):706\n",
      "226 is ok,len(output):805\n",
      "228 is ok,len(output):912\n",
      "230 is ok,len(output):606\n",
      "232 is ok,len(output):917\n",
      "234 is ok,len(output):1013\n",
      "236 is ok,len(output):801\n",
      "238 is ok,len(output):935\n",
      "240 is ok,len(output):833\n",
      "242 is ok,len(output):729\n",
      "244 is ok,len(output):914\n",
      "246 is ok,len(output):869\n",
      "248 is ok,len(output):921\n",
      "250 is ok,len(output):816\n",
      "252 is ok,len(output):1021\n",
      "254 is ok,len(output):477\n",
      "256 is ok,len(output):1111\n",
      "258 is ok,len(output):493\n",
      "260 is ok,len(output):722\n",
      "262 is ok,len(output):700\n",
      "264 is ok,len(output):608\n",
      "266 is ok,len(output):729\n",
      "268 is ok,len(output):616\n",
      "270 is ok,len(output):743\n",
      "272 is ok,len(output):727\n",
      "274 is ok,len(output):2506\n",
      "276 is ok,len(output):707\n",
      "278 is ok,len(output):959\n",
      "280 is ok,len(output):851\n",
      "282 is ok,len(output):559\n",
      "284 is ok,len(output):829\n",
      "286 is ok,len(output):707\n",
      "288 is ok,len(output):748\n",
      "290 is ok,len(output):722\n",
      "292 is ok,len(output):820\n",
      "294 is ok,len(output):728\n",
      "296 is ok,len(output):844\n",
      "298 is ok,len(output):661\n",
      "300 is ok,len(output):810\n",
      "302 is ok,len(output):794\n",
      "304 is ok,len(output):1063\n",
      "306 is ok,len(output):979\n",
      "308 is ok,len(output):971\n",
      "310 is ok,len(output):816\n",
      "312 is ok,len(output):863\n",
      "314 is ok,len(output):886\n",
      "316 is ok,len(output):814\n",
      "318 is ok,len(output):848\n",
      "320 is ok,len(output):817\n",
      "322 is ok,len(output):923\n",
      "324 is ok,len(output):812\n",
      "326 is ok,len(output):800\n",
      "328 is ok,len(output):802\n",
      "330 is ok,len(output):862\n",
      "332 is ok,len(output):1352\n",
      "334 is ok,len(output):711\n",
      "336 is ok,len(output):828\n",
      "338 is ok,len(output):768\n",
      "340 is ok,len(output):850\n",
      "342 is ok,len(output):785\n",
      "344 is ok,len(output):1033\n",
      "346 is ok,len(output):837\n",
      "348 is ok,len(output):987\n",
      "350 is ok,len(output):804\n",
      "352 is ok,len(output):724\n",
      "354 is ok,len(output):703\n",
      "356 is ok,len(output):630\n",
      "358 is ok,len(output):839\n",
      "360 is ok,len(output):685\n",
      "362 is ok,len(output):665\n",
      "364 is ok,len(output):710\n",
      "366 is ok,len(output):863\n",
      "368 is ok,len(output):738\n",
      "370 is ok,len(output):902\n",
      "372 is ok,len(output):773\n",
      "374 is ok,len(output):847\n",
      "376 is ok,len(output):918\n",
      "378 is ok,len(output):774\n",
      "380 is ok,len(output):878\n",
      "382 is ok,len(output):953\n",
      "384 is ok,len(output):3382\n",
      "386 is ok,len(output):2849\n",
      "388 is ok,len(output):753\n",
      "390 is ok,len(output):2955\n",
      "392 is ok,len(output):957\n",
      "394 is ok,len(output):738\n",
      "396 is ok,len(output):850\n",
      "398 is ok,len(output):858\n",
      "400 is ok,len(output):674\n",
      "402 is ok,len(output):597\n",
      "404 is ok,len(output):558\n",
      "406 is ok,len(output):3206\n",
      "408 is ok,len(output):804\n",
      "410 is ok,len(output):848\n",
      "412 is ok,len(output):647\n",
      "414 is ok,len(output):3440\n",
      "416 is ok,len(output):603\n",
      "418 is ok,len(output):686\n",
      "420 is ok,len(output):2832\n",
      "422 is ok,len(output):2846\n",
      "424 is ok,len(output):641\n",
      "426 is ok,len(output):1388\n",
      "428 is ok,len(output):870\n",
      "430 is ok,len(output):639\n",
      "432 is ok,len(output):760\n",
      "434 is ok,len(output):780\n",
      "436 is ok,len(output):895\n",
      "438 is ok,len(output):656\n",
      "440 is ok,len(output):3126\n",
      "442 is ok,len(output):745\n",
      "444 is ok,len(output):2484\n",
      "446 is ok,len(output):874\n",
      "448 is ok,len(output):676\n",
      "450 is ok,len(output):837\n",
      "452 is ok,len(output):896\n",
      "454 is ok,len(output):837\n",
      "456 is ok,len(output):869\n",
      "458 is ok,len(output):709\n",
      "460 is ok,len(output):699\n",
      "462 is ok,len(output):907\n",
      "464 is ok,len(output):666\n",
      "466 is ok,len(output):835\n",
      "468 is ok,len(output):682\n",
      "470 is ok,len(output):1003\n",
      "472 is ok,len(output):779\n",
      "474 is ok,len(output):798\n",
      "476 is ok,len(output):825\n",
      "478 is ok,len(output):660\n",
      "480 is ok,len(output):701\n",
      "482 is ok,len(output):1455\n",
      "484 is ok,len(output):726\n",
      "486 is ok,len(output):804\n",
      "488 is ok,len(output):620\n",
      "490 is ok,len(output):803\n",
      "492 is ok,len(output):809\n",
      "494 is ok,len(output):756\n",
      "496 is ok,len(output):828\n",
      "498 is ok,len(output):842\n",
      "500 is ok,len(output):1024\n",
      "502 is ok,len(output):879\n",
      "504 is ok,len(output):761\n",
      "506 is ok,len(output):732\n",
      "508 is ok,len(output):643\n",
      "510 is ok,len(output):1034\n",
      "512 is ok,len(output):893\n",
      "514 is ok,len(output):822\n",
      "516 is ok,len(output):820\n",
      "518 is ok,len(output):859\n",
      "520 is ok,len(output):738\n",
      "522 is ok,len(output):955\n",
      "524 is ok,len(output):3059\n",
      "526 is ok,len(output):705\n",
      "528 is ok,len(output):789\n",
      "530 is ok,len(output):798\n",
      "532 is ok,len(output):2898\n",
      "534 is ok,len(output):900\n",
      "536 is ok,len(output):892\n",
      "538 is ok,len(output):689\n",
      "540 is ok,len(output):844\n",
      "542 is ok,len(output):788\n",
      "544 is ok,len(output):906\n",
      "546 is ok,len(output):614\n",
      "548 is ok,len(output):950\n",
      "550 is ok,len(output):936\n",
      "552 is ok,len(output):885\n",
      "554 is ok,len(output):926\n",
      "556 is ok,len(output):914\n",
      "558 is ok,len(output):632\n",
      "560 is ok,len(output):978\n",
      "562 is ok,len(output):752\n",
      "564 is ok,len(output):990\n",
      "566 is ok,len(output):1605\n",
      "568 is ok,len(output):875\n",
      "570 is ok,len(output):962\n",
      "572 is ok,len(output):1210\n",
      "574 is ok,len(output):838\n",
      "576 is ok,len(output):635\n",
      "578 is ok,len(output):1849\n",
      "580 is ok,len(output):3126\n",
      "582 is ok,len(output):809\n",
      "584 is ok,len(output):1684\n",
      "586 is ok,len(output):968\n",
      "588 is ok,len(output):808\n",
      "590 is ok,len(output):1032\n",
      "592 is ok,len(output):746\n",
      "594 is ok,len(output):986\n",
      "596 is ok,len(output):793\n",
      "598 is ok,len(output):832\n",
      "600 is ok,len(output):711\n",
      "602 is ok,len(output):970\n",
      "604 is ok,len(output):2957\n",
      "606 is ok,len(output):2626\n",
      "608 is ok,len(output):724\n",
      "610 is ok,len(output):939\n",
      "612 is ok,len(output):801\n",
      "614 is ok,len(output):1001\n",
      "616 is ok,len(output):448\n",
      "618 is ok,len(output):601\n",
      "620 is ok,len(output):665\n",
      "622 is ok,len(output):813\n",
      "624 is ok,len(output):757\n",
      "626 is ok,len(output):713\n",
      "628 is ok,len(output):712\n",
      "630 is ok,len(output):678\n",
      "632 is ok,len(output):2496\n",
      "634 is ok,len(output):591\n",
      "636 is ok,len(output):823\n",
      "638 is ok,len(output):3127\n",
      "640 is ok,len(output):644\n",
      "642 is ok,len(output):746\n",
      "644 is ok,len(output):651\n",
      "646 is ok,len(output):644\n",
      "648 is ok,len(output):750\n",
      "650 is ok,len(output):637\n",
      "652 is ok,len(output):693\n",
      "654 is ok,len(output):561\n",
      "656 is ok,len(output):807\n",
      "658 is ok,len(output):743\n",
      "660 is ok,len(output):628\n",
      "662 is ok,len(output):729\n",
      "664 is ok,len(output):596\n",
      "666 is ok,len(output):730\n",
      "668 is ok,len(output):687\n",
      "670 is ok,len(output):575\n",
      "672 is ok,len(output):809\n",
      "674 is ok,len(output):586\n",
      "676 is ok,len(output):1714\n",
      "678 is ok,len(output):1198\n",
      "680 is ok,len(output):643\n",
      "682 is ok,len(output):570\n",
      "684 is ok,len(output):499\n",
      "686 is ok,len(output):600\n",
      "688 is ok,len(output):665\n",
      "690 is ok,len(output):863\n",
      "692 is ok,len(output):2608\n",
      "694 is ok,len(output):715\n",
      "696 is ok,len(output):724\n",
      "698 is ok,len(output):780\n",
      "700 is ok,len(output):723\n",
      "702 is ok,len(output):883\n",
      "704 is ok,len(output):936\n",
      "706 is ok,len(output):1081\n",
      "708 is ok,len(output):728\n",
      "710 is ok,len(output):1009\n",
      "712 is ok,len(output):860\n",
      "714 is ok,len(output):2680\n",
      "716 is ok,len(output):3735\n",
      "718 is ok,len(output):659\n",
      "720 is ok,len(output):844\n",
      "722 is ok,len(output):720\n",
      "724 is ok,len(output):924\n",
      "726 is ok,len(output):845\n",
      "728 is ok,len(output):909\n",
      "730 is ok,len(output):818\n",
      "732 is ok,len(output):1148\n",
      "734 is ok,len(output):798\n",
      "736 is ok,len(output):732\n",
      "738 is ok,len(output):970\n",
      "740 is ok,len(output):819\n",
      "742 is ok,len(output):668\n",
      "744 is ok,len(output):701\n",
      "746 is ok,len(output):885\n",
      "748 is ok,len(output):661\n",
      "750 is ok,len(output):679\n",
      "752 is ok,len(output):896\n",
      "754 is ok,len(output):876\n",
      "756 is ok,len(output):929\n",
      "758 is ok,len(output):662\n",
      "760 is ok,len(output):612\n",
      "762 is ok,len(output):804\n",
      "764 is ok,len(output):817\n",
      "766 is ok,len(output):3119\n",
      "768 is ok,len(output):803\n",
      "770 is ok,len(output):2675\n",
      "772 is ok,len(output):779\n",
      "774 is ok,len(output):746\n",
      "776 is ok,len(output):647\n",
      "778 is ok,len(output):756\n",
      "780 is ok,len(output):834\n",
      "782 is ok,len(output):652\n",
      "784 is ok,len(output):688\n",
      "786 is ok,len(output):818\n",
      "788 is ok,len(output):815\n",
      "790 is ok,len(output):861\n",
      "792 is ok,len(output):1014\n",
      "794 is ok,len(output):775\n",
      "796 is ok,len(output):1087\n",
      "798 is ok,len(output):963\n",
      "800 is ok,len(output):810\n",
      "802 is ok,len(output):808\n",
      "804 is ok,len(output):846\n",
      "806 is ok,len(output):909\n",
      "808 is ok,len(output):866\n",
      "810 is ok,len(output):796\n",
      "812 is ok,len(output):811\n",
      "814 is ok,len(output):3198\n",
      "816 is ok,len(output):777\n",
      "818 is ok,len(output):670\n",
      "820 is ok,len(output):824\n",
      "822 is ok,len(output):808\n",
      "824 is ok,len(output):898\n",
      "826 is ok,len(output):878\n",
      "828 is ok,len(output):963\n",
      "830 is ok,len(output):1019\n",
      "832 is ok,len(output):842\n",
      "834 is ok,len(output):1056\n",
      "836 is ok,len(output):764\n",
      "838 is ok,len(output):2867\n",
      "840 is ok,len(output):802\n",
      "842 is ok,len(output):843\n",
      "844 is ok,len(output):1130\n",
      "846 is ok,len(output):829\n",
      "848 is ok,len(output):872\n",
      "850 is ok,len(output):775\n",
      "852 is ok,len(output):703\n",
      "854 is ok,len(output):766\n",
      "856 is ok,len(output):670\n",
      "858 is ok,len(output):3387\n",
      "860 is ok,len(output):779\n",
      "862 is ok,len(output):742\n",
      "864 is ok,len(output):588\n",
      "866 is ok,len(output):964\n",
      "868 is ok,len(output):808\n",
      "870 is ok,len(output):806\n",
      "872 is ok,len(output):3130\n",
      "874 is ok,len(output):642\n",
      "876 is ok,len(output):942\n",
      "878 is ok,len(output):1070\n",
      "880 is ok,len(output):848\n",
      "882 is ok,len(output):816\n",
      "884 is ok,len(output):800\n",
      "886 is ok,len(output):745\n",
      "888 is ok,len(output):994\n",
      "890 is ok,len(output):2740\n",
      "892 is ok,len(output):681\n",
      "894 is ok,len(output):664\n",
      "896 is ok,len(output):1012\n",
      "898 is ok,len(output):784\n",
      "900 is ok,len(output):769\n",
      "902 is ok,len(output):817\n",
      "904 is ok,len(output):645\n",
      "906 is ok,len(output):633\n",
      "908 is ok,len(output):681\n",
      "910 is ok,len(output):777\n",
      "912 is ok,len(output):619\n",
      "914 is ok,len(output):720\n",
      "916 is ok,len(output):939\n",
      "918 is ok,len(output):704\n",
      "920 is ok,len(output):823\n",
      "922 is ok,len(output):748\n",
      "924 is ok,len(output):809\n",
      "926 is ok,len(output):622\n",
      "928 is ok,len(output):640\n",
      "930 is ok,len(output):759\n",
      "932 is ok,len(output):768\n",
      "934 is ok,len(output):696\n",
      "936 is ok,len(output):800\n",
      "938 is ok,len(output):727\n",
      "940 is ok,len(output):681\n",
      "942 is ok,len(output):700\n",
      "944 is ok,len(output):701\n",
      "946 is ok,len(output):644\n",
      "948 is ok,len(output):833\n",
      "950 is ok,len(output):699\n",
      "952 is ok,len(output):636\n",
      "954 is ok,len(output):1010\n",
      "956 is ok,len(output):728\n",
      "958 is ok,len(output):2342\n",
      "960 is ok,len(output):796\n",
      "962 is ok,len(output):456\n",
      "964 is ok,len(output):781\n",
      "966 is ok,len(output):617\n",
      "968 is ok,len(output):815\n",
      "970 is ok,len(output):832\n",
      "972 is ok,len(output):522\n",
      "974 is ok,len(output):665\n",
      "976 is ok,len(output):645\n",
      "978 is ok,len(output):3368\n",
      "980 is ok,len(output):710\n",
      "982 is ok,len(output):545\n",
      "984 is ok,len(output):1681\n",
      "986 is ok,len(output):748\n",
      "988 is ok,len(output):634\n",
      "990 is ok,len(output):776\n",
      "992 is ok,len(output):814\n",
      "994 is ok,len(output):2393\n",
      "996 is ok,len(output):738\n",
      "998 is ok,len(output):25381\n",
      "Output[0]:在喧嚣的市面上，迷茫和绝望驱使了少年李晨进一步沦入贫困之中。失业几场，破产更难忍，他的内心如同荒芜的花园，渴望得到水的浇灌。他渴望拥有一份稳定的收入，也渴望摆脱疲惫和绝望。\n",
      "\n",
      "然而，生活中总是有一些光束照亮他的道路。他的朋友们鼓励他，向他分享一些创业经验；他的老师则鼓励他努力参加就业考试；他的家乡里也有一些企业招募人才，希望可以帮助他重返社会。\n",
      "\n",
      "经过努力练习，李晨终于参加了招聘考试，考上了一个热身行业的公司。他竭尽全力，勤刻学习，勤刻工作，终于在忙碌的 days 中找到了一份稳定的工作。\n",
      "\n",
      "然而，他的辛苦付出并没有得到回报。几年过去了，却没有看到他的辛苦成果。一种无力感笼罩了他的心灵，让他变得失去了对生活的热情和渴望。当他听到有人问他是否愿意来参加一个音乐节时，他毫无信心地拒绝了。\n",
      "\n",
      "迷茫和绝望吞噬了他的心灵，仿佛那时的失去了对生活的热情般。但就在那个时刻，他突然想起一些曾经的梦想，他心中充满了希望。他将当年为了梦想而努力学习的经验照进工作中，并将每一个成功的瞬间作为他的动力。\n",
      "\n",
      "终于，他明白，成功需要付出努力，也需要战胜怀疑。他重新失去了对生活的热爱，重新振作起来。他加入了一些社团，结识了一些志同道合的朋友，他们共同支持着他，激励他。\n",
      "\n",
      "终于，他找到了属于他的那一份激情。他开始思考如何打造一份可持续的商业模式，如何才能让自己的创业故事充满温暖和希望。他专注于提升自身的能力，不断学习新的知识，不断提升自身的能力。\n",
      "\n",
      "经过不断的努力，李晨终于建立了自己的企业,它在市场上取得了堂堂的成就。他用汗水和智慧，他带着一种难能可贵的精神和热情，他成为了这行业的领袖。\n",
      "\n",
      "在一段又一段成功的背后，李晨始终记得那个曾经迷茫和绝望的时刻，那一份渴望战胜了来自生活的 every 困难。当他胜利的时候，他也一定会用行动去回馈社会，为其他人注入希望。\n"
     ]
    }
   ],
   "source": [
    "import re#正则表达式库\n",
    "#用户聊天模板和模型聊天模板\n",
    "USER_CHAT_TEMPLATE = \"<start_of_turn> user \\n{prompt} <end_of_turn> \\n\"\n",
    "MODEL_CHAT_TEMPLATE = \"<start_of_turn> model\\n{prompt} <end_of_turn> \\n\"\n",
    "margin=2\n",
    "for i in range(0,len(Input),margin):\n",
    "    prompt = (\n",
    "        #用户说中国有哪些可以旅游的地方\n",
    "        USER_CHAT_TEMPLATE.format(\n",
    "            prompt=f\"你是一个厉害的小说家,请完成下面小说的创作,字数不少于1000字:{Input[i]},深呼吸,仔细思考,写出一篇精彩的小说。\"\n",
    "        )\n",
    "        #模型开始说\n",
    "        + \"<start_of_turn>model\\n\"\n",
    "    )\n",
    "    output = model.generate(\n",
    "        #用户说的提示词\n",
    "        USER_CHAT_TEMPLATE.format(prompt=prompt),\n",
    "        output_len=2048,\n",
    "        device=device)\n",
    "    for j in range(i,i+margin):\n",
    "        Output[j]=output\n",
    "    #字数太少会扣分\n",
    "    if len(output)<=800:\n",
    "        output=\"这是一个非常有趣的故事,且听我细细道来。\"+output\n",
    "    print(f\"{i} is ok,len(output):{len(output)}\")\n",
    "print(f\"Output[0]:{Output[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991ab62b",
   "metadata": {
    "papermill": {
     "duration": 0.044164,
     "end_time": "2024-06-20T20:46:53.653642",
     "exception": false,
     "start_time": "2024-06-20T20:46:53.609478",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 保存提交文件,这里需要命名为submit.json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8206d64e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T20:46:53.742385Z",
     "iopub.status.busy": "2024-06-20T20:46:53.741451Z",
     "iopub.status.idle": "2024-06-20T20:46:53.769569Z",
     "shell.execute_reply": "2024-06-20T20:46:53.768873Z"
    },
    "papermill": {
     "duration": 0.074513,
     "end_time": "2024-06-20T20:46:53.771485",
     "exception": false,
     "start_time": "2024-06-20T20:46:53.696972",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 创建一个列表，包含所有行的字典\n",
    "rows = []\n",
    "for i in range(len(Output)):\n",
    "    row = {\"instruction\": Instruction[i], \"input\": Input[i], \"output\": Output[i]}\n",
    "    rows.append(row)\n",
    "with open('submit.json', 'w') as f:\n",
    "    for item in rows:\n",
    "        # 将字典转换为JSON格式的字符串，并写入文件，每个对象占一行\n",
    "        f.write(json.dumps(item) + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5242416,
     "sourceId": 8733505,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelInstanceId": 5383,
     "sourceId": 11358,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30732,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 25838.256964,
   "end_time": "2024-06-20T20:46:55.087423",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-06-20T13:36:16.830459",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
