{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6687aec2",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.009126,
     "end_time": "2024-06-08T03:10:18.044108",
     "exception": false,
     "start_time": "2024-06-08T03:10:18.034982",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Created by <a href=\"https://github.com/yunsuxiaozi\">yunsuxiaozi</a> 2024/6/8\n",
    "\n",
    "#### 虽然在这场比赛中我的分数和排名都不算前排,但是我还是打算开源。一方面这是我个人比赛的记录,另一方面毕竟还有人在我后面,说不定我的方法能够帮到别人。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a852ba",
   "metadata": {
    "papermill": {
     "duration": 0.009148,
     "end_time": "2024-06-08T03:10:18.062422",
     "exception": false,
     "start_time": "2024-06-08T03:10:18.053274",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 导入常用的库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e70de5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T03:10:18.083263Z",
     "iopub.status.busy": "2024-06-08T03:10:18.082286Z",
     "iopub.status.idle": "2024-06-08T03:10:19.175501Z",
     "shell.execute_reply": "2024-06-08T03:10:19.174159Z"
    },
    "papermill": {
     "duration": 1.106866,
     "end_time": "2024-06-08T03:10:19.178617",
     "exception": false,
     "start_time": "2024-06-08T03:10:18.071751",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#necessary\n",
    "import pandas as pd#导入csv文件的库\n",
    "import numpy as np#进行矩阵运算的库\n",
    "import json#用于读取和写入json数据格式\n",
    "import re#用于正则表达式提取\n",
    "import fasttext#高效处理单词表示和句子分类的库\n",
    "import warnings#避免一些可以忽略的报错\n",
    "warnings.filterwarnings('ignore')#filterwarnings()方法是用于设置警告过滤器的方法，它可以控制警告信息的输出方式和级别。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edd23a9",
   "metadata": {
    "papermill": {
     "duration": 0.00826,
     "end_time": "2024-06-08T03:10:19.195613",
     "exception": false,
     "start_time": "2024-06-08T03:10:19.187353",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 参数解释\n",
    "\n",
    "- seed是随机种子。\n",
    "\n",
    "- topwords是根据词频统计选择title和abstract里最常见的100个词,可惜大多是停用词,其实应该根据比赛的背景来选择更合适的词。\n",
    "\n",
    "- country是作者组织所属的国家。\n",
    "\n",
    "- try_program就是一个测试程序是否跑通,如果为True就选择train和test里第一个author构造特征."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2648bac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T03:10:19.215433Z",
     "iopub.status.busy": "2024-06-08T03:10:19.214846Z",
     "iopub.status.idle": "2024-06-08T03:10:19.233302Z",
     "shell.execute_reply": "2024-06-08T03:10:19.231856Z"
    },
    "papermill": {
     "duration": 0.031822,
     "end_time": "2024-06-08T03:10:19.236628",
     "exception": false,
     "start_time": "2024-06-08T03:10:19.204806",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#config\n",
    "class Config():\n",
    "    seed=2024#随机种子\n",
    "    #这里是abstract和title出现最频繁的100个词\n",
    "    abstracttopwords=['the', 'of', 'and', 'in', 'to', 'a', 'is', 'with', 'for', 'that', 'by', 'on', 'was', 'this', 'are', 'we', 'were', 'as', 'from', 'an', 'be', 'at', 'can', 'which', 'results', 'or', 'using', 'based', 'has', 'have', 'between', 'it', 'method', 'patients', 'data', 'model', 'than', 'proposed', 'our', 'these', 'system', 'been', 'two', 'also', 'used', 'not', 'different', 'high', 'more', 'study', 'show', '=', 'both', 'into', 'new', 'its', 'control', 'cancer', 'analysis', 'performance', 'such', '2', 'their', 'after', 'paper', 'all', 'but', 'power', 'however,', 'one', 'algorithm', 'time', 'compared', 'may', 'cell', 'when', 'other', 'under', 'rate', 'paper,', 'energy', 'network', 'higher', 'each', 'expression', 'information', 'only', 'during', '1', 'significantly', 'most', 'surface', 'cells', 'approach', 'effect', '3', 'through', 'novel', 'low', 'group']\n",
    "    titletopwords=['of', 'and', 'in', 'for', 'the', 'a', 'on', 'with', 'by', 'based', 'to', 'from', 'study', 'cancer', 'analysis', 'using', 'an', 'system', 'method', 'patients', 'cell', 'control', 'model', 'systems', 'design', 'power', 'effect', 'phase', 'data', 'lung', 'networks', 'as', 'network', 'at', 'properties', 'detection', 'high', 'novel', 'application', 'its', 'learning', 'new', 'algorithm', 'research', 'carbon', 'via', 'image', 'treatment', 'effects', 'synthesis', 'performance', 'human', 'risk', 'between', 'structure', '2', 'energy', 'breast', 'approach', 'cells', 'surface', 'dynamic', 'expression', 'advanced', 'optimization', 'neural', 'clinical', 'efficient', 'is', 'wireless', 'evaluation', 'under', 'simulation', 'carcinoma', 'development', 'water', 'hybrid', 'films', 'growth', 'multiple', 'during', 'characteristics', 'therapy', 'cancer.', 'modeling', 'china', 'robust', 'after', 'optical', 'recognition', 'gene', '3d', 'distribution', 'estimation', 'process', 'molecular', 'low', 'characterization', 'through', 'or']\n",
    "    top=100#这里选择前100个词做词袋模型\n",
    "    #作者组织所属的国家: 中国,日本,法国,美国,瑞士,墨西哥,英国,奥地利,马来西亚,韩国,德国,加拿大\n",
    "    country=['china','japan','france','usa','switzerland','uk','germany','canada',\n",
    "   #澳大利亚,保加利亚,中国香港,美国,美国,新加坡,英国,葡萄牙,俄罗斯\n",
    "   'australia','hong kong','united states','u.s.a','singapore','united kingdom','russia'\n",
    "     ]\n",
    "    try_program=False#如果只是测试程序是否跑通的话,train_feats和valid_feats只用一个authorid\n",
    "import random#提供了一些用于生成随机数的函数\n",
    "#设置随机种子,保证模型可以复现\n",
    "def seed_everything(seed):\n",
    "    np.random.seed(seed)#numpy的随机种子\n",
    "    random.seed(seed)#python内置的随机种子\n",
    "seed_everything(Config.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330cc4ef",
   "metadata": {
    "papermill": {
     "duration": 0.008927,
     "end_time": "2024-06-08T03:10:19.254899",
     "exception": false,
     "start_time": "2024-06-08T03:10:19.245972",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 读取json数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2605a50d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T03:10:19.274277Z",
     "iopub.status.busy": "2024-06-08T03:10:19.273857Z",
     "iopub.status.idle": "2024-06-08T03:10:52.766812Z",
     "shell.execute_reply": "2024-06-08T03:10:52.765499Z"
    },
    "papermill": {
     "duration": 33.506231,
     "end_time": "2024-06-08T03:10:52.769912",
     "exception": false,
     "start_time": "2024-06-08T03:10:19.263681",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "path='/kaggle/input/'\n",
    "with open(path+\"2024kddcupwhoiswho/2024kddcupwhoiswho/train_author.json\") as f:\n",
    "    train_author=json.load(f)\n",
    "with open(path+\"2024kddcupwhoiswho/2024kddcupwhoiswho/pid_to_info_all.json\") as f:\n",
    "    pid_to_info=json.load(f)\n",
    "with open(path+\"2024kddcupwhoiswho/2024kddcupwhoiswho/ind_test_author_filter_public.json\") as f:\n",
    "    valid_author=json.load(f)\n",
    "with open(path+\"2024kddcupwhoiswho/2024kddcupwhoiswho/ind_test_author_filter_public.json\") as f:\n",
    "    submission=json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e16bbb0",
   "metadata": {
    "papermill": {
     "duration": 0.008432,
     "end_time": "2024-06-08T03:10:52.787278",
     "exception": false,
     "start_time": "2024-06-08T03:10:52.778846",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 文本可读性指数的函数,这个特征是在<a href=\"https://www.kaggle.com/code/yunsuxiaozi/writing-quality-top25-study-notebook-score-0-5651\">Linking Writing Process to Writing Quality</a>比赛中学到的,是top25solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6022ad93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T03:10:52.807255Z",
     "iopub.status.busy": "2024-06-08T03:10:52.806832Z",
     "iopub.status.idle": "2024-06-08T03:10:52.822617Z",
     "shell.execute_reply": "2024-06-08T03:10:52.821420Z"
    },
    "papermill": {
     "duration": 0.028843,
     "end_time": "2024-06-08T03:10:52.825394",
     "exception": false,
     "start_time": "2024-06-08T03:10:52.796551",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#文本的自动可读性指数 旨在衡量文本的可理解性.输出是理解课文所需的美国年级水平的近似表示.\n",
    "#https://www.nhooo.com/note/qa0tpe.html\n",
    "#初步理解:相同词数的情况下,句子越少,说明句子相对来说会很长,越长越不容易理解.words/sentence就会越大.\n",
    "#字符数相同的情况下,词数越多,单词越短,短的单词可能简单,所以就好理解.characters/words变小.\n",
    "#数值小就好理解,数值大就不好理解.具体的公式可能用数据做过实验得出?\n",
    "def ARI(txt):\n",
    "    if txt==None:\n",
    "        txt=\"q\"\n",
    "    characters=len(txt)\n",
    "    words=len(re.split(' |\\\\n|\\\\.|\\\\?|\\\\!|\\,',txt))#空格,换行符,句号,问号,感叹号,逗号分开.\n",
    "    sentence=len(re.split('\\\\.|\\\\?|\\\\!',txt))#句号,问号,感叹号分开的句子.\n",
    "    ari_score=4.71*(characters/words)+0.5*(words/sentence)-21.43\n",
    "    return ari_score\n",
    "\"\"\"\n",
    "http://www.supermagnus.com/mac/Word_Counter/index.html\n",
    "McAlpine EFLAW© Test\n",
    "     (W + SW) / S\n",
    "McAlpine EFLAW© Readability\n",
    "     Scale:\n",
    "     1-20: Easy\n",
    "     21-25: Quite Easy\n",
    "     26-29: Mildly Difficult\n",
    "     ≥ 30: Very Confusing\n",
    "     S:total sentences\n",
    "     W:total words\n",
    "\"\"\"\n",
    "def McAlpine_EFLAW(txt):\n",
    "    if txt==None:\n",
    "        txt=\"q\"\n",
    "    W=len(re.split(' |\\\\n|\\\\.|\\\\?|\\\\!|\\,',txt))#空格,换行符,句号,问号,感叹号,逗号分开.\n",
    "    S=len(re.split('\\\\.|\\\\?|\\\\!',txt))#句号,问号,感叹号分开的句子.\n",
    "    mcalpine_eflaw_score=(W+S*W)/S\n",
    "    return mcalpine_eflaw_score\n",
    "\"\"\"\n",
    "https://readable.com/readability/coleman-liau-readability-index/\n",
    "\n",
    "=0.0588*L-0.296*S-15.8\n",
    "L是每100个单词有多少个字母,S是平均每100个单词有多少句子.\n",
    "\"\"\"\n",
    "def CLRI(txt):\n",
    "    if txt==None:\n",
    "        txt=\"q\"\n",
    "    characters=len(txt)\n",
    "    words=len(re.split(' |\\\\n|\\\\.|\\\\?|\\\\!|\\,',txt))#空格,换行符,句号,问号,感叹号,逗号分开.\n",
    "    sentence=len(re.split('\\\\.|\\\\?|\\\\!',txt))#句号,问号,感叹号分开的句子.\n",
    "    L=100*characters/words\n",
    "    S=100*sentence/words\n",
    "    clri_score=0.0588*L-0.296*S-15.8\n",
    "    return clri_score\n",
    "\n",
    "#统计txt文本中出现find_word几次\n",
    "def calwordcnt(txt,find_word):\n",
    "    wordcnt=0\n",
    "    words=txt.split()\n",
    "    for word in words:\n",
    "        word=word.lower()\n",
    "        wordcnt+=int(word==find_word)\n",
    "    return wordcnt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e035f3",
   "metadata": {
    "papermill": {
     "duration": 0.009423,
     "end_time": "2024-06-08T03:10:52.843826",
     "exception": false,
     "start_time": "2024-06-08T03:10:52.834403",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 接下来就是训练数据和测试数据基本特征的构造,这里基本就是统计特征(mean,max,sum,std,median之类的)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6b2e45d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T03:10:52.865303Z",
     "iopub.status.busy": "2024-06-08T03:10:52.864863Z",
     "iopub.status.idle": "2024-06-08T03:27:38.188352Z",
     "shell.execute_reply": "2024-06-08T03:27:38.186747Z"
    },
    "papermill": {
     "duration": 1005.338465,
     "end_time": "2024-06-08T03:27:38.192059",
     "exception": false,
     "start_time": "2024-06-08T03:10:52.853594",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(columns):279\n",
      "train_feats.shape:(148309, 279),labels.shape:(148309,)\n",
      "np.mean(labels):0.8834527911320283\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authorid</th>\n",
       "      <th>person_id</th>\n",
       "      <th>essay_id</th>\n",
       "      <th>title_len</th>\n",
       "      <th>title_wordcount</th>\n",
       "      <th>title_ari</th>\n",
       "      <th>title_McAlpine_EFLAW</th>\n",
       "      <th>title_CLRI</th>\n",
       "      <th>title_word_maxlen</th>\n",
       "      <th>title_word_medianlen</th>\n",
       "      <th>...</th>\n",
       "      <th>abstract_top92</th>\n",
       "      <th>abstract_top93</th>\n",
       "      <th>abstract_top94</th>\n",
       "      <th>abstract_top95</th>\n",
       "      <th>abstract_top96</th>\n",
       "      <th>abstract_top97</th>\n",
       "      <th>abstract_top98</th>\n",
       "      <th>abstract_top99</th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Iki037dt</td>\n",
       "      <td>YzOCpPTO</td>\n",
       "      <td>120</td>\n",
       "      <td>18</td>\n",
       "      <td>18.970000000000006</td>\n",
       "      <td>36.0</td>\n",
       "      <td>21.75555555555555</td>\n",
       "      <td>14</td>\n",
       "      <td>4.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Iki037dt</td>\n",
       "      <td>AblgcGjH</td>\n",
       "      <td>123</td>\n",
       "      <td>15</td>\n",
       "      <td>21.148235294117647</td>\n",
       "      <td>34.0</td>\n",
       "      <td>25.002352941176465</td>\n",
       "      <td>12</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Iki037dt</td>\n",
       "      <td>B5aouLse</td>\n",
       "      <td>100</td>\n",
       "      <td>13</td>\n",
       "      <td>15.712857142857146</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.97142857142857</td>\n",
       "      <td>14</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Iki037dt</td>\n",
       "      <td>u1G7wBEv</td>\n",
       "      <td>103</td>\n",
       "      <td>14</td>\n",
       "      <td>20.222142857142856</td>\n",
       "      <td>28.0</td>\n",
       "      <td>25.345714285714283</td>\n",
       "      <td>11</td>\n",
       "      <td>6.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Iki037dt</td>\n",
       "      <td>W7w6P8lA</td>\n",
       "      <td>133</td>\n",
       "      <td>14</td>\n",
       "      <td>24.082</td>\n",
       "      <td>22.5</td>\n",
       "      <td>32.389333333333326</td>\n",
       "      <td>20</td>\n",
       "      <td>7.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 280 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  authorid person_id  essay_id title_len title_wordcount           title_ari  \\\n",
       "0        0  Iki037dt  YzOCpPTO       120              18  18.970000000000006   \n",
       "1        0  Iki037dt  AblgcGjH       123              15  21.148235294117647   \n",
       "2        0  Iki037dt  B5aouLse       100              13  15.712857142857146   \n",
       "3        0  Iki037dt  u1G7wBEv       103              14  20.222142857142856   \n",
       "4        0  Iki037dt  W7w6P8lA       133              14              24.082   \n",
       "\n",
       "  title_McAlpine_EFLAW          title_CLRI title_word_maxlen  \\\n",
       "0                 36.0   21.75555555555555                14   \n",
       "1                 34.0  25.002352941176465                12   \n",
       "2                 21.0   21.97142857142857                14   \n",
       "3                 28.0  25.345714285714283                11   \n",
       "4                 22.5  32.389333333333326                20   \n",
       "\n",
       "  title_word_medianlen  ... abstract_top92 abstract_top93 abstract_top94  \\\n",
       "0                  4.5  ...              0              0              0   \n",
       "1                  8.0  ...              0              0              0   \n",
       "2                  7.0  ...              0              0              0   \n",
       "3                  6.5  ...              0              0              0   \n",
       "4                  7.5  ...              0              0              0   \n",
       "\n",
       "  abstract_top95 abstract_top96 abstract_top97 abstract_top98 abstract_top99  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "  category label  \n",
       "0        0     1  \n",
       "1        0     1  \n",
       "2        9     1  \n",
       "3        0     1  \n",
       "4        9     1  \n",
       "\n",
       "[5 rows x 280 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 加载之前保存的模型\n",
    "model = fasttext.load_model('/kaggle/input/fasttext-essay-category-80/fasttext_arxivcategory.model')\n",
    "columns=['authorid',#第几个论文作者\n",
    "         #这个人发表过多少篇论文,这篇论文是有几条数据\n",
    "         'person_id','essay_id',\n",
    "          #标题的长度,标题的词数,文本可读性指数\n",
    "         'title_len','title_wordcount','title_ari','title_McAlpine_EFLAW','title_CLRI',\n",
    "         #标题词长度的统计特征\n",
    "         'title_word_maxlen','title_word_medianlen','title_word_meanlen','title_word_stdlen','title_word_sumlen',\n",
    "         #论文的作者数,作者的组织数\n",
    "         'author_count',\n",
    "         'china','japan','france','usa','switzerland','uk','germany','canada',\n",
    "          #澳大利亚,保加利亚,中国香港,美国,美国,新加坡,英国,葡萄牙,俄罗斯\n",
    "         'australia','hong kong','united states','u.s.a','singapore','united kingdom','russia',\n",
    "         'author_org_count',\n",
    "         #作者组织的长度\n",
    "         'max_orgs_len','median_orgs_len','mean_orgs_len','std_orgs_len','sum_orgs_len',\n",
    "         #作者组织的词长度统计\n",
    "         'max_orgs_wordcnt','median_orgs_wordcnt','mean_orgs_wordcnt','std_orgs_wordcnt','sum_orgs_wordcnt',\n",
    "         #摘要的文本可读性指数\n",
    "         'abs_ari','abs_McAlpine_EFLAW','abs_CLRI',\n",
    "         #摘要长度,摘要词数,摘要的句子数\n",
    "         'abs_len','abs_wordcount','abs_sentenece_count',\n",
    "         #摘要里词长度的统计特征\n",
    "         'max_abs_wordlen','median_abs_wordlen','mean_abs_wordlen','std_abs_wordlen','sum_abs_wordlen',\n",
    "         #摘要里句子长度的统计特征\n",
    "         'max_abs_sentencelen','median_abs_sentencelen','mean_abs_sentencelen','std_abs_sentencelen','sum_abs_sentencelen',\n",
    "         #摘要里句子词数的统计特征\n",
    "         'max_abs_senwordcnt','median_abs_senwordcnt','mean_abs_senwordcnt','std_abs_senwordcnt','sum_abs_senwordcnt',\n",
    "         #关键词个数,所有关键词的长度和\n",
    "         'keywords_count','keywords_len_sum',\n",
    "         #关键词的特征统计\n",
    "         'keywords_len_max','keywords_len_median','keywords_len_mean','keywords_len_std',\n",
    "         #地点的长度和词数,词长度统计\n",
    "        'venue_len','venue_wordcount','venue_maxwordlen','venue_medianwordlen','venue_meanwordlen','venue_stdwordlen','venue_sumwordlen',\n",
    "         #地点的文本可读性指数\n",
    "         'venue_ari','venue_McAlpine_EFLAW','venue_CLRI',\n",
    "         #年份\n",
    "        'year',\n",
    "        #统计title前100个词\n",
    "        'title_top0', 'title_top1', 'title_top2', 'title_top3', 'title_top4', \n",
    "         'title_top5', 'title_top6', 'title_top7', 'title_top8', 'title_top9', \n",
    "         'title_top10', 'title_top11', 'title_top12', 'title_top13', 'title_top14', \n",
    "         'title_top15', 'title_top16', 'title_top17', 'title_top18', 'title_top19',\n",
    "         'title_top20', 'title_top21', 'title_top22', 'title_top23', 'title_top24',\n",
    "         'title_top25', 'title_top26', 'title_top27', 'title_top28', 'title_top29', \n",
    "         'title_top30', 'title_top31', 'title_top32', 'title_top33', 'title_top34', \n",
    "         'title_top35', 'title_top36', 'title_top37', 'title_top38', 'title_top39',\n",
    "         'title_top40', 'title_top41', 'title_top42', 'title_top43', 'title_top44',\n",
    "         'title_top45', 'title_top46', 'title_top47', 'title_top48', 'title_top49',\n",
    "         'title_top50', 'title_top51', 'title_top52', 'title_top53', 'title_top54', \n",
    "         'title_top55', 'title_top56', 'title_top57', 'title_top58', 'title_top59', \n",
    "         'title_top60', 'title_top61', 'title_top62', 'title_top63', 'title_top64', \n",
    "         'title_top65', 'title_top66', 'title_top67', 'title_top68', 'title_top69', \n",
    "         'title_top70', 'title_top71', 'title_top72', 'title_top73', 'title_top74',\n",
    "         'title_top75', 'title_top76', 'title_top77', 'title_top78', 'title_top79',\n",
    "         'title_top80', 'title_top81', 'title_top82', 'title_top83', 'title_top84',\n",
    "         'title_top85', 'title_top86', 'title_top87', 'title_top88', 'title_top89', \n",
    "         'title_top90', 'title_top91', 'title_top92', 'title_top93', 'title_top94', \n",
    "         'title_top95', 'title_top96', 'title_top97', 'title_top98', 'title_top99',\n",
    "         #统计abstract的前100个词\n",
    "         'abstract_top0', 'abstract_top1', 'abstract_top2', 'abstract_top3', 'abstract_top4',\n",
    "         'abstract_top5', 'abstract_top6', 'abstract_top7', 'abstract_top8', 'abstract_top9',\n",
    "         'abstract_top10', 'abstract_top11', 'abstract_top12', 'abstract_top13', 'abstract_top14',\n",
    "         'abstract_top15', 'abstract_top16', 'abstract_top17', 'abstract_top18', 'abstract_top19',\n",
    "         'abstract_top20', 'abstract_top21', 'abstract_top22', 'abstract_top23', 'abstract_top24', \n",
    "         'abstract_top25', 'abstract_top26', 'abstract_top27', 'abstract_top28', 'abstract_top29', \n",
    "         'abstract_top30', 'abstract_top31', 'abstract_top32', 'abstract_top33', 'abstract_top34', \n",
    "         'abstract_top35', 'abstract_top36', 'abstract_top37', 'abstract_top38', 'abstract_top39',\n",
    "         'abstract_top40', 'abstract_top41', 'abstract_top42', 'abstract_top43', 'abstract_top44',\n",
    "         'abstract_top45', 'abstract_top46', 'abstract_top47', 'abstract_top48', 'abstract_top49', \n",
    "         'abstract_top50', 'abstract_top51', 'abstract_top52', 'abstract_top53', 'abstract_top54', \n",
    "         'abstract_top55', 'abstract_top56', 'abstract_top57', 'abstract_top58', 'abstract_top59',\n",
    "         'abstract_top60', 'abstract_top61', 'abstract_top62', 'abstract_top63', 'abstract_top64',\n",
    "         'abstract_top65', 'abstract_top66', 'abstract_top67', 'abstract_top68', 'abstract_top69', \n",
    "         'abstract_top70', 'abstract_top71', 'abstract_top72', 'abstract_top73', 'abstract_top74',\n",
    "         'abstract_top75', 'abstract_top76', 'abstract_top77', 'abstract_top78', 'abstract_top79', \n",
    "         'abstract_top80', 'abstract_top81', 'abstract_top82', 'abstract_top83', 'abstract_top84', \n",
    "         'abstract_top85', 'abstract_top86', 'abstract_top87', 'abstract_top88', 'abstract_top89', \n",
    "         'abstract_top90', 'abstract_top91', 'abstract_top92', 'abstract_top93', 'abstract_top94', \n",
    "         'abstract_top95', 'abstract_top96', 'abstract_top97', 'abstract_top98', 'abstract_top99',\n",
    "         #根据摘要预测论文的学科类别\n",
    "         'category'\n",
    "        ]\n",
    "print(f\"len(columns):{len(columns)}\")\n",
    "idx2col={}\n",
    "for i in range(len(columns)):\n",
    "    idx2col[i]=columns[i]\n",
    "train_feats=[]\n",
    "labels=[]\n",
    "authorid=0#第几个论文作者\n",
    "for id,person_info in train_author.items():\n",
    "    for data in ['normal_data','outliers']:\n",
    "        for text_id in person_info[data]:#正样本\n",
    "            feat=pid_to_info[text_id]\n",
    "            train_feat=[authorid,id,feat['id']]\n",
    "            #这里正式开始认真做特征工程 设置哪些列,具体如何构造特征\n",
    "            #columns=[‘title_len’,'title_wordcount']\n",
    "            train_feat+=[len(feat['title'])]\n",
    "            title_word=feat['title'].split(\" \")\n",
    "            title_word_len=[len(word) for word in title_word]\n",
    "            train_feat+=[len(title_word_len),ARI(feat['title']),McAlpine_EFLAW(feat['title']),CLRI(feat['title']),\n",
    "                         np.max(title_word_len),np.median(title_word_len),np.mean(title_word_len),np.std(title_word_len),np.sum(title_word_len)]\n",
    "\n",
    "            #columns=['author_count','author_org_count']\n",
    "            train_feat+=[len(feat['authors'])]\n",
    "            #作者所属的组织的国家\n",
    "            country_cnt=[0 for i in range(len(Config.country))]\n",
    "            for author_dict in feat['authors']:\n",
    "                for i in range(len(Config.country)):\n",
    "                    country_cnt[i]+=int(Config.country[i] in author_dict['org'].lower())\n",
    "            train_feat+=country_cnt\n",
    "            \n",
    "            orgs=[]\n",
    "            for org_dict in feat['authors']:\n",
    "                org=org_dict['org']\n",
    "                if org not in orgs:\n",
    "                    orgs.append(org)\n",
    "            train_feat+=[len(orgs)]\n",
    "            #组织名的长度\n",
    "            orgs_len=[len(org) for org in orgs]\n",
    "            #组织名的词数\n",
    "            orgs_wordcnt=[len(org.split()) for org in orgs]\n",
    "            try:\n",
    "                #组织名长度的统计特征\n",
    "                train_feat+=[np.max(orgs_len),np.median(orgs_len),np.mean(orgs_len),\n",
    "                             np.std(orgs_len),np.sum(orgs_len)]\n",
    "            except:\n",
    "                train_feat+=[np.nan,np.nan,np.nan,np.nan,np.nan]\n",
    "            try:\n",
    "                #组织名词数的统计特征\n",
    "                train_feat+=[np.max(orgs_wordcnt),np.median(orgs_wordcnt),np.mean(orgs_wordcnt),\n",
    "                             np.std(orgs_wordcnt),np.sum(orgs_wordcnt)]\n",
    "            except:\n",
    "                train_feat+=[np.nan,np.nan,np.nan,np.nan,np.nan]\n",
    "            \n",
    "            train_feat+=[ARI(feat['abstract']),McAlpine_EFLAW(feat['abstract']),CLRI(feat['abstract'])]\n",
    "            \n",
    "            #columns=['abstract_len','abstract_wordcount','abstract_sentenece_count']\n",
    "            words=feat['abstract'].split()\n",
    "            sentences=feat['abstract'].split(\".\")\n",
    "            train_feat+=[len(feat['abstract']),len(words),len(sentences)]\n",
    "            wordlen=[len(word) for word in words]\n",
    "            #摘要里词长度的统计特征\n",
    "            try:\n",
    "                train_feat+=[np.max(wordlen),np.median(wordlen),np.mean(wordlen),\n",
    "                             np.std(wordlen),np.sum(wordlen)]\n",
    "            except:\n",
    "                train_feat+=[np.nan,np.nan,np.nan,np.nan,np.nan]\n",
    "            #摘要里句子长度的统计特征\n",
    "            sentencelen=[len(sentence) for sentence in sentences]\n",
    "            try:\n",
    "                train_feat+=[np.max(sentencelen),np.median(sentencelen),np.mean(sentencelen),\n",
    "                             np.std(sentencelen),np.sum(sentencelen)]\n",
    "            except:\n",
    "                train_feat+=[np.nan,np.nan,np.nan,np.nan,np.nan]\n",
    "                \n",
    "            #摘要里句子词数的统计特征\n",
    "            sentencewordcnt=[len(sentence.split()) for sentence in sentences]\n",
    "            try:\n",
    "                train_feat+=[np.max(sentencewordcnt),np.median(sentencewordcnt),np.mean(sentencewordcnt),\n",
    "                             np.std(sentencewordcnt),np.sum(sentencewordcnt)]\n",
    "            except:\n",
    "                train_feat+=[np.nan,np.nan,np.nan,np.nan,np.nan]\n",
    "            \n",
    "            #columns=['keywords_count',keywords_len_sum]\n",
    "            len_keyword=np.array([len(word) for word in feat['keywords']])\n",
    "            try:\n",
    "                train_feat+=[len(feat['keywords']),np.sum(len_keyword),np.max(len_keyword),\n",
    "                             np.median(len_keyword),np.mean(len_keyword),np.std(len_keyword)]\n",
    "            except:\n",
    "                train_feat+=[len(feat['keywords']),np.sum(len_keyword),np.nan,np.nan,np.nan,np.nan]\n",
    "           \n",
    "            #columns=['venue_len','venue_wordcount']\n",
    "            try:\n",
    "                train_feat+=[len(feat['venue'])]\n",
    "                venue_word=feat['venue'].split(\" \")\n",
    "                venue_wordlen=[len(word)for word in venue_word]\n",
    "                train_feat+=[len(venue_wordlen),np.max(venue_wordlen),np.median(venue_wordlen),\n",
    "                             np.mean(venue_wordlen),np.std(venue_wordlen),np.sum(venue_wordlen)]\n",
    "            except:\n",
    "                train_feat+=[0]\n",
    "                train_feat+=[np.nan,np.nan,np.nan,np.nan,np.nan,np.nan]\n",
    "                \n",
    "            train_feat+=[ARI(feat['venue']),McAlpine_EFLAW(feat['venue']),CLRI(feat['venue'])]\n",
    "            \n",
    "            #columns=['year']\n",
    "            try:\n",
    "                train_feat+=[int(feat['year'])]\n",
    "            except:\n",
    "                train_feat+=[np.nan]\n",
    "                \n",
    "            #词袋模型\n",
    "            for top in range(Config.top):\n",
    "                train_feat+=[calwordcnt(feat['title'],Config.titletopwords[top])]\n",
    "            for top in range(Config.top):\n",
    "                train_feat+=[calwordcnt(feat['abstract'],Config.abstracttopwords[top])]        \n",
    "            #fasttext预测的论文的学科类别\n",
    "            train_feat+=[int(model.predict(feat['abstract'].replace('\\n', ''),k=len(model.labels))[0][0][9:])]\n",
    "                \n",
    "            train_feats.append(train_feat)\n",
    "            labels.append(int(data=='normal_data'))\n",
    "    authorid+=1\n",
    "    if Config.try_program:\n",
    "        break\n",
    "train_feats=np.array(train_feats)\n",
    "labels=np.array(labels)\n",
    "print(f\"train_feats.shape:{train_feats.shape},labels.shape:{labels.shape}\")\n",
    "print(f\"np.mean(labels):{np.mean(labels)}\")\n",
    "train_feats=pd.DataFrame(train_feats)\n",
    "train_feats=train_feats.rename(columns=idx2col)\n",
    "\n",
    "train_feats['label']=labels\n",
    "train_feats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95dd318c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T03:27:38.214439Z",
     "iopub.status.busy": "2024-06-08T03:27:38.213997Z",
     "iopub.status.idle": "2024-06-08T03:40:49.209605Z",
     "shell.execute_reply": "2024-06-08T03:40:49.208273Z"
    },
    "papermill": {
     "duration": 791.010493,
     "end_time": "2024-06-08T03:40:49.212472",
     "exception": false,
     "start_time": "2024-06-08T03:27:38.201979",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_feats.shape:(116262, 279)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authorid</th>\n",
       "      <th>person_id</th>\n",
       "      <th>essay_id</th>\n",
       "      <th>title_len</th>\n",
       "      <th>title_wordcount</th>\n",
       "      <th>title_ari</th>\n",
       "      <th>title_McAlpine_EFLAW</th>\n",
       "      <th>title_CLRI</th>\n",
       "      <th>title_word_maxlen</th>\n",
       "      <th>title_word_medianlen</th>\n",
       "      <th>...</th>\n",
       "      <th>abstract_top91</th>\n",
       "      <th>abstract_top92</th>\n",
       "      <th>abstract_top93</th>\n",
       "      <th>abstract_top94</th>\n",
       "      <th>abstract_top95</th>\n",
       "      <th>abstract_top96</th>\n",
       "      <th>abstract_top97</th>\n",
       "      <th>abstract_top98</th>\n",
       "      <th>abstract_top99</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Fkb16wn7</td>\n",
       "      <td>0DchSY2n</td>\n",
       "      <td>79</td>\n",
       "      <td>11</td>\n",
       "      <td>12.577499999999993</td>\n",
       "      <td>18.0</td>\n",
       "      <td>17.97666666666667</td>\n",
       "      <td>13</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Fkb16wn7</td>\n",
       "      <td>0Gw6iDes</td>\n",
       "      <td>51</td>\n",
       "      <td>7</td>\n",
       "      <td>16.385714285714286</td>\n",
       "      <td>14.0</td>\n",
       "      <td>22.811428571428568</td>\n",
       "      <td>10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Fkb16wn7</td>\n",
       "      <td>0PgoDSAP</td>\n",
       "      <td>40</td>\n",
       "      <td>6</td>\n",
       "      <td>7.234285714285715</td>\n",
       "      <td>10.5</td>\n",
       "      <td>9.342857142857145</td>\n",
       "      <td>10</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Fkb16wn7</td>\n",
       "      <td>0S7g2B2l</td>\n",
       "      <td>74</td>\n",
       "      <td>9</td>\n",
       "      <td>15.924</td>\n",
       "      <td>15.0</td>\n",
       "      <td>21.791999999999998</td>\n",
       "      <td>14</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Fkb16wn7</td>\n",
       "      <td>0YJjxtdf</td>\n",
       "      <td>52</td>\n",
       "      <td>7</td>\n",
       "      <td>11.184999999999995</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15.02</td>\n",
       "      <td>11</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 279 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  authorid person_id  essay_id title_len title_wordcount           title_ari  \\\n",
       "0        0  Fkb16wn7  0DchSY2n        79              11  12.577499999999993   \n",
       "1        0  Fkb16wn7  0Gw6iDes        51               7  16.385714285714286   \n",
       "2        0  Fkb16wn7  0PgoDSAP        40               6   7.234285714285715   \n",
       "3        0  Fkb16wn7  0S7g2B2l        74               9              15.924   \n",
       "4        0  Fkb16wn7  0YJjxtdf        52               7  11.184999999999995   \n",
       "\n",
       "  title_McAlpine_EFLAW          title_CLRI title_word_maxlen  \\\n",
       "0                 18.0   17.97666666666667                13   \n",
       "1                 14.0  22.811428571428568                10   \n",
       "2                 10.5   9.342857142857145                10   \n",
       "3                 15.0  21.791999999999998                14   \n",
       "4                 12.0               15.02                11   \n",
       "\n",
       "  title_word_medianlen  ... abstract_top91 abstract_top92 abstract_top93  \\\n",
       "0                  6.0  ...              0              0              1   \n",
       "1                  5.0  ...              0              0              0   \n",
       "2                  6.0  ...              0              0              2   \n",
       "3                  7.0  ...              0              0              0   \n",
       "4                  6.0  ...              0              0              0   \n",
       "\n",
       "  abstract_top94 abstract_top95 abstract_top96 abstract_top97 abstract_top98  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              1              0   \n",
       "3              0              0              0              1              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "  abstract_top99 category  \n",
       "0              0        0  \n",
       "1              0        0  \n",
       "2              0        0  \n",
       "3              0        0  \n",
       "4              0        0  \n",
       "\n",
       "[5 rows x 279 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_feats=[]\n",
    "authorid=0\n",
    "for id,person_info in valid_author.items():\n",
    "    for text_id in person_info['papers']:\n",
    "        feat=pid_to_info[text_id]\n",
    "        valid_feat=[authorid,id,feat['id']]\n",
    "        #这里正式开始认真做特征工程 设置哪些列,具体如何构造特征\n",
    "        #columns=[‘title_len’,'title_wordcount','title_word_maxlen','title_word_meanlen']\n",
    "        valid_feat+=[len(feat['title'])]\n",
    "        title_word=feat['title'].split(\" \")\n",
    "        title_word_len=[len(word) for word in title_word]\n",
    "        valid_feat+=[len(title_word_len),ARI(feat['title']),McAlpine_EFLAW(feat['title']),CLRI(feat['title']),\n",
    "                     np.max(title_word_len),np.median(title_word_len),np.mean(title_word_len),np.std(title_word_len),np.sum(title_word_len)]\n",
    "      \n",
    "        #columns=['author_count','author_org_count']\n",
    "        valid_feat+=[len(feat['authors'])]\n",
    "        \n",
    "        #作者所属的组织的国家\n",
    "        country_cnt=[0 for i in range(len(Config.country))]\n",
    "        for author_dict in feat['authors']:\n",
    "            for i in range(len(Config.country)):\n",
    "                country_cnt[i]+=int(Config.country[i] in author_dict['org'].lower())\n",
    "        valid_feat+=country_cnt\n",
    "        \n",
    "        orgs=[]\n",
    "        for org_dict in feat['authors']:\n",
    "            org=org_dict['org']\n",
    "            if org not in orgs:\n",
    "                orgs.append(org)\n",
    "        valid_feat+=[len(orgs)]\n",
    "        #组织名的长度\n",
    "        orgs_len=[len(org) for org in orgs]\n",
    "        #组织名的词数\n",
    "        orgs_wordcnt=[len(org.split()) for org in orgs]\n",
    "        try:\n",
    "            #组织名长度的统计特征\n",
    "            valid_feat+=[np.max(orgs_len),np.median(orgs_len),np.mean(orgs_len),\n",
    "                         np.std(orgs_len),np.sum(orgs_len)]\n",
    "        except:\n",
    "            valid_feat+=[np.nan,np.nan,np.nan,np.nan,np.nan]\n",
    "        try:\n",
    "            #组织名词数的统计特征\n",
    "            valid_feat+=[np.max(orgs_wordcnt),np.median(orgs_wordcnt),np.mean(orgs_wordcnt),\n",
    "                         np.std(orgs_wordcnt),np.sum(orgs_wordcnt)]\n",
    "        except:\n",
    "            valid_feat+=[np.nan,np.nan,np.nan,np.nan,np.nan]\n",
    "        valid_feat+=[ARI(feat['abstract']),McAlpine_EFLAW(feat['abstract']),CLRI(feat['abstract'])]\n",
    "\n",
    "        words=feat['abstract'].split()\n",
    "        sentences=feat['abstract'].split(\".\")\n",
    "        valid_feat+=[len(feat['abstract']),len(words),len(sentences)]\n",
    "        wordlen=[len(word) for word in words]\n",
    "        #摘要里词长度的统计特征\n",
    "        try:\n",
    "            valid_feat+=[np.max(wordlen),np.median(wordlen),np.mean(wordlen),\n",
    "                         np.std(wordlen),np.sum(wordlen)]\n",
    "        except:\n",
    "            valid_feat+=[np.nan,np.nan,np.nan,np.nan,np.nan]\n",
    "        #摘要里句子长度的统计特征\n",
    "        sentencelen=[len(sentence) for sentence in sentences]\n",
    "        try:\n",
    "            valid_feat+=[np.max(sentencelen),np.median(sentencelen),np.mean(sentencelen),\n",
    "                         np.std(sentencelen),np.sum(sentencelen)]\n",
    "        except:\n",
    "            valid_feat+=[np.nan,np.nan,np.nan,np.nan,np.nan]\n",
    "\n",
    "        #摘要里句子词数的统计特征\n",
    "        sentencewordcnt=[len(sentence.split()) for sentence in sentences]\n",
    "        try:\n",
    "            valid_feat+=[np.max(sentencewordcnt),np.median(sentencewordcnt),np.mean(sentencewordcnt),\n",
    "                         np.std(sentencewordcnt),np.sum(sentencewordcnt)]\n",
    "        except:\n",
    "            valid_feat+=[np.nan,np.nan,np.nan,np.nan,np.nan]\n",
    "       \n",
    "        #columns=['keywords_count',keywords_len_sum]\n",
    "        len_keyword=np.array([len(word) for word in feat['keywords']])\n",
    "        try:\n",
    "            valid_feat+=[len(feat['keywords']),np.sum(len_keyword),np.max(len_keyword),\n",
    "                         np.median(len_keyword),np.mean(len_keyword),np.std(len_keyword)]\n",
    "        except:\n",
    "            valid_feat+=[len(feat['keywords']),np.sum(len_keyword),np.nan,np.nan,np.nan,np.nan]\n",
    "        #columns=['venue_len','venue_wordcount']\n",
    "        try:\n",
    "            valid_feat+=[len(feat['venue'])]\n",
    "            venue_word=feat['venue'].split(\" \")\n",
    "            venue_wordlen=[len(word)for word in venue_word]\n",
    "            valid_feat+=[len(venue_wordlen),np.max(venue_wordlen),np.median(venue_wordlen),\n",
    "                         np.mean(venue_wordlen),np.std(venue_wordlen),np.sum(venue_wordlen)]\n",
    "        except:\n",
    "            valid_feat+=[0]\n",
    "            valid_feat+=[np.nan,np.nan,np.nan,np.nan,np.nan,np.nan]\n",
    "        \n",
    "        valid_feat+=[ARI(feat['venue']),McAlpine_EFLAW(feat['venue']),CLRI(feat['venue'])]\n",
    "        #columns=['year']\n",
    "        try:\n",
    "            valid_feat+=[int(feat['year'])]\n",
    "        except:\n",
    "            valid_feat+=[np.nan]\n",
    "            \n",
    "        #词袋模型\n",
    "        for top in range(Config.top):\n",
    "            valid_feat+=[calwordcnt(feat['title'],Config.titletopwords[top])]\n",
    "        for top in range(Config.top):\n",
    "            valid_feat+=[calwordcnt(feat['abstract'],Config.abstracttopwords[top])]   \n",
    "        \n",
    "        #fasttext预测的论文的学科类别\n",
    "        valid_feat+=[int(model.predict(feat['abstract'].replace('\\n', ''),k=len(model.labels))[0][0][9:])]       \n",
    "        \n",
    "        valid_feats.append(valid_feat)\n",
    "    authorid+=1   \n",
    "    if Config.try_program:\n",
    "        break\n",
    "valid_feats=np.array(valid_feats)\n",
    "print(f\"valid_feats.shape:{valid_feats.shape}\")\n",
    "valid_feats=pd.DataFrame(valid_feats)\n",
    "valid_feats=valid_feats.rename(columns=idx2col)\n",
    "\n",
    "valid_feats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9b3b9a",
   "metadata": {
    "papermill": {
     "duration": 0.009974,
     "end_time": "2024-06-08T03:40:49.232820",
     "exception": false,
     "start_time": "2024-06-08T03:40:49.222846",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 接下来有构造一些联合特征,对异常值进行处理,更多的是对每个author的group特征."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1df62ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T03:40:49.256534Z",
     "iopub.status.busy": "2024-06-08T03:40:49.256074Z",
     "iopub.status.idle": "2024-06-08T05:13:14.504919Z",
     "shell.execute_reply": "2024-06-08T05:13:14.503053Z"
    },
    "papermill": {
     "duration": 5545.266052,
     "end_time": "2024-06-08T05:13:14.509288",
     "exception": false,
     "start_time": "2024-06-08T03:40:49.243236",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def feature_engineer(df):\n",
    "    for col in columns:\n",
    "        if col not in ['person_id','essay_id']:\n",
    "            if col in df.columns:\n",
    "                df[col]=df[col].astype(float)\n",
    "    df['mean_abstract_sentence_wordcount']=df['abs_wordcount']/df['abs_sentenece_count']\n",
    "    df['mean_org_author_count']=df['author_count']/df['author_org_count']\n",
    "    df['mean_title_wordlen']=df['title_len']/df['title_wordcount']\n",
    "    df['mean_venue_wordlen']=df['venue_len']/df['venue_wordcount']\n",
    "    df['total_len']=df['title_len']+df['abs_len']+df['venue_len']\n",
    "    \n",
    "    #2024年没有过完,论文数据较少,故换成2023年\n",
    "    df['year'] = df['year'].replace(2024, 2023)\n",
    "    #0应该是异常值,故换成np.nan\n",
    "    df['year'] = df['year'].replace(0, np.nan)\n",
    "    \n",
    "    \n",
    "    #title_len缺失值用均值4.5来代替,对title_len异常值的修正\n",
    "    df.loc[df['title_len']==np.expm1(0), 'title_len'] = np.expm1(4.5)\n",
    "    df.loc[df['title_len']<=np.expm1(3), 'title_len'] = np.expm1(3)\n",
    "    df.loc[df['title_len']>=np.expm1(6), 'title_len'] = np.expm1(6)\n",
    "    \n",
    "    #abs_len缺失值用均值7来代替,对abs_len异常值的修正\n",
    "    df.loc[df['abs_len']==np.expm1(0), 'abs_len'] = np.expm1(7)\n",
    "    df.loc[df['abs_len']<=np.expm1(3), 'abs_len'] = np.expm1(3)\n",
    "    df.loc[df['abs_len']>=np.expm1(9), 'abs_len'] = np.expm1(9)\n",
    "    \n",
    "    #venue_len缺失值用均值3.25来代替,对venue_len异常值的修正\n",
    "    df.loc[df['venue_len']==np.expm1(0), 'venue_len'] = np.expm1(3.25)\n",
    "    df.loc[df['venue_len']<=np.expm1(1.1), 'venue_len'] = np.expm1(1.1)\n",
    "    df.loc[df['venue_len']>=np.expm1(5.5), 'venue_len'] = np.expm1(5.5)\n",
    "    \n",
    "    for i in range(14):\n",
    "        df[f'category_{i}']=(df['category']==i)\n",
    "        \n",
    "    for col in columns+[f'category_{i}' for i in range(14)]:\n",
    "        if col not in ['authorid','person_id','essay_id']:\n",
    "            if col in df.columns:\n",
    "                person_col=df[col].groupby(df['person_id']).sum().reset_index()\n",
    "                person_col=person_col.rename(columns={col:f'sum_{col}'})\n",
    "                df=df.merge(person_col,on='person_id',how='left')\n",
    "\n",
    "\n",
    "                person_col=df[col].groupby(df['person_id']).mean().reset_index()\n",
    "                person_col=person_col.rename(columns={col:f'mean_{col}'})\n",
    "                df=df.merge(person_col,on='person_id',how='left')\n",
    "\n",
    "                person_col=df[col].groupby(df['person_id']).median().reset_index()\n",
    "                person_col=person_col.rename(columns={col:f'median_{col}'})\n",
    "                df=df.merge(person_col,on='person_id',how='left')\n",
    "\n",
    "                person_col=df[col].groupby(df['person_id']).skew().reset_index()\n",
    "                person_col=person_col.rename(columns={col:f'skew_{col}'})\n",
    "                df=df.merge(person_col,on='person_id',how='left')\n",
    "\n",
    "                person_col=df[col].groupby(df['person_id']).max().reset_index()\n",
    "                person_col=person_col.rename(columns={col:f'max_{col}'})\n",
    "                df=df.merge(person_col,on='person_id',how='left')\n",
    "\n",
    "                person_col=df[col].groupby(df['person_id']).std().reset_index()\n",
    "                person_col=person_col.rename(columns={col:f'std_{col}'})\n",
    "                df=df.merge(person_col,on='person_id',how='left')\n",
    "\n",
    "                df[f'gap_{col}']=df[f'mean_{col}']-df[col]\n",
    "            \n",
    "    df.drop(['person_id','essay_id'],axis=1,inplace=True)\n",
    "    \n",
    "    return df\n",
    "    \n",
    "train_feats=feature_engineer(train_feats)\n",
    "valid_feats=feature_engineer(valid_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ca101e",
   "metadata": {
    "papermill": {
     "duration": 0.010303,
     "end_time": "2024-06-08T05:13:14.532676",
     "exception": false,
     "start_time": "2024-06-08T05:13:14.522373",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 这里是对模型筛选出的一些重要特征进行特征交叉,纯粹暴力的交叉。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72298940",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T05:13:14.557374Z",
     "iopub.status.busy": "2024-06-08T05:13:14.556853Z",
     "iopub.status.idle": "2024-06-08T05:13:15.864389Z",
     "shell.execute_reply": "2024-06-08T05:13:15.862806Z"
    },
    "papermill": {
     "duration": 1.323961,
     "end_time": "2024-06-08T05:13:15.867375",
     "exception": false,
     "start_time": "2024-06-08T05:13:14.543414",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#这里对重要的特征进行特征交叉\n",
    "#大于270个迭代器的重要特征,这里还有一些前缀是gap的特征,这里只选择了1个\n",
    "tops=['title_ari','author_count','venue_stdwordlen','year','mean_org_author_count','total_len','gap_author_count','mean_abs_wordlen', 'std_abs_wordlen', 'sum_abs_wordlen', 'keywords_len_mean', 'keywords_len_std']   \n",
    "for i in range(len(tops)):\n",
    "    for j in range(i+1,len(tops)):\n",
    "        train_feats[f\"{tops[i]}+{tops[j]}\"]=train_feats[tops[i]]+train_feats[tops[j]]\n",
    "        train_feats[f\"{tops[i]}-{tops[j]}\"]=train_feats[tops[i]]-train_feats[tops[j]]\n",
    "        train_feats[f\"{tops[i]}*{tops[j]}\"]=train_feats[tops[i]]*train_feats[tops[j]]\n",
    "        train_feats[f\"{tops[i]}/{tops[j]}\"]=train_feats[tops[i]]/train_feats[tops[j]]\n",
    "        \n",
    "        valid_feats[f\"{tops[i]}+{tops[j]}\"]=valid_feats[tops[i]]+valid_feats[tops[j]]\n",
    "        valid_feats[f\"{tops[i]}-{tops[j]}\"]=valid_feats[tops[i]]-valid_feats[tops[j]]\n",
    "        valid_feats[f\"{tops[i]}*{tops[j]}\"]=valid_feats[tops[i]]*valid_feats[tops[j]]\n",
    "        valid_feats[f\"{tops[i]}/{tops[j]}\"]=valid_feats[tops[i]]/valid_feats[tops[j]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47003e4",
   "metadata": {
    "papermill": {
     "duration": 0.010127,
     "end_time": "2024-06-08T05:13:15.887990",
     "exception": false,
     "start_time": "2024-06-08T05:13:15.877863",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 这里drop了一些无用的特征,有的是模型训练是重要性太低的,有的是对抗性检验发现训练数据和测试数据分布不一致的。这个操作进行了很多次。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "748c63a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T05:13:15.911844Z",
     "iopub.status.busy": "2024-06-08T05:13:15.911389Z",
     "iopub.status.idle": "2024-06-08T05:13:19.347593Z",
     "shell.execute_reply": "2024-06-08T05:13:19.346150Z"
    },
    "papermill": {
     "duration": 3.45195,
     "end_time": "2024-06-08T05:13:19.350557",
     "exception": false,
     "start_time": "2024-06-08T05:13:15.898607",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "useless_cols=['abstract_top89', 'mean_abstract_top39', 'median_title_top66', 'max_title_top0', 'sum_keywords_len_max', 'max_abstract_top49', 'median_title_top79', 'mean_title_top30', 'sum_abstract_top89', 'median_max_orgs_wordcnt', 'std_abs_CLRI', 'median_title_top8', 'median_mean_orgs_wordcnt', 'author_org_count', 'abstract_top75', 'mean_title_top49', 'gap_title_top87', 'median_abstract_top31', 'median_title_top60', 'max_title_top81', 'std_sum_abs_senwordcnt', 'std_std_orgs_wordcnt', 'std_abstract_top16', 'std_abstract_top91', 'sum_title_top33', 'mean_title_top57', 'std_sum_abs_wordlen', 'mean_std_abs_sentencelen', 'std_title_top46', 'median_abstract_top98', 'abstract_top66', 'title_top83', 'median_title_top1', 'max_abstract_top27', 'sum_abstract_top23', 'max_title_top66', 'max_title_top42', 'max_abstract_top6', 'sum_abstract_top30', 'max_abstract_top86', 'sum_title_ari', 'sum_abstract_top25', 'median_abstract_top64', 'abstract_top91', 'abstract_top17', 'std_title_top13', 'max_title_word_medianlen', 'median_title_top89', 'sum_title_top82', 'sum_title_top64', 'sum_abstract_top43', 'mean_title_word_sumlen', 'std_title_top53', 'std_abs_len', 'median_abstract_top9', 'title_top42', 'max_venue_ari', 'median_mean_orgs_len', 'sum_abstract_top87', 'median_abstract_top94', 'mean_title_top67', 'max_abstract_top91', 'abstract_top31', 'mean_max_abs_senwordcnt', 'std_mean_orgs_len', 'max_title_top69', 'sum_abstract_top31', 'median_title_word_medianlen', 'title_top36', 'sum_abstract_top10', 'abstract_top14', 'sum_abstract_top14', 'sum_title_top10', 'max_abstract_top83', 'std_title_top40', 'abstract_top86', 'median_title_top98', 'max_abstract_top4', 'max_abstract_top87', 'sum_title_top41', 'mean_title_top26', 'gap_title_top66', 'max_abstract_top81', 'gap_title_top83', 'abstract_top64', 'max_venue_maxwordlen', 'median_title_top39', 'max_title_top25', 'mean_mean_abs_senwordcnt', 'std_title_top19', 'max_title_top70', 'median_title_word_maxlen', 'mean_title_top82', 'max_abstract_top48', 'sum_std_orgs_len', 'max_abstract_top18', 'title_top3', 'std_title_top59', 'median_title_top41', 'mean_abstract_top79', 'title_top40', 'title_top67', 'abstract_top73', 'std_title_top26', 'sum_abstract_top28', 'median_abstract_top91', 'max_title_top2', 'median_title_top17', 'median_title_top64', 'median_abstract_top28', 'abstract_top83', 'std_title_top48', 'sum_abstract_top66', 'std_title_top92', 'skew_title_top98', 'title_top54', 'max_abstract_top23', 'max_title_top74', 'max_title_top35',  'mean_max_orgs_len', 'max_title_top61', 'title_top63', 'max_title_top82', 'sum_author_count', 'median_title_top69', 'max_title_top33', 'median_abstract_top84', 'median_abstract_top88', 'title_top50', 'sum_max_abs_wordlen', 'sum_title_top19', 'title_top93', 'median_keywords_count', 'median_title_top59', 'mean_abstract_top92', 'median_abstract_top66', 'max_title_top3', 'mean_mean_orgs_wordcnt', 'title_top84', 'abstract_top30', 'std_title_top57', 'title_top56', 'median_title_top48', 'title_top51', 'sum_keywords_len_std', 'std_title_top50', 'gap_title_top80', 'sum_venue_medianwordlen', 'max_title_top8', 'abstract_top4', 'median_median_abs_wordlen', 'sum_title_top36', 'max_abstract_top63', 'max_title_top84', 'sum_title_top57', 'abstract_top92', 'median_title_top80', 'abstract_top87', 'max_title_top48', 'title_top24', 'max_abstract_top78', 'title_top96', 'title_top65', 'sum_abstract_top4', 'abstract_top3', 'median_abstract_top20', 'title_top35', 'abstract_top60', 'median_abstract_top35', 'median_abstract_top33', 'std_title_top27', 'abstract_top63', 'max_abs_len', 'sum_abstract_top8', 'sum_title_McAlpine_EFLAW', 'max_title_top85', 'sum_abstract_top72', 'std_abstract_top93', 'title_top69', 'median_abstract_top85', 'median_abstract_top19', 'median_max_orgs_len', 'max_title_top54', 'median_title_top31', 'median_title_top29', 'sum_abstract_top46', 'std_abs_sentenece_count', 'median_median_abs_senwordcnt', 'sum_abs_len', 'max_abstract_top43', 'title_top26', 'max_abstract_top0', 'sum_abstract_top27', 'max_title_top23', 'title_top72', 'abstract_top41', 'title_top70', 'sum_title_word_stdlen', 'sum_title_top35', 'median_title_top62', 'max_abstract_top98', 'sum_title_top32', 'sum_abstract_top74', 'mean_title_len', 'mean_abstract_top32', 'std_abstract_top79', 'max_abstract_top26', 'max_abstract_top46', 'median_title_top14', 'median_abstract_top53', 'median_std_orgs_wordcnt', 'sum_title_top0', 'median_title_top10', 'std_abstract_top9', 'title_top39', 'median_abs_wordcount', 'max_venue_meanwordlen', 'max_title_top19', 'max_venue_McAlpine_EFLAW', 'abstract_top58', 'sum_title_top70', 'gap_title_top55', 'median_title_top97', 'sum_abstract_top13', 'sum_abstract_top16', 'abstract_top67', 'title_top5', 'mean_title_top99', 'median_title_top27', 'mean_title_top92', 'title_top68', 'max_abs_McAlpine_EFLAW', 'abstract_top19', 'abstract_top85', 'max_abstract_top56', 'max_title_top80', 'sum_abstract_top9', 'sum_title_top94', 'max_abstract_top64', 'median_title_top65', 'max_abstract_top93', 'skew_title_top88', 'abstract_top84', 'sum_title_top51', 'std_title_top75', 'sum_abstract_top95', 'median_title_top40', 'sum_sum_abs_sentencelen', 'sum_title_top91', 'median_sum_orgs_wordcnt', 'skew_abs_CLRI', 'title_top10', 'max_abstract_top54', 'max_title_top77', 'median_abstract_top26', 'mean_title_CLRI', 'sum_title_top12', 'median_title_top49', 'abstract_top77', 'median_abstract_top77', 'median_abstract_top89', 'title_top82', 'median_abstract_top58', 'median_title_McAlpine_EFLAW', 'std_title_top31', 'gap_title_top57', 'sum_abstract_top65', 'sum_title_top72', 'median_abstract_top6', 'max_title_top98', 'sum_title_top45', 'sum_title_top18', 'max_abstract_top14', 'max_title_top62', 'sum_abstract_top76', 'mean_title_top75', 'std_title_top39', 'sum_abstract_top71', 'max_abstract_top61', 'max_abstract_top66',  'sum_title_top52', 'mean_title_top3', 'std_title_top80', 'sum_title_top61', 'title_top37', 'sum_std_abs_sentencelen', 'sum_abstract_top79', 'mean_title_top62', 'median_abstract_top92', 'max_sum_abs_sentencelen', 'sum_title_top15', 'sum_title_top7', 'median_title_top84', 'median_abstract_top11', 'skew_title_top73', 'mean_abstract_top88', 'skew_title_top57', 'max_abstract_top15', 'median_abs_len', 'mean_title_word_stdlen', 'sum_max_orgs_wordcnt', 'max_abstract_top53', 'std_title_top55', 'sum_title_top3', 'median_title_top13', 'sum_abs_sentenece_count', 'max_abstract_top62', 'median_abstract_top75', 'max_abstract_top20', 'max_title_top68', 'median_abstract_top49', 'max_max_orgs_wordcnt', 'median_abstract_top55', 'max_title_top78', 'max_title_top93', 'sum_title_top8', 'title_top62', 'sum_title_top31', 'std_abstract_top12', 'mean_title_top64', 'abstract_top98', 'title_top58', 'sum_median_orgs_wordcnt', 'skew_title_top25', 'std_title_top38', 'max_abstract_top44', 'sum_title_top95', 'std_abs_McAlpine_EFLAW', 'sum_title_top85', 'std_title_top66', 'median_abstract_top90', 'sum_title_word_meanlen', 'max_abstract_top88', 'std_title_top91', 'sum_abstract_top55', 'median_title_top43', 'median_title_top3', 'median_title_top26', 'median_title_top34', 'sum_abs_wordcount', 'abstract_top53', 'std_title_top44', 'std_title_top49', 'sum_title_top40', 'title_top55', 'median_title_top2', 'title_top11', 'median_sum_abs_sentencelen', 'median_title_top72', 'max_abstract_top24', 'median_abstract_top27', 'std_abstract_top2', 'sum_abstract_top82', 'max_abstract_top67', 'max_title_top13', 'max_abstract_top2', 'median_title_top63', 'std_title_top86', 'sum_title_top20', 'sum_title_top46', 'max_title_top50', 'sum_title_top42', 'sum_title_top88', 'std_title_top88', 'median_abstract_top23', 'skew_abstract_top57', 'sum_abstract_top63', 'median_title_top7', 'sum_venue_sumwordlen', 'sum_abstract_top7', 'sum_abstract_top20', 'venue_wordcount', 'median_title_top5', 'max_abstract_top97', 'gap_title_top47', 'title_top99', 'median_title_top11', 'abstract_top48', 'abstract_top35', 'sum_median_orgs_len', 'abstract_top39', 'max_title_top79', 'max_abstract_top12', 'max_abstract_top22', 'std_title_top29', 'sum_title_top50', 'max_abstract_top5', 'median_median_abs_sentencelen', 'max_abstract_top8', 'abstract_top74', 'median_abstract_top46', 'sum_abstract_top50', 'mean_title_top34', 'mean_abs_CLRI', 'median_title_top74', 'title_top7', 'max_title_top51', 'median_max_abs_sentencelen', 'std_title_top70', 'max_title_top91', 'max_title_top17', 'skew_abs_McAlpine_EFLAW', 'title_top15', 'max_abstract_top41', 'skew_title_top44', 'median_title_top23', 'max_abstract_top47', 'sum_title_top92', 'median_abstract_top72', 'median_title_top78', 'abstract_top7', 'std_abs_wordcount', 'sum_title_top56', 'title_top64', 'sum_std_orgs_wordcnt', 'sum_abstract_top73', 'skew_abs_wordcount', 'median_title_top35', 'median_abstract_top93', 'sum_title_top86', 'title_top95', 'median_title_top82', 'median_title_top33', 'median_abstract_top30', 'abstract_top37', 'max_title_top73', 'median_abstract_top54', 'std_title_top61', 'std_abstract_top95', 'std_abstract_top89', 'sum_title_top99', 'sum_title_top63', 'sum_abstract_top52', 'sum_title_top80', 'max_mean_orgs_len', 'sum_year', 'title_top98', 'std_title_top87', 'median_title_top83', 'abstract_top10', 'mean_title_top56', 'median_title_top36', 'median_title_top55', 'mean_title_top85', 'title_top90', 'median_title_top94', 'abstract_top69', 'max_abstract_top16', 'gap_title_top90', 'sum_keywords_len_median', 'title_top97', 'median_abstract_top7', 'sum_venue_stdwordlen', 'median_abstract_top96', 'max_title_top10', 'sum_median_abs_senwordcnt', 'mean_title_top86', 'abstract_top20', 'sum_abstract_top91', 'max_title_top72', 'sum_title_top11', 'skew_title_top78', 'max_title_top38', 'abstract_top59', 'median_title_top70', 'mean_title_top32', 'sum_abstract_top11', 'std_title_top56', 'mean_abstract_top61', 'title_top79', 'mean_title_top42', 'mean_title_top31', 'mean_abstract_top8', 'title_top9', 'max_title_top20', 'abstract_top24', 'abstract_top46', 'sum_sum_orgs_wordcnt', 'sum_title_top22', 'max_title_top47', 'max_title_top58', 'max_title_top65', 'std_title_top72', 'std_title_top84', 'mean_title_top74', 'max_title_top49', 'sum_abstract_top36', 'max_title_top6', 'max_title_top43', 'abstract_top72', 'sum_title_top98', 'max_abstract_top35', 'gap_title_top89', 'median_title_top58', 'max_abstract_top77', 'sum_abstract_top1', 'max_title_top90', 'median_title_top28', 'abstract_top62', 'max_title_top86', 'max_title_top92', 'median_title_top67', 'std_abstract_top92', 'sum_abstract_top54', 'median_abstract_top24', 'sum_abstract_top6', 'mean_title_top61', 'max_title_top16', 'gap_title_top70', 'sum_title_top76', 'sum_mean_orgs_wordcnt', 'sum_abstract_top41', 'std_title_top93', 'max_abstract_top33', 'median_title_top44', 'median_median_orgs_wordcnt', 'mean_title_top87', 'max_title_top7', 'std_title_top76', 'abstract_top99', 'abstract_top23', 'sum_title_top65', 'mean_title_top53', 'median_title_top50', 'max_abstract_top58', 'median_title_top30', 'std_title_top62', 'std_title_top69', 'max_title_top36', 'abstract_top28', 'max_title_top29', 'max_title_top24', 'std_title_top81', 'std_title_top71', 'sum_title_top26', 'sum_median_abs_wordlen', 'abstract_top34', 'abstract_top65', 'median_abs_sentenece_count', 'sum_abstract_top24', 'max_abstract_top76', 'title_top16', 'sum_venue_len', 'max_title_top1', 'title_top34', 'title_top23', 'sum_abstract_top81', 'max_abstract_top60', 'median_abstract_top48', 'median_abstract_top61', 'median_abstract_top63', 'median_title_top56', 'sum_author_org_count', 'max_title_top14', 'median_title_top96', 'max_title_top44', 'max_title_top97', 'max_abstract_top74', 'sum_abstract_top94', 'skew_title_top46', 'sum_sum_orgs_len', 'sum_abstract_top59', 'std_abstract_top51', 'mean_abstract_top4', 'max_abstract_top94', 'abstract_top82', 'max_title_top96', 'median_abstract_top1', 'abstract_top8', 'median_abstract_top45', 'std_abstract_top33', 'max_title_top27', 'skew_sum_abs_sentencelen', 'title_top14', 'abstract_top29', 'max_title_top9', 'sum_title_top49', 'max_title_top64', 'max_title_top83', 'abstract_top97', 'sum_abstract_top67', 'sum_abstract_top93', 'mean_title_top91', 'sum_title_top67', 'sum_title_top25', 'max_title_top94', 'mean_abstract_top95', 'title_top25', 'abstract_top52', 'max_title_top39', 'median_title_top24', 'sum_mean_abs_sentencelen', 'mean_title_top55', 'mean_title_top69', 'skew_title_top76', 'median_title_top92', 'mean_abs_McAlpine_EFLAW', 'max_title_top26', 'mean_title_top48', 'mean_mean_orgs_len', 'sum_abstract_top2', 'std_title_top58', 'median_author_count', 'abstract_top25', 'median_title_top4', 'abstract_top81', 'sum_title_wordcount', 'title_top4', 'median_title_top16', 'title_top52', 'max_title_top76', 'max_abstract_top55', 'mean_median_orgs_len', 'max_abstract_top99', 'abstract_top38', 'sum_title_word_sumlen', 'abstract_top9', 'std_title_top30', 'median_abstract_top5', 'median_abstract_top34', 'max_abstract_top84', 'mean_title_top63', 'sum_abstract_top98', 'sum_title_top43', 'median_title_top93', 'max_abstract_top38', 'sum_abstract_top12', 'mean_title_top46', 'median_abstract_top81', 'sum_abstract_top34', 'median_title_top52', 'sum_abs_ari', 'skew_title_top65', 'title_top91', 'std_title_top73', 'std_abs_ari', 'median_title_top21', 'max_abstract_top71', 'max_title_top21', 'median_abstract_top15', 'median_abstract_top50', 'max_mean_orgs_wordcnt', 'max_abstract_top31', 'std_title_top89', 'sum_title_top37', 'median_abstract_top80', 'max_title_top41', 'median_abstract_top44', 'std_abstract_top88', 'skew_title_top89', 'std_title_top35', 'sum_abstract_top38', 'abstract_top95', 'title_top17', 'std_title_top9', 'skew_title_top60', 'sum_abstract_top86', 'mean_abs_wordcount', 'skew_title_top63', 'title_top86', 'gap_title_top82', 'sum_title_top39', 'max_abstract_top42', 'median_abstract_top2', 'title_top28', 'title_top85', 'title_top45', 'sum_max_orgs_len', 'sum_abstract_top44', 'median_abstract_top62', 'max_title_ari', 'sum_title_top13', 'title_top46', 'sum_title_top89', 'median_title_top85', 'abstract_top93', 'median_title_top45', 'sum_abstract_top70', 'max_abstract_top39', 'max_title_top22', 'gap_title_top86', 'std_title_top95', 'mean_title_top9', 'mean_title_top40', 'std_title_top45', 'std_title_top94', 'mean_title_top97', 'sum_abstract_top42', 'median_abstract_top59', 'std_abstract_top39', 'mean_sum_abs_sentencelen', 'median_title_word_sumlen', 'skew_abs_len', 'max_sum_abs_senwordcnt', 'sum_abstract_top39', 'median_abstract_top82', 'sum_title_top79', 'median_title_top46', 'sum_abstract_top18', 'title_top32', 'sum_title_top9', 'max_title_top37', 'median_sum_abs_senwordcnt', 'gap_title_top93', 'sum_abstract_top92', 'sum_abstract_top37', 'sum_title_top55', 'max_title_top60', 'median_abstract_top99', 'sum_venue_McAlpine_EFLAW', 'sum_sum_abs_wordlen', 'gap_title_top53', 'median_title_top77', 'sum_venue_maxwordlen', 'sum_abstract_top69', 'std_title_top99', 'abstract_top51', 'sum_title_top47', 'max_abstract_top10', 'median_abstract_top36', 'median_venue_wordcount', 'max_title_wordcount', 'std_abstract_top36', 'sum_abstract_top77', 'median_abstract_top52', 'sum_abstract_top53', 'max_abstract_top51', 'title_top92', 'std_title_top67', 'sum_abstract_top56', 'max_title_top67', 'sum_venue_meanwordlen', 'std_title_top24', 'sum_title_top75', 'sum_title_top4', 'sum_title_top84', 'median_title_top91', 'median_abstract_top41', 'title_top75', 'title_top27', 'median_abstract_top78', 'title_top29', 'sum_title_top58', 'sum_abstract_top47', 'max_abstract_top79', 'median_abstract_top51', 'title_top1', 'skew_title_top47', 'sum_abstract_top64', 'max_abstract_top85', 'max_abstract_top21', 'max_abstract_top45', 'max_abstract_top36', 'max_abstract_top1', 'sum_abstract_top96', 'sum_title_top90', 'max_abstract_top70', 'max_title_top31', 'median_median_orgs_len', 'sum_title_top69', 'median_title_wordcount', 'title_top47', 'title_top81', 'sum_median_abs_sentencelen', 'median_abstract_top17', 'abstract_top49', 'mean_title_top23', 'median_abstract_top4', 'std_title_top43', 'std_title_top90', 'sum_abstract_top3', 'std_abstract_top67', 'sum_max_abs_sentencelen', 'mean_median_abs_sentencelen', 'sum_abstract_top57', 'median_max_abs_wordlen', 'median_abstract_top47', 'abstract_top50', 'median_abstract_top60', 'max_abstract_top32', 'sum_abstract_top48', 'median_abstract_top73', 'abstract_top61', 'median_title_top37', 'abstract_top18', 'median_abstract_top39', 'mean_abstract_top70', 'sum_abstract_top19', 'skew_abs_ari', 'max_title_top32', 'std_title_top60', 'abstract_top36', 'max_median_abs_senwordcnt', 'sum_abstract_top0', 'title_top53', 'abstract_top44', 'sum_title_top38', 'median_title_top57', 'sum_title_top78', 'mean_title_top72', 'sum_abstract_top32', 'std_abstract_top61', 'mean_std_abs_senwordcnt', 'abstract_top11', 'std_title_top32', 'max_title_top18', 'max_title_top95', 'sum_title_word_medianlen', 'median_title_top88', 'mean_title_top78', 'sum_mean_orgs_len', 'skew_abstract_top4', 'sum_mean_abs_senwordcnt', 'max_title_top99', 'sum_title_top71', 'title_top48', 'median_title_top18', 'median_abs_wordlen', 'abstract_top45', 'median_title_top32', 'title_top38', 'sum_abstract_top22', 'max_title_top59', 'max_abstract_top30', 'median_abstract_top76', 'sum_abstract_top62', 'max_title_top75', 'skew_title_top13', 'std_title_top52', 'max_abstract_top50', 'sum_title_top27', 'title_top43','std_title_top79', 'median_title_top76', 'sum_abstract_top84', 'skew_sum_abs_senwordcnt', 'median_title_top15', 'max_title_top87', 'median_venue_len', 'max_title_top55', 'abstract_top43', 'median_abs_McAlpine_EFLAW', 'median_title_top71', 'max_sum_orgs_wordcnt', 'max_title_top56', 'max_abstract_top13', 'median_abstract_top18', 'max_abstract_top3', 'max_abstract_top89', 'std_abstract_top1', 'median_abstract_top16', 'mean_mean_abs_sentencelen', 'median_abstract_top68', 'mean_sum_orgs_len', 'abstract_top32', 'sum_title_top6', 'median_title_top99', 'sum_abstract_top78', 'skew_mean_abs_senwordcnt', 'title_top33', 'max_median_abs_wordlen', 'max_abstract_top7', 'abstract_top27', 'mean_venue_sumwordlen', 'sum_abstract_top26', 'mean_title_top47', 'median_abstract_top79', 'std_title_top28', 'max_venue_wordcount', 'sum_title_top53', 'median_abstract_top56', 'median_venue_medianwordlen', 'abstract_top13', 'median_title_top38', 'max_abstract_top52', 'max_abstract_top28', 'sum_abstract_top75', 'max_abstract_top75', 'median_abstract_top95', 'max_abstract_top57', 'mean_title_top59', 'median_author_org_count', 'median_abstract_top14', 'max_title_top30', 'max_abstract_top17', 'sum_title_top21', 'std_title_top54', 'mean_abstract_top7', 'mean_abs_ari', 'max_abstract_top69', 'abstract_top54', 'mean_title_top83', 'max_title_top40', 'max_abstract_top73', 'median_title_top53', 'max_abstract_top9', 'std_title_top64', 'sum_std_abs_senwordcnt', 'abstract_top96', 'sum_std_abs_wordlen', 'mean_max_abs_sentencelen', 'max_sum_abs_wordlen', 'sum_title_top48', 'title_top71', 'abstract_top1', 'mean_title_top76', 'max_abstract_top59', 'std_title_top12', 'mean_abs_len', 'max_title_top89', 'median_abstract_top87', 'median_abstract_top10', 'std_title_top23', 'abstract_top90', 'title_top12', 'std_title_top78', 'median_abstract_top42', 'abstract_top71', 'title_top2', 'median_title_top75', 'abstract_top42', 'median_abstract_top32', 'sum_abstract_top51', 'max_abstract_top96', 'median_venue_maxwordlen', 'sum_abstract_top17', 'title_top20', 'max_abstract_top65', 'gap_title_top65', 'sum_sum_abs_senwordcnt', 'std_title_top34', 'max_title_top4', 'std_title_top85', 'max_abstract_top11', 'title_top66', 'std_title_top68', 'sum_title_top23', 'median_abstract_top67', 'title_top30', 'skew_title_top49', 'sum_title_top30', 'abstract_top80', 'title_top59', 'max_title_top71', 'title_top74', 'median_title_top25', 'sum_title_top73', 'max_title_top46', 'abstract_top76', 'sum_max_abs_senwordcnt', 'mean_title_top66', 'std_title_top74', 'std_title_top77', 'median_abstract_top3', 'max_abstract_top82', 'std_title_top97', 'median_abstract_top83', 'sum_title_top77', 'max_abstract_top29', 'sum_abs_McAlpine_EFLAW', 'std_title_top47', 'title_top89', 'median_title_top95', 'max_title_top15', 'max_title_top57', 'abstract_top55', 'sum_title_top34', 'max_title_top28', 'median_abstract_top97', 'std_title_top83', 'sum_title_top68', 'mean_title_top29', 'title_top78', 'mean_sum_abs_senwordcnt', 'median_std_orgs_len', 'sum_keywords_len_sum', 'std_title_top96', 'sum_abstract_top33', 'mean_title_top37', 'max_title_top45', 'median_title_top12', 'sum_title_top28', 'skew_title_top77', 'mean_title_top84', 'std_title_top20', 'median_abstract_top29', 'title_top21', 'max_author_org_count', 'mean_title_top88', 'sum_keywords_count', 'median_abstract_top21', 'std_title_top63', 'median_abstract_top86', 'skew_abstract_top60', 'median_title_top54', 'sum_title_top44', 'median_title_top61', 'max_median_orgs_wordcnt', 'sum_keywords_len_mean', 'median_title_top68', 'median_title_top81', 'median_abstract_top37', 'std_abstract_top57', 'title_top76', 'mean_title_top90', 'abstract_top21', 'title_top60', 'median_abstract_top38', 'median_title_top73', 'mean_title_top93', 'abstract_top94', 'median_title_top51', 'sum_title_top83', 'median_title_top9', 'median_abstract_top12', 'max_abstract_top40', 'mean_title_top13', 'sum_title_top29', 'median_abstract_top13', 'median_max_abs_senwordcnt', 'median_title_top22', 'sum_venue_ari', 'max_title_top34', 'median_title_top86', 'median_title_top47', 'median_venue_McAlpine_EFLAW', 'max_title_top11', 'median_title_top19', 'max_title_top88', 'abstract_top40', 'max_abstract_top68', 'max_abstract_top19', 'median_title_top6', 'abstract_top56', 'median_abstract_top57', 'std_title_top98', 'mean_abstract_top51', 'abstract_top78', 'std_title_top36', 'median_sum_orgs_len', 'sum_mean_abs_wordlen', 'median_title_top90', 'sum_title_top96', 'sum_title_top97', 'sum_abstract_top60', 'title_top22', 'sum_title_top93', 'mean_title_top27', 'median_title_top42', 'max_abstract_top80', 'std_abstract_top7', 'sum_abstract_top88', 'mean_title_top79', 'abstract_top79', 'title_top18', 'median_abstract_top74', 'std_max_orgs_len', 'std_title_top51', 'title_top41', 'sum_abstract_top21', 'max_title_top5', 'abstract_top68', 'max_title_top63', 'skew_title_top90', 'skew_title_top82', 'gap_title_top26', 'title_top49', 'std_title_top42', 'median_abstract_top70', 'max_std_orgs_wordcnt', 'abstract_top47', 'sum_title_top2', 'abstract_top26', 'abstract_top88', 'title_top0', 'median_title_top0', 'sum_abstract_top45', 'mean_title_top73', 'median_abstract_top0', 'median_keywords_len_max', 'max_title_top52', 'std_title_top65', 'abstract_top70', 'max_title_top53', 'sum_abstract_top85', 'max_abstract_top92', 'sum_abstract_top49', 'gap_title_top74', 'title_top19', 'sum_title_top59', 'median_abstract_top69', 'median_title_top87', 'max_abstract_top90', 'title_top88', 'title_top94', 'std_sum_abs_sentencelen', 'sum_title_top60', 'sum_title_top54', 'max_venue_medianwordlen', 'sum_title_top17', 'mean_title_top19', 'sum_title_top1', 'max_abstract_top25', 'max_title_top12', 'title_top31', 'sum_abstract_top61', 'sum_venue_wordcount', 'abstract_top22', 'skew_title_top29', 'median_abstract_top25', 'mean_median_abs_senwordcnt', 'std_title_top82', 'median_abstract_top65', 'max_abstract_top72', 'max_abs_sentenece_count', 'mean_title_top89', 'sum_title_top74', 'sum_venue_CLRI', 'median_title_top20', 'sum_title_len', 'mean_median_orgs_wordcnt', 'sum_abstract_top29', 'sum_title_top62', 'sum_abstract_top80', 'sum_title_top24', 'max_abstract_top34', 'title_top44', 'sum_title_top66', 'mean_title_top20', 'title_top80', 'median_abstract_top22', 'sum_abs_sentencelen', 'median_abstract_top40', 'mean_title_top44', 'median_abstract_top8', 'sum_title_top87', 'title_top61', 'title_top57', 'max_abstract_top95', 'median_abstract_top71', 'title_top8', 'title_top6', 'max_abs_wordcount', 'std_title_top37', 'median_abstract_top43', 'title_top87', 'max_abstract_top37', 'skew_title_top50', 'sum_title_word_maxlen','std_title_top22', 'std_title_top18', 'abstract_top57', 'abstract_top5', 'std_abstract_top18', 'std_title_top25', 'skew_title_top40', 'skew_title_top85', 'mean_title_top77', 'median_std_abs_sentencelen', 'title_top73', 'median_venue_meanwordlen', 'skew_title_top51']\n",
    "useless_cols+=['japan', 'france', 'switzerland',  'uk','germany', 'canada', 'australia',  'hong kong', 'united states', 'u.s.a', 'singapore', 'united kingdom', 'russia', 'median_china', 'sum_japan', 'median_japan', 'max_japan', 'median_france', 'max_france', 'median_usa', 'sum_switzerland', 'median_switzerland', 'max_switzerland', 'std_switzerland','median_uk', 'max_uk', 'sum_germany', 'median_germany', 'max_germany', 'sum_canada', 'median_canada', 'sum_australia', 'median_australia', 'max_australia', 'std_australia',   'median_hong kong', 'median_united states', 'sum_u.s.a', 'mean_u.s.a', 'median_u.s.a', 'skew_u.s.a', 'max_u.s.a', 'std_u.s.a', 'gap_u.s.a', 'median_singapore', 'max_singapore', 'sum_united kingdom', 'median_united kingdom', 'max_united kingdom', 'std_united kingdom','sum_russia', 'mean_russia', 'median_russia', 'max_russia', 'std_russia', 'gap_russia','gap_switzerland', 'max_united states','mean_switzerland', 'author_count/mean_org_author_count','sum_uk', 'max_hong kong', 'sum_united states']\n",
    "useless_cols+=['max_author_count', 'skew_mean_abs_wordlen', 'skew_venue_wordcount', 'skew_venue_McAlpine_EFLAW', 'mean_year', 'skew_year', 'skew_title_top4', 'skew_title_top11', 'skew_title_top42', 'skew_title_top53', 'gap_title_top56', 'std_abstract_top10', 'std_abstract_top22', 'std_abstract_top35', 'skew_abstract_top47', 'std_abstract_top69', 'skew_abstract_top72', 'skew_abstract_top93']\n",
    "useless_cols+=['category_3', 'sum_category_8', 'abstract_top0', 'category_8',  'max_category_6', 'sum_category_10', 'abs_sentenece_count', 'mean_category_7', 'median_category_6', 'max_category_0', 'max_category_5', 'skew_category_13', 'category_12', 'median_category_3', 'category_0', 'median_category_7', 'max_category_1', 'max_category_12', 'median_category_11', 'median_category_9', 'title_word_medianlen', 'std_category_7', 'median_category_0', 'max_category_10', 'max_category_2', 'median_category_12', 'gap_category_8', 'std_category_13', 'max_category_8', 'category_1', 'median_category', 'category_10', 'sum_category_11', 'max_category_7', 'category_13', 'median_category_8', 'median_category_4', 'category_4', 'median_category_2', 'max_category_4', 'median_category_13', 'std_category_8', 'median_category_10', 'max_category_13', 'gap_category_7', 'max_category_3', 'max_category_11', 'category_7', 'sum_category_13', 'median_category_1', 'category_6', 'max_category_9', 'median_category_5', 'sum_category_7']\n",
    "useless_cols+=['abstract_top2', 'abstract_top6', 'author_count', 'china', 'median_abs_senwordcnt', 'abstract_top33', 'gap_category_13', 'max_orgs_wordcnt', 'sum_abs_wordlen', 'total_len+std_abs_wordlen', 'mean_abs_wordlen+sum_abs_wordlen', 'mean_abs_wordlen-sum_abs_wordlen', 'std_abs_wordlen+sum_abs_wordlen', 'std_abs_wordlen-sum_abs_wordlen', 'abs_len', 'category_11', 'std_category_11', 'author_count-sum_abs_wordlen', 'venue_stdwordlen+sum_abs_wordlen', 'mean_org_author_count+sum_abs_wordlen', 'total_len+mean_abs_wordlen', 'total_len-mean_abs_wordlen', 'std_category_2', 'venue_stdwordlen-sum_abs_wordlen', 'gap_author_count-sum_abs_wordlen', 'sum_category_4', 'title_ari+sum_abs_wordlen', 'mean_org_author_count-sum_abs_wordlen', 'total_len-std_abs_wordlen', 'category_9', 'mean_category_8', 'total_len*sum_abs_wordlen', 'total_len+sum_abs_wordlen', 'skew_category_7', 'category_2', 'std_category_4', 'title_ari-sum_abs_wordlen', 'year*sum_abs_wordlen', 'mean_category_4', 'author_count+sum_abs_wordlen', 'max_category', 'gap_category_11', 'year-sum_abs_wordlen', 'sum_category_2']\n",
    "train_feats.drop(useless_cols,axis=1,inplace=True)\n",
    "valid_feats.drop(useless_cols,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c9944b",
   "metadata": {
    "papermill": {
     "duration": 0.010279,
     "end_time": "2024-06-08T05:13:19.371273",
     "exception": false,
     "start_time": "2024-06-08T05:13:19.360994",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 对数据右偏取log1p进行处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96c7cfaa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T05:13:19.394055Z",
     "iopub.status.busy": "2024-06-08T05:13:19.393588Z",
     "iopub.status.idle": "2024-06-08T05:13:30.553629Z",
     "shell.execute_reply": "2024-06-08T05:13:30.552314Z"
    },
    "papermill": {
     "duration": 11.174711,
     "end_time": "2024-06-08T05:13:30.556428",
     "exception": false,
     "start_time": "2024-06-08T05:13:19.381717",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skew:title_len\n",
      "skew:title_wordcount\n",
      "skew:title_McAlpine_EFLAW\n",
      "skew:title_word_maxlen\n",
      "skew:title_word_meanlen\n",
      "skew:title_word_stdlen\n",
      "skew:title_word_sumlen\n",
      "skew:usa\n",
      "skew:max_orgs_len\n",
      "skew:median_orgs_len\n",
      "skew:mean_orgs_len\n",
      "skew:std_orgs_len\n",
      "skew:sum_orgs_len\n",
      "skew:median_orgs_wordcnt\n",
      "skew:mean_orgs_wordcnt\n",
      "skew:std_orgs_wordcnt\n",
      "skew:sum_orgs_wordcnt\n",
      "skew:abs_McAlpine_EFLAW\n",
      "skew:abs_wordcount\n",
      "skew:max_abs_wordlen\n",
      "skew:mean_abs_wordlen\n",
      "skew:std_abs_wordlen\n",
      "skew:max_abs_sentencelen\n",
      "skew:std_abs_sentencelen\n",
      "skew:max_abs_senwordcnt\n",
      "skew:sum_abs_senwordcnt\n",
      "skew:keywords_count\n",
      "skew:keywords_len_sum\n",
      "skew:keywords_len_max\n",
      "skew:keywords_len_median\n",
      "skew:keywords_len_mean\n",
      "skew:keywords_len_std\n",
      "skew:venue_len\n",
      "skew:venue_sumwordlen\n",
      "skew:venue_McAlpine_EFLAW\n",
      "skew:title_top13\n",
      "skew:title_top77\n",
      "skew:abstract_top12\n",
      "skew:abstract_top15\n",
      "skew:abstract_top16\n",
      "skew:category\n",
      "skew:mean_org_author_count\n",
      "skew:mean_title_wordlen\n",
      "skew:total_len\n",
      "skew:category_5\n",
      "skew:std_title_len\n",
      "skew:std_title_wordcount\n",
      "skew:std_title_ari\n",
      "skew:max_title_McAlpine_EFLAW\n",
      "skew:max_title_CLRI\n",
      "skew:std_title_CLRI\n",
      "skew:max_title_word_maxlen\n",
      "skew:std_title_word_maxlen\n",
      "skew:std_title_word_medianlen\n",
      "skew:max_title_word_meanlen\n",
      "skew:std_title_word_meanlen\n",
      "skew:max_title_word_stdlen\n",
      "skew:std_title_word_stdlen\n",
      "skew:max_title_word_sumlen\n",
      "skew:mean_author_count\n",
      "skew:std_author_count\n",
      "skew:sum_china\n",
      "skew:max_china\n",
      "skew:std_china\n",
      "skew:mean_japan\n",
      "skew:std_japan\n",
      "skew:sum_france\n",
      "skew:mean_france\n",
      "skew:std_france\n",
      "skew:sum_usa\n",
      "skew:mean_usa\n",
      "skew:max_usa\n",
      "skew:std_usa\n",
      "skew:skew_switzerland\n",
      "skew:mean_uk\n",
      "skew:std_uk\n",
      "skew:mean_germany\n",
      "skew:std_germany\n",
      "skew:mean_canada\n",
      "skew:max_canada\n",
      "skew:std_canada\n",
      "skew:mean_australia\n",
      "skew:sum_hong kong\n",
      "skew:mean_hong kong\n",
      "skew:skew_hong kong\n",
      "skew:std_hong kong\n",
      "skew:mean_united states\n",
      "skew:std_united states\n",
      "skew:sum_singapore\n",
      "skew:mean_singapore\n",
      "skew:std_singapore\n",
      "skew:mean_united kingdom\n",
      "skew:skew_united kingdom\n",
      "skew:skew_russia\n",
      "skew:mean_author_org_count\n",
      "skew:std_author_org_count\n",
      "skew:max_max_orgs_len\n",
      "skew:max_median_orgs_len\n",
      "skew:std_median_orgs_len\n",
      "skew:mean_std_orgs_len\n",
      "skew:max_std_orgs_len\n",
      "skew:std_std_orgs_len\n",
      "skew:max_sum_orgs_len\n",
      "skew:std_sum_orgs_len\n",
      "skew:std_max_orgs_wordcnt\n",
      "skew:std_median_orgs_wordcnt\n",
      "skew:std_mean_orgs_wordcnt\n",
      "skew:mean_std_orgs_wordcnt\n",
      "skew:mean_sum_orgs_wordcnt\n",
      "skew:std_sum_orgs_wordcnt\n",
      "skew:max_abs_ari\n",
      "skew:max_abs_CLRI\n",
      "skew:mean_abs_sentenece_count\n",
      "skew:mean_max_abs_wordlen\n",
      "skew:max_max_abs_wordlen\n",
      "skew:std_max_abs_wordlen\n",
      "skew:mean_median_abs_wordlen\n",
      "skew:std_median_abs_wordlen\n",
      "skew:mean_mean_abs_wordlen\n",
      "skew:max_mean_abs_wordlen\n",
      "skew:std_mean_abs_wordlen\n",
      "skew:mean_std_abs_wordlen\n",
      "skew:median_std_abs_wordlen\n",
      "skew:max_std_abs_wordlen\n",
      "skew:std_std_abs_wordlen\n",
      "skew:mean_sum_abs_wordlen\n",
      "skew:max_max_abs_sentencelen\n",
      "skew:std_max_abs_sentencelen\n",
      "skew:max_median_abs_sentencelen\n",
      "skew:std_median_abs_sentencelen\n",
      "skew:max_mean_abs_sentencelen\n",
      "skew:std_mean_abs_sentencelen\n",
      "skew:max_std_abs_sentencelen\n",
      "skew:std_std_abs_sentencelen\n",
      "skew:max_max_abs_senwordcnt\n",
      "skew:std_max_abs_senwordcnt\n",
      "skew:std_median_abs_senwordcnt\n",
      "skew:max_mean_abs_senwordcnt\n",
      "skew:std_mean_abs_senwordcnt\n",
      "skew:max_std_abs_senwordcnt\n",
      "skew:std_std_abs_senwordcnt\n",
      "skew:mean_keywords_count\n",
      "skew:max_keywords_count\n",
      "skew:mean_keywords_len_sum\n",
      "skew:median_keywords_len_sum\n",
      "skew:max_keywords_len_max\n",
      "skew:std_keywords_len_max\n",
      "skew:max_keywords_len_median\n",
      "skew:std_keywords_len_median\n",
      "skew:max_keywords_len_mean\n",
      "skew:std_keywords_len_mean\n",
      "skew:max_keywords_len_std\n",
      "skew:std_keywords_len_std\n",
      "skew:std_venue_wordcount\n",
      "skew:max_venue_stdwordlen\n",
      "skew:mean_venue_McAlpine_EFLAW\n",
      "skew:std_venue_McAlpine_EFLAW\n",
      "skew:max_venue_CLRI\n",
      "skew:std_year\n",
      "skew:mean_title_top4\n",
      "skew:sum_title_top5\n",
      "skew:mean_title_top5\n",
      "skew:mean_title_top6\n",
      "skew:skew_title_top6\n",
      "skew:mean_title_top7\n",
      "skew:skew_title_top7\n",
      "skew:mean_title_top8\n",
      "skew:skew_title_top8\n",
      "skew:std_title_top8\n",
      "skew:mean_title_top10\n",
      "skew:skew_title_top10\n",
      "skew:mean_title_top11\n",
      "skew:mean_title_top12\n",
      "skew:skew_title_top12\n",
      "skew:sum_title_top14\n",
      "skew:mean_title_top14\n",
      "skew:skew_title_top14\n",
      "skew:mean_title_top15\n",
      "skew:skew_title_top15\n",
      "skew:sum_title_top16\n",
      "skew:mean_title_top16\n",
      "skew:mean_title_top17\n",
      "skew:skew_title_top17\n",
      "skew:mean_title_top18\n",
      "skew:skew_title_top18\n",
      "skew:skew_title_top19\n",
      "skew:mean_title_top21\n",
      "skew:std_title_top21\n",
      "skew:mean_title_top22\n",
      "skew:skew_title_top22\n",
      "skew:skew_title_top23\n",
      "skew:mean_title_top24\n",
      "skew:mean_title_top25\n",
      "skew:skew_title_top26\n",
      "skew:mean_title_top28\n",
      "skew:skew_title_top28\n",
      "skew:skew_title_top30\n",
      "skew:skew_title_top32\n",
      "skew:mean_title_top33\n",
      "skew:std_title_top33\n",
      "skew:skew_title_top34\n",
      "skew:mean_title_top35\n",
      "skew:mean_title_top36\n",
      "skew:mean_title_top38\n",
      "skew:mean_title_top39\n",
      "skew:mean_title_top41\n",
      "skew:skew_title_top41\n",
      "skew:mean_title_top43\n",
      "skew:mean_title_top45\n",
      "skew:mean_title_top50\n",
      "skew:mean_title_top51\n",
      "skew:mean_title_top52\n",
      "skew:skew_title_top52\n",
      "skew:mean_title_top54\n",
      "skew:skew_title_top55\n",
      "skew:skew_title_top56\n",
      "skew:mean_title_top58\n",
      "skew:skew_title_top59\n",
      "skew:mean_title_top60\n",
      "skew:skew_title_top61\n",
      "skew:skew_title_top62\n",
      "skew:mean_title_top65\n",
      "skew:skew_title_top66\n",
      "skew:mean_title_top68\n",
      "skew:skew_title_top68\n",
      "skew:skew_title_top69\n",
      "skew:mean_title_top70\n",
      "skew:mean_title_top71\n",
      "skew:skew_title_top72\n",
      "skew:skew_title_top75\n",
      "skew:mean_title_top80\n",
      "skew:sum_title_top81\n",
      "skew:mean_title_top81\n",
      "skew:skew_title_top81\n",
      "skew:skew_title_top83\n",
      "skew:skew_title_top84\n",
      "skew:skew_title_top86\n",
      "skew:skew_title_top87\n",
      "skew:skew_title_top91\n",
      "skew:skew_title_top93\n",
      "skew:mean_title_top94\n",
      "skew:mean_title_top95\n",
      "skew:skew_title_top95\n",
      "skew:mean_title_top96\n",
      "skew:mean_title_top98\n",
      "skew:mean_abstract_top0\n",
      "skew:std_abstract_top0\n",
      "skew:mean_abstract_top1\n",
      "skew:mean_abstract_top2\n",
      "skew:mean_abstract_top3\n",
      "skew:std_abstract_top3\n",
      "skew:std_abstract_top4\n",
      "skew:sum_abstract_top5\n",
      "skew:mean_abstract_top5\n",
      "skew:std_abstract_top5\n",
      "skew:std_abstract_top6\n",
      "skew:std_abstract_top8\n",
      "skew:mean_abstract_top9\n",
      "skew:mean_abstract_top10\n",
      "skew:mean_abstract_top11\n",
      "skew:std_abstract_top11\n",
      "skew:skew_abstract_top12\n",
      "skew:std_abstract_top13\n",
      "skew:mean_abstract_top14\n",
      "skew:std_abstract_top14\n",
      "skew:sum_abstract_top15\n",
      "skew:mean_abstract_top15\n",
      "skew:std_abstract_top15\n",
      "skew:mean_abstract_top16\n",
      "skew:skew_abstract_top16\n",
      "skew:mean_abstract_top17\n",
      "skew:std_abstract_top17\n",
      "skew:mean_abstract_top18\n",
      "skew:mean_abstract_top19\n",
      "skew:std_abstract_top19\n",
      "skew:mean_abstract_top20\n",
      "skew:std_abstract_top20\n",
      "skew:mean_abstract_top21\n",
      "skew:std_abstract_top21\n",
      "skew:mean_abstract_top23\n",
      "skew:std_abstract_top23\n",
      "skew:std_abstract_top24\n",
      "skew:mean_abstract_top25\n",
      "skew:std_abstract_top25\n",
      "skew:mean_abstract_top26\n",
      "skew:skew_abstract_top26\n",
      "skew:std_abstract_top26\n",
      "skew:skew_abstract_top27\n",
      "skew:mean_abstract_top28\n",
      "skew:std_abstract_top28\n",
      "skew:mean_abstract_top29\n",
      "skew:std_abstract_top29\n",
      "skew:mean_abstract_top30\n",
      "skew:std_abstract_top30\n",
      "skew:mean_abstract_top31\n",
      "skew:std_abstract_top31\n",
      "skew:skew_abstract_top32\n",
      "skew:mean_abstract_top33\n",
      "skew:mean_abstract_top34\n",
      "skew:std_abstract_top34\n",
      "skew:sum_abstract_top35\n",
      "skew:mean_abstract_top35\n",
      "skew:skew_abstract_top35\n",
      "skew:mean_abstract_top36\n",
      "skew:mean_abstract_top37\n",
      "skew:mean_abstract_top38\n",
      "skew:sum_abstract_top40\n",
      "skew:mean_abstract_top40\n",
      "skew:std_abstract_top40\n",
      "skew:mean_abstract_top41\n",
      "skew:skew_abstract_top41\n",
      "skew:std_abstract_top41\n",
      "skew:mean_abstract_top42\n",
      "skew:skew_abstract_top42\n",
      "skew:std_abstract_top42\n",
      "skew:mean_abstract_top43\n",
      "skew:std_abstract_top43\n",
      "skew:mean_abstract_top44\n",
      "skew:std_abstract_top44\n",
      "skew:mean_abstract_top45\n",
      "skew:std_abstract_top45\n",
      "skew:mean_abstract_top46\n",
      "skew:std_abstract_top46\n",
      "skew:mean_abstract_top47\n",
      "skew:std_abstract_top47\n",
      "skew:mean_abstract_top48\n",
      "skew:std_abstract_top48\n",
      "skew:mean_abstract_top49\n",
      "skew:skew_abstract_top49\n",
      "skew:std_abstract_top49\n",
      "skew:mean_abstract_top50\n",
      "skew:std_abstract_top50\n",
      "skew:skew_abstract_top51\n",
      "skew:mean_abstract_top52\n",
      "skew:skew_abstract_top52\n",
      "skew:std_abstract_top52\n",
      "skew:mean_abstract_top53\n",
      "skew:std_abstract_top53\n",
      "skew:mean_abstract_top54\n",
      "skew:std_abstract_top54\n",
      "skew:mean_abstract_top55\n",
      "skew:std_abstract_top55\n",
      "skew:mean_abstract_top56\n",
      "skew:std_abstract_top56\n",
      "skew:mean_abstract_top57\n",
      "skew:sum_abstract_top58\n",
      "skew:mean_abstract_top58\n",
      "skew:skew_abstract_top58\n",
      "skew:std_abstract_top58\n",
      "skew:mean_abstract_top59\n",
      "skew:std_abstract_top59\n",
      "skew:mean_abstract_top60\n",
      "skew:std_abstract_top60\n",
      "skew:skew_abstract_top61\n",
      "skew:mean_abstract_top62\n",
      "skew:skew_abstract_top62\n",
      "skew:std_abstract_top62\n",
      "skew:mean_abstract_top63\n",
      "skew:skew_abstract_top63\n",
      "skew:std_abstract_top63\n",
      "skew:mean_abstract_top64\n",
      "skew:mean_abstract_top65\n",
      "skew:skew_abstract_top65\n",
      "skew:std_abstract_top65\n",
      "skew:mean_abstract_top66\n",
      "skew:std_abstract_top66\n",
      "skew:mean_abstract_top67\n",
      "skew:sum_abstract_top68\n",
      "skew:mean_abstract_top68\n",
      "skew:std_abstract_top68\n",
      "skew:mean_abstract_top69\n",
      "skew:skew_abstract_top69\n",
      "skew:mean_abstract_top71\n",
      "skew:skew_abstract_top71\n",
      "skew:std_abstract_top71\n",
      "skew:mean_abstract_top72\n",
      "skew:std_abstract_top72\n",
      "skew:mean_abstract_top73\n",
      "skew:skew_abstract_top73\n",
      "skew:std_abstract_top73\n",
      "skew:mean_abstract_top74\n",
      "skew:std_abstract_top74\n",
      "skew:mean_abstract_top75\n",
      "skew:skew_abstract_top75\n",
      "skew:std_abstract_top75\n",
      "skew:mean_abstract_top76\n",
      "skew:std_abstract_top76\n",
      "skew:mean_abstract_top77\n",
      "skew:skew_abstract_top77\n",
      "skew:std_abstract_top77\n",
      "skew:mean_abstract_top78\n",
      "skew:skew_abstract_top78\n",
      "skew:std_abstract_top78\n",
      "skew:mean_abstract_top80\n",
      "skew:std_abstract_top80\n",
      "skew:mean_abstract_top81\n",
      "skew:std_abstract_top81\n",
      "skew:mean_abstract_top82\n",
      "skew:std_abstract_top82\n",
      "skew:sum_abstract_top83\n",
      "skew:mean_abstract_top83\n",
      "skew:skew_abstract_top83\n",
      "skew:std_abstract_top83\n",
      "skew:mean_abstract_top84\n",
      "skew:std_abstract_top84\n",
      "skew:mean_abstract_top85\n",
      "skew:std_abstract_top85\n",
      "skew:mean_abstract_top86\n",
      "skew:skew_abstract_top86\n",
      "skew:std_abstract_top86\n",
      "skew:mean_abstract_top87\n",
      "skew:skew_abstract_top87\n",
      "skew:std_abstract_top87\n",
      "skew:mean_abstract_top89\n",
      "skew:sum_abstract_top90\n",
      "skew:mean_abstract_top90\n",
      "skew:skew_abstract_top90\n",
      "skew:std_abstract_top90\n",
      "skew:mean_abstract_top91\n",
      "skew:mean_abstract_top93\n",
      "skew:mean_abstract_top94\n",
      "skew:std_abstract_top94\n",
      "skew:skew_abstract_top95\n",
      "skew:mean_abstract_top96\n",
      "skew:std_abstract_top96\n",
      "skew:sum_abstract_top97\n",
      "skew:mean_abstract_top97\n",
      "skew:skew_abstract_top97\n",
      "skew:mean_abstract_top98\n",
      "skew:skew_abstract_top98\n",
      "skew:std_abstract_top98\n",
      "skew:sum_abstract_top99\n",
      "skew:mean_abstract_top99\n",
      "skew:std_abstract_top99\n",
      "skew:sum_category\n",
      "skew:sum_category_0\n",
      "skew:sum_category_1\n",
      "skew:mean_category_1\n",
      "skew:std_category_1\n",
      "skew:mean_category_2\n",
      "skew:skew_category_2\n",
      "skew:sum_category_3\n",
      "skew:mean_category_3\n",
      "skew:skew_category_3\n",
      "skew:std_category_3\n",
      "skew:skew_category_4\n",
      "skew:sum_category_5\n",
      "skew:mean_category_5\n",
      "skew:sum_category_6\n",
      "skew:mean_category_6\n",
      "skew:std_category_6\n",
      "skew:skew_category_8\n",
      "skew:sum_category_9\n",
      "skew:mean_category_9\n",
      "skew:mean_category_10\n",
      "skew:skew_category_10\n",
      "skew:std_category_10\n",
      "skew:mean_category_11\n",
      "skew:skew_category_11\n",
      "skew:sum_category_12\n",
      "skew:mean_category_12\n",
      "skew:skew_category_12\n",
      "skew:std_category_12\n",
      "skew:mean_category_13\n",
      "skew:title_ari/year\n",
      "skew:title_ari/sum_abs_wordlen\n",
      "skew:author_count+venue_stdwordlen\n",
      "skew:author_count*venue_stdwordlen\n",
      "skew:author_count/venue_stdwordlen\n",
      "skew:author_count+year\n",
      "skew:author_count*year\n",
      "skew:author_count/year\n",
      "skew:author_count+mean_org_author_count\n",
      "skew:author_count-mean_org_author_count\n",
      "skew:author_count*mean_org_author_count\n",
      "skew:author_count+total_len\n",
      "skew:author_count*total_len\n",
      "skew:author_count/total_len\n",
      "skew:author_count+gap_author_count\n",
      "skew:author_count+mean_abs_wordlen\n",
      "skew:author_count*mean_abs_wordlen\n",
      "skew:author_count/mean_abs_wordlen\n",
      "skew:author_count+std_abs_wordlen\n",
      "skew:author_count*std_abs_wordlen\n",
      "skew:author_count/std_abs_wordlen\n",
      "skew:author_count*sum_abs_wordlen\n",
      "skew:author_count/sum_abs_wordlen\n",
      "skew:author_count+keywords_len_mean\n",
      "skew:author_count*keywords_len_mean\n",
      "skew:author_count/keywords_len_mean\n",
      "skew:author_count+keywords_len_std\n",
      "skew:author_count*keywords_len_std\n",
      "skew:author_count/keywords_len_std\n",
      "skew:venue_stdwordlen+mean_org_author_count\n",
      "skew:venue_stdwordlen*mean_org_author_count\n",
      "skew:venue_stdwordlen/mean_org_author_count\n",
      "skew:venue_stdwordlen+total_len\n",
      "skew:venue_stdwordlen*total_len\n",
      "skew:venue_stdwordlen/total_len\n",
      "skew:venue_stdwordlen+mean_abs_wordlen\n",
      "skew:venue_stdwordlen*mean_abs_wordlen\n",
      "skew:venue_stdwordlen+std_abs_wordlen\n",
      "skew:venue_stdwordlen*std_abs_wordlen\n",
      "skew:venue_stdwordlen*sum_abs_wordlen\n",
      "skew:venue_stdwordlen/sum_abs_wordlen\n",
      "skew:venue_stdwordlen+keywords_len_mean\n",
      "skew:venue_stdwordlen*keywords_len_mean\n",
      "skew:venue_stdwordlen/keywords_len_mean\n",
      "skew:venue_stdwordlen+keywords_len_std\n",
      "skew:venue_stdwordlen*keywords_len_std\n",
      "skew:venue_stdwordlen/keywords_len_std\n",
      "skew:year+mean_org_author_count\n",
      "skew:year*mean_org_author_count\n",
      "skew:year/mean_org_author_count\n",
      "skew:year+total_len\n",
      "skew:year*total_len\n",
      "skew:year/total_len\n",
      "skew:year-gap_author_count\n",
      "skew:year+mean_abs_wordlen\n",
      "skew:year*mean_abs_wordlen\n",
      "skew:year/mean_abs_wordlen\n",
      "skew:year*std_abs_wordlen\n",
      "skew:year/std_abs_wordlen\n",
      "skew:year+sum_abs_wordlen\n",
      "skew:year/sum_abs_wordlen\n",
      "skew:year+keywords_len_mean\n",
      "skew:year*keywords_len_mean\n",
      "skew:year/keywords_len_mean\n",
      "skew:year*keywords_len_std\n",
      "skew:year/keywords_len_std\n",
      "skew:mean_org_author_count+total_len\n",
      "skew:mean_org_author_count*total_len\n",
      "skew:mean_org_author_count/total_len\n",
      "skew:mean_org_author_count+mean_abs_wordlen\n",
      "skew:mean_org_author_count*mean_abs_wordlen\n",
      "skew:mean_org_author_count/mean_abs_wordlen\n",
      "skew:mean_org_author_count+std_abs_wordlen\n",
      "skew:mean_org_author_count*std_abs_wordlen\n",
      "skew:mean_org_author_count/std_abs_wordlen\n",
      "skew:mean_org_author_count*sum_abs_wordlen\n",
      "skew:mean_org_author_count/sum_abs_wordlen\n",
      "skew:mean_org_author_count+keywords_len_mean\n",
      "skew:mean_org_author_count*keywords_len_mean\n",
      "skew:mean_org_author_count/keywords_len_mean\n",
      "skew:mean_org_author_count+keywords_len_std\n",
      "skew:mean_org_author_count*keywords_len_std\n",
      "skew:mean_org_author_count/keywords_len_std\n",
      "skew:total_len*mean_abs_wordlen\n",
      "skew:total_len/mean_abs_wordlen\n",
      "skew:total_len*std_abs_wordlen\n",
      "skew:total_len/std_abs_wordlen\n",
      "skew:total_len-sum_abs_wordlen\n",
      "skew:total_len/sum_abs_wordlen\n",
      "skew:total_len+keywords_len_mean\n",
      "skew:total_len*keywords_len_mean\n",
      "skew:total_len/keywords_len_mean\n",
      "skew:total_len+keywords_len_std\n",
      "skew:total_len-keywords_len_std\n",
      "skew:total_len*keywords_len_std\n",
      "skew:total_len/keywords_len_std\n",
      "skew:mean_abs_wordlen+std_abs_wordlen\n",
      "skew:mean_abs_wordlen*std_abs_wordlen\n",
      "skew:mean_abs_wordlen/std_abs_wordlen\n",
      "skew:mean_abs_wordlen*sum_abs_wordlen\n",
      "skew:mean_abs_wordlen/sum_abs_wordlen\n",
      "skew:mean_abs_wordlen+keywords_len_mean\n",
      "skew:mean_abs_wordlen*keywords_len_mean\n",
      "skew:mean_abs_wordlen/keywords_len_mean\n",
      "skew:mean_abs_wordlen+keywords_len_std\n",
      "skew:mean_abs_wordlen*keywords_len_std\n",
      "skew:mean_abs_wordlen/keywords_len_std\n",
      "skew:std_abs_wordlen*sum_abs_wordlen\n",
      "skew:std_abs_wordlen/sum_abs_wordlen\n",
      "skew:std_abs_wordlen+keywords_len_mean\n",
      "skew:std_abs_wordlen*keywords_len_mean\n",
      "skew:std_abs_wordlen/keywords_len_mean\n",
      "skew:std_abs_wordlen+keywords_len_std\n",
      "skew:std_abs_wordlen*keywords_len_std\n",
      "skew:std_abs_wordlen/keywords_len_std\n",
      "skew:sum_abs_wordlen+keywords_len_mean\n",
      "skew:sum_abs_wordlen*keywords_len_mean\n",
      "skew:sum_abs_wordlen/keywords_len_mean\n",
      "skew:sum_abs_wordlen+keywords_len_std\n",
      "skew:sum_abs_wordlen*keywords_len_std\n",
      "skew:sum_abs_wordlen/keywords_len_std\n",
      "skew:keywords_len_mean+keywords_len_std\n",
      "skew:keywords_len_mean*keywords_len_std\n",
      "skew:keywords_len_mean/keywords_len_std\n"
     ]
    }
   ],
   "source": [
    "train_feats.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "valid_feats.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "for col in valid_feats.columns:\n",
    "    #数据呈现右偏,并且可以进行log1p处理\n",
    "    if (train_feats[col].skew()>1) and train_feats[col].min()>-1:\n",
    "        print(f\"skew:{col}\")\n",
    "        train_feats[col]=np.log1p(train_feats[col])\n",
    "        valid_feats[col]=np.log1p(valid_feats[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37e66f0",
   "metadata": {
    "papermill": {
     "duration": 0.013837,
     "end_time": "2024-06-08T05:13:30.585002",
     "exception": false,
     "start_time": "2024-06-08T05:13:30.571165",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 处在边界又出现次数少,换成np.nan ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74085b30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T05:13:30.615935Z",
     "iopub.status.busy": "2024-06-08T05:13:30.615523Z",
     "iopub.status.idle": "2024-06-08T05:13:39.054727Z",
     "shell.execute_reply": "2024-06-08T05:13:39.053242Z"
    },
    "papermill": {
     "duration": 8.458187,
     "end_time": "2024-06-08T05:13:39.057944",
     "exception": false,
     "start_time": "2024-06-08T05:13:30.599757",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:venue_maxwordlen\n",
      "1:title_top13\n",
      "1:title_top77\n",
      "1:abstract_top12\n",
      "1:abstract_top15\n",
      "1:abstract_top16\n",
      "2:max_title_word_maxlen\n",
      "1:mean_title_top16\n",
      "1:mean_title_top17\n",
      "1:mean_title_top50\n",
      "1:mean_title_top51\n",
      "2:skew_title_top64\n",
      "1:mean_title_top70\n",
      "2:skew_abstract_top80\n",
      "1:mean_abstract_top91\n"
     ]
    }
   ],
   "source": [
    "for col in valid_feats.columns:\n",
    "    #长度,个数,词袋统计一般是int类型的数据,也可以当作是类别型的变量,统计一下value_count\n",
    "    #如果一个类别型变量出现次数很少,把它当np.nan.\n",
    "    if ('len' in col) or ('count' in col) or ('top' in col ):\n",
    "        tmp=train_feats[col].value_counts().to_frame().reset_index()\n",
    "        margin=10\n",
    "        #我这里打算把出现次数少的类别型变量当作np.nan,设置nan的占比为数据的0.001\n",
    "        if tmp[tmp['count']<=margin]['count'].sum()<len(train_feats)*0.0025:\n",
    "            #如果出现次数很少的values都是大于出现次数很多的values\n",
    "            less_value_min=tmp[tmp['count']<=margin][col].min()\n",
    "            more_value_max=tmp[tmp['count']>margin][col].max()\n",
    "            less_value_max=tmp[tmp['count']<=margin][col].max()\n",
    "            more_value_min=tmp[tmp['count']>margin][col].min()\n",
    "            if less_value_min>more_value_max:\n",
    "                print(f\"1:{col}\")\n",
    "                #大于这个阈值全为np.nan\n",
    "                value=(less_value_min+more_value_max)/2\n",
    "                train_feats.loc[train_feats[col] >= value, col] = np.nan\n",
    "                valid_feats.loc[valid_feats[col] >= value, col] = np.nan\n",
    "            if less_value_max<more_value_min:\n",
    "                print(f\"2:{col}\")\n",
    "                #大于这个阈值全为np.nan\n",
    "                value=(less_value_max+more_value_min)/2\n",
    "                train_feats.loc[train_feats[col] <= value, col] = np.nan\n",
    "                valid_feats.loc[valid_feats[col] <= value, col] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b068f30",
   "metadata": {
    "papermill": {
     "duration": 0.014839,
     "end_time": "2024-06-08T05:13:39.087997",
     "exception": false,
     "start_time": "2024-06-08T05:13:39.073158",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 想title_len,title_wordcount之类的值如果等于0的话其实就是缺失值,如果缺失值少的话用均值替代掉。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8149299c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T05:13:39.120126Z",
     "iopub.status.busy": "2024-06-08T05:13:39.119643Z",
     "iopub.status.idle": "2024-06-08T05:14:27.717761Z",
     "shell.execute_reply": "2024-06-08T05:14:27.716179Z"
    },
    "papermill": {
     "duration": 48.632692,
     "end_time": "2024-06-08T05:14:27.735648",
     "exception": false,
     "start_time": "2024-06-08T05:13:39.102956",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(zerocols):22,zerocols:['title_word_maxlen', 'title_word_meanlen', 'title_word_sumlen', 'keywords_len_max', 'keywords_len_median', 'keywords_len_mean', 'venue_maxwordlen', 'venue_medianwordlen', 'venue_meanwordlen', 'venue_sumwordlen', 'mean_title_wordlen', 'mean_venue_wordlen', 'total_len', 'median_title_word_meanlen', 'max_max_orgs_len', 'max_median_orgs_len', 'max_sum_orgs_len', 'mean_keywords_count', 'max_keywords_count', 'mean_keywords_len_sum', 'max_keywords_len_sum', 'median_venue_sumwordlen']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authorid</th>\n",
       "      <th>title_len</th>\n",
       "      <th>title_wordcount</th>\n",
       "      <th>title_ari</th>\n",
       "      <th>title_McAlpine_EFLAW</th>\n",
       "      <th>title_CLRI</th>\n",
       "      <th>title_word_maxlen</th>\n",
       "      <th>title_word_meanlen</th>\n",
       "      <th>title_word_stdlen</th>\n",
       "      <th>title_word_sumlen</th>\n",
       "      <th>...</th>\n",
       "      <th>sum_abs_wordlen*keywords_len_mean</th>\n",
       "      <th>sum_abs_wordlen/keywords_len_mean</th>\n",
       "      <th>sum_abs_wordlen+keywords_len_std</th>\n",
       "      <th>sum_abs_wordlen-keywords_len_std</th>\n",
       "      <th>sum_abs_wordlen*keywords_len_std</th>\n",
       "      <th>sum_abs_wordlen/keywords_len_std</th>\n",
       "      <th>keywords_len_mean+keywords_len_std</th>\n",
       "      <th>keywords_len_mean-keywords_len_std</th>\n",
       "      <th>keywords_len_mean*keywords_len_std</th>\n",
       "      <th>keywords_len_mean/keywords_len_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.795791</td>\n",
       "      <td>2.944439</td>\n",
       "      <td>18.970000</td>\n",
       "      <td>3.610918</td>\n",
       "      <td>21.755556</td>\n",
       "      <td>2.708050</td>\n",
       "      <td>1.905419</td>\n",
       "      <td>1.506033</td>\n",
       "      <td>4.644391</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.820282</td>\n",
       "      <td>2.772589</td>\n",
       "      <td>21.148235</td>\n",
       "      <td>3.555348</td>\n",
       "      <td>25.002353</td>\n",
       "      <td>2.564949</td>\n",
       "      <td>2.112231</td>\n",
       "      <td>1.519022</td>\n",
       "      <td>4.700480</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.615121</td>\n",
       "      <td>2.639057</td>\n",
       "      <td>15.712857</td>\n",
       "      <td>3.091042</td>\n",
       "      <td>21.971429</td>\n",
       "      <td>2.708050</td>\n",
       "      <td>2.050171</td>\n",
       "      <td>1.525656</td>\n",
       "      <td>4.488636</td>\n",
       "      <td>...</td>\n",
       "      <td>9.340140</td>\n",
       "      <td>4.114444</td>\n",
       "      <td>6.728071</td>\n",
       "      <td>821.466433</td>\n",
       "      <td>8.596151</td>\n",
       "      <td>4.849920</td>\n",
       "      <td>3.057935</td>\n",
       "      <td>7.216433</td>\n",
       "      <td>4.509062</td>\n",
       "      <td>1.132858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.644391</td>\n",
       "      <td>2.708050</td>\n",
       "      <td>20.222143</td>\n",
       "      <td>3.367296</td>\n",
       "      <td>25.345714</td>\n",
       "      <td>2.484907</td>\n",
       "      <td>2.005334</td>\n",
       "      <td>1.396379</td>\n",
       "      <td>4.510860</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.897840</td>\n",
       "      <td>2.708050</td>\n",
       "      <td>24.082000</td>\n",
       "      <td>3.157000</td>\n",
       "      <td>32.389333</td>\n",
       "      <td>3.044522</td>\n",
       "      <td>2.258782</td>\n",
       "      <td>1.721640</td>\n",
       "      <td>4.795791</td>\n",
       "      <td>...</td>\n",
       "      <td>10.029997</td>\n",
       "      <td>4.471427</td>\n",
       "      <td>7.250074</td>\n",
       "      <td>1394.790330</td>\n",
       "      <td>9.071164</td>\n",
       "      <td>5.423256</td>\n",
       "      <td>3.153149</td>\n",
       "      <td>9.990330</td>\n",
       "      <td>4.621011</td>\n",
       "      <td>1.283385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1250 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   authorid  title_len  title_wordcount  title_ari  title_McAlpine_EFLAW  \\\n",
       "0       0.0   4.795791         2.944439  18.970000              3.610918   \n",
       "1       0.0   4.820282         2.772589  21.148235              3.555348   \n",
       "2       0.0   4.615121         2.639057  15.712857              3.091042   \n",
       "3       0.0   4.644391         2.708050  20.222143              3.367296   \n",
       "4       0.0   4.897840         2.708050  24.082000              3.157000   \n",
       "\n",
       "   title_CLRI  title_word_maxlen  title_word_meanlen  title_word_stdlen  \\\n",
       "0   21.755556           2.708050            1.905419           1.506033   \n",
       "1   25.002353           2.564949            2.112231           1.519022   \n",
       "2   21.971429           2.708050            2.050171           1.525656   \n",
       "3   25.345714           2.484907            2.005334           1.396379   \n",
       "4   32.389333           3.044522            2.258782           1.721640   \n",
       "\n",
       "   title_word_sumlen  ...  sum_abs_wordlen*keywords_len_mean  \\\n",
       "0           4.644391  ...                                NaN   \n",
       "1           4.700480  ...                                NaN   \n",
       "2           4.488636  ...                           9.340140   \n",
       "3           4.510860  ...                                NaN   \n",
       "4           4.795791  ...                          10.029997   \n",
       "\n",
       "   sum_abs_wordlen/keywords_len_mean  sum_abs_wordlen+keywords_len_std  \\\n",
       "0                                NaN                               NaN   \n",
       "1                                NaN                               NaN   \n",
       "2                           4.114444                          6.728071   \n",
       "3                                NaN                               NaN   \n",
       "4                           4.471427                          7.250074   \n",
       "\n",
       "   sum_abs_wordlen-keywords_len_std  sum_abs_wordlen*keywords_len_std  \\\n",
       "0                               NaN                               NaN   \n",
       "1                               NaN                               NaN   \n",
       "2                        821.466433                          8.596151   \n",
       "3                               NaN                               NaN   \n",
       "4                       1394.790330                          9.071164   \n",
       "\n",
       "   sum_abs_wordlen/keywords_len_std  keywords_len_mean+keywords_len_std  \\\n",
       "0                               NaN                                 NaN   \n",
       "1                               NaN                                 NaN   \n",
       "2                          4.849920                            3.057935   \n",
       "3                               NaN                                 NaN   \n",
       "4                          5.423256                            3.153149   \n",
       "\n",
       "   keywords_len_mean-keywords_len_std  keywords_len_mean*keywords_len_std  \\\n",
       "0                                 NaN                                 NaN   \n",
       "1                                 NaN                                 NaN   \n",
       "2                            7.216433                            4.509062   \n",
       "3                                 NaN                                 NaN   \n",
       "4                            9.990330                            4.621011   \n",
       "\n",
       "   keywords_len_mean/keywords_len_std  \n",
       "0                                 NaN  \n",
       "1                                 NaN  \n",
       "2                            1.132858  \n",
       "3                                 NaN  \n",
       "4                            1.283385  \n",
       "\n",
       "[5 rows x 1250 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zerocols=[]\n",
    "for col in valid_feats.columns:\n",
    "    if (('len' in col) or ('count' in col)) and \\\n",
    "        ('+' not in col) and ('-' not in col) and ('*' not in col)and ('/' not in col)\\\n",
    "        and ('gap' not in col ) and ('skew' not in col ) and ('std' not in col ):\n",
    "        df=train_feats[train_feats[col]==0]\n",
    "        if (len(df)>0) and (len(df)/len(train_feats)<0.15):#如果0也就是缺失值占比不是占大多数的话\n",
    "            zerocols.append(col)\n",
    "print(f\"len(zerocols):{len(zerocols)},zerocols:{zerocols}\")\n",
    "for col in zerocols:\n",
    "    mean=train_feats[train_feats[col]!=0][col].mean()\n",
    "    train_feats[col]=train_feats[col].replace(0, mean)\n",
    "    valid_feats[col]=valid_feats[col].replace(0, mean)\n",
    "\n",
    "train_feats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49300df1",
   "metadata": {
    "papermill": {
     "duration": 0.015721,
     "end_time": "2024-06-08T05:14:27.767587",
     "exception": false,
     "start_time": "2024-06-08T05:14:27.751866",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 这个就是节省内存的一个函数,与特征工程无关。简单来说就是一个数据能用8位存储就不用16位存储,能用16位存储就不用32位存储。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51e38ac1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T05:14:27.802824Z",
     "iopub.status.busy": "2024-06-08T05:14:27.802375Z",
     "iopub.status.idle": "2024-06-08T05:14:32.954644Z",
     "shell.execute_reply": "2024-06-08T05:14:32.953117Z"
    },
    "papermill": {
     "duration": 5.173698,
     "end_time": "2024-06-08T05:14:32.957746",
     "exception": false,
     "start_time": "2024-06-08T05:14:27.784048",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 1413.54 MB\n",
      "Memory usage after optimization is: 706.77 MB\n",
      "Decreased by 50.0%\n",
      "Memory usage of dataframe is 1107.21 MB\n",
      "Memory usage after optimization is: 553.94 MB\n",
      "Decreased by 50.0%\n"
     ]
    }
   ],
   "source": [
    "def reduce_mem_usage(df, float16_as32=True):\n",
    "    #memory_usage()是df每列的内存使用量,sum是对它们求和, B->KB->MB\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:#遍历每列的列名\n",
    "        col_type = df[col].dtype#列名的type\n",
    "        if col_type != object and str(col_type)!='category':#不是object也就是说这里处理的是数值类型的变量\n",
    "            c_min,c_max = df[col].min(),df[col].max() #求出这列的最大值和最小值\n",
    "            if str(col_type)[:3] == 'int':#如果是int类型的变量,不管是int8,int16,int32还是int64\n",
    "                #如果这列的取值范围是在int8的取值范围内,那就对类型进行转换 (-128 到 127)\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                #如果这列的取值范围是在int16的取值范围内,那就对类型进行转换(-32,768 到 32,767)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                #如果这列的取值范围是在int32的取值范围内,那就对类型进行转换(-2,147,483,648到2,147,483,647)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                #如果这列的取值范围是在int64的取值范围内,那就对类型进行转换(-9,223,372,036,854,775,808到9,223,372,036,854,775,807)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:#如果是浮点数类型.\n",
    "                #如果数值在float16的取值范围内,如果觉得需要更高精度可以考虑float32\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    if float16_as32:#如果数据需要更高的精度可以选择float32\n",
    "                        df[col] = df[col].astype(np.float32)\n",
    "                    else:\n",
    "                        df[col] = df[col].astype(np.float16)  \n",
    "                #如果数值在float32的取值范围内，对它进行类型转换\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                #如果数值在float64的取值范围内，对它进行类型转换\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    #计算一下结束后的内存\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    #相比一开始的内存减少了百分之多少\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df\n",
    "train_feats=reduce_mem_usage(train_feats, float16_as32=True)\n",
    "valid_feats=reduce_mem_usage(valid_feats, float16_as32=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5edde5cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T05:14:32.996349Z",
     "iopub.status.busy": "2024-06-08T05:14:32.995903Z",
     "iopub.status.idle": "2024-06-08T05:25:28.798681Z",
     "shell.execute_reply": "2024-06-08T05:25:28.797217Z"
    },
    "papermill": {
     "duration": 655.825539,
     "end_time": "2024-06-08T05:25:28.802231",
     "exception": false,
     "start_time": "2024-06-08T05:14:32.976692",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_feats.to_csv(\"train_feats.csv\",index=None)\n",
    "valid_feats.to_csv(\"valid_feats.csv\",index=None)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5129554,
     "sourceId": 8577770,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 182139590,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30732,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8117.229881,
   "end_time": "2024-06-08T05:25:31.864576",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-06-08T03:10:14.634695",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
