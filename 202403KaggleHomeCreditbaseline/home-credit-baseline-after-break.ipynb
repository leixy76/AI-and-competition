{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c451ef5",
   "metadata": {
    "papermill": {
     "duration": 0.005327,
     "end_time": "2024-03-12T01:57:12.495271",
     "exception": false,
     "start_time": "2024-03-12T01:57:12.489944",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Created by yunsuxiaozi 2024/3/12\n",
    "\n",
    "### This is the notebook after a two-week break from the competition,you can check the running time of my program.After the competition restarted, I have experienced \"threw exception\" three times, and here I am trying to implement a baseline with as few files as possible.Linear regression is used as the baseline here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db3c2e8",
   "metadata": {
    "papermill": {
     "duration": 0.004293,
     "end_time": "2024-03-12T01:57:12.504443",
     "exception": false,
     "start_time": "2024-03-12T01:57:12.500150",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54682c9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-12T01:57:12.516559Z",
     "iopub.status.busy": "2024-03-12T01:57:12.515759Z",
     "iopub.status.idle": "2024-03-12T01:57:17.427167Z",
     "shell.execute_reply": "2024-03-12T01:57:17.425870Z"
    },
    "papermill": {
     "duration": 4.920939,
     "end_time": "2024-03-12T01:57:17.429953",
     "exception": false,
     "start_time": "2024-03-12T01:57:12.509014",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this notebook training time is  2024-03-12 01:57:17\n"
     ]
    }
   ],
   "source": [
    "import polars as pl#和pandas类似,但是处理大型数据集有更好的性能.\n",
    "#necessary\n",
    "import pandas as pd#导入csv文件的库\n",
    "import numpy as np#进行矩阵运算的库\n",
    "#model\n",
    "from lightgbm import LGBMClassifier\n",
    "#metric\n",
    "from sklearn.metrics import roc_auc_score#导入roc_auc曲线\n",
    "#KFold是直接分成k折,StratifiedKFold还要考虑每种类别的占比\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.decomposition import TruncatedSVD#截断奇异值分解,是一种数据降维的方法\n",
    "import dill#对对象进行序列化和反序列化(例如保存和加载树模型)\n",
    "import gc#垃圾回收模块\n",
    "import time#标准库的时间模块\n",
    "#为了方便后期调用训练的模型时不会调用错版本,提供模型训练的时间\n",
    "#time.strftime()函数用于将时间对象格式化为字符串，time.localtime()函数返回表示当前本地时间的time.struct_time对象\n",
    "current_time = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\n",
    "print(\"this notebook training time is \", current_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2b5fc3",
   "metadata": {
    "papermill": {
     "duration": 0.004559,
     "end_time": "2024-03-12T01:57:17.439319",
     "exception": false,
     "start_time": "2024-03-12T01:57:17.434760",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Config and random seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4503c3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-12T01:57:17.451283Z",
     "iopub.status.busy": "2024-03-12T01:57:17.450428Z",
     "iopub.status.idle": "2024-03-12T01:57:17.458453Z",
     "shell.execute_reply": "2024-03-12T01:57:17.457121Z"
    },
    "papermill": {
     "duration": 0.01724,
     "end_time": "2024-03-12T01:57:17.461268",
     "exception": false,
     "start_time": "2024-03-12T01:57:17.444028",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#config\n",
    "class Config():\n",
    "    seed=2024\n",
    "    num_folds=10\n",
    "    TARGET_NAME ='target'\n",
    "    batch_size=1000#由于不知道测试数据的大小,所以分批次放入模型.\n",
    "import random#提供了一些用于生成随机数的函数\n",
    "#设置随机种子,保证模型可以复现\n",
    "def seed_everything(seed):\n",
    "    np.random.seed(seed)#numpy的随机种子\n",
    "    random.seed(seed)#python内置的随机种子\n",
    "seed_everything(Config.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790cecfa",
   "metadata": {
    "papermill": {
     "duration": 0.004523,
     "end_time": "2024-03-12T01:57:17.470973",
     "exception": false,
     "start_time": "2024-03-12T01:57:17.466450",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Feature engineer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "858b14ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-12T01:57:17.482791Z",
     "iopub.status.busy": "2024-03-12T01:57:17.482344Z",
     "iopub.status.idle": "2024-03-12T01:57:33.771011Z",
     "shell.execute_reply": "2024-03-12T01:57:33.769834Z"
    },
    "papermill": {
     "duration": 16.297813,
     "end_time": "2024-03-12T01:57:33.773587",
     "exception": false,
     "start_time": "2024-03-12T01:57:17.475774",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Feature Engineer-------------\n",
      "\n",
      "base file\n",
      "deposit file num 1\n",
      "static_cb_file num 1\n",
      "len(train_feats):771863\n",
      "base file\n",
      "deposit file num 1\n",
      "static_cb_file num 1\n",
      "len(test_feats):10\n",
      "---------Feature Transformer-------------\n",
      "\n",
      "----------string one hot encoder ****\n",
      "one_hot_10:assignmentdate_238D\n",
      "one_hot_10:birthdate_574D\n",
      "one_hot_2:description_5085714M\n",
      "one_hot_10:education_1103M\n",
      "one_hot_10:education_88M\n",
      "one_hot_10:maritalst_385M\n",
      "one_hot_10:maritalst_893M\n",
      "one_hot_10:requesttype_4525192L\n",
      "one_hot_10:responsedate_1012D\n",
      "----------drop other string or unique value full null value ****\n",
      "len(drop_cols):48,drop_cols:['date_decision', 'std_deposit_amount_416A', 'std_deposit_num_group1', 'min_deposit_num_group1', 'assignmentdate_4527235D', 'assignmentdate_4955616D', 'contractssum_5085716L', 'dateofbirth_337D', 'dateofbirth_342D', 'for3years_128L', 'for3years_504L', 'for3years_584L', 'formonth_118L', 'formonth_206L', 'formonth_535L', 'forquarter_1017L', 'forquarter_462L', 'forquarter_634L', 'fortoday_1092L', 'forweek_1077L', 'forweek_528L', 'forweek_601L', 'foryear_618L', 'foryear_818L', 'foryear_850L', 'pmtaverage_3A', 'pmtaverage_4527227A', 'pmtaverage_4955615A', 'pmtcount_4527229L', 'pmtcount_4955617L', 'pmtcount_693L', 'pmtscount_423L', 'pmtssum_45A', 'responsedate_4527233D', 'responsedate_4917613D', 'riskassesment_302T', 'riskassesment_940T', 'assignmentdate_238D_0', 'birthdate_574D_0', 'education_1103M_5', 'education_88M_5', 'maritalst_385M_6', 'maritalst_893M_6', 'requesttype_4525192L_3', 'responsedate_1012D_0', 'case_id', 'WEEK_NUM', 'MONTH']\n",
      "----------fillna value ****\n",
      "len(drop_cols):48,total_features_count:65\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>max_deposit_amount_416A</th>\n",
       "      <th>mean_deposit_amount_416A</th>\n",
       "      <th>median_deposit_amount_416A</th>\n",
       "      <th>min_deposit_amount_416A</th>\n",
       "      <th>count_deposit_amount_416A</th>\n",
       "      <th>sum_deposit_amount_416A</th>\n",
       "      <th>n_unique_deposit_amount_416A</th>\n",
       "      <th>first_deposit_amount_416A</th>\n",
       "      <th>last_deposit_amount_416A</th>\n",
       "      <th>...</th>\n",
       "      <th>requesttype_4525192L_1</th>\n",
       "      <th>requesttype_4525192L_2</th>\n",
       "      <th>responsedate_1012D_1</th>\n",
       "      <th>responsedate_1012D_2</th>\n",
       "      <th>responsedate_1012D_3</th>\n",
       "      <th>responsedate_1012D_4</th>\n",
       "      <th>responsedate_1012D_5</th>\n",
       "      <th>responsedate_1012D_6</th>\n",
       "      <th>responsedate_1012D_7</th>\n",
       "      <th>responsedate_1012D_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   target  max_deposit_amount_416A  mean_deposit_amount_416A  \\\n",
       "0       0                     -1.0                      -1.0   \n",
       "1       0                     -1.0                      -1.0   \n",
       "2       0                     -1.0                      -1.0   \n",
       "3       0                     -1.0                      -1.0   \n",
       "4       0                     -1.0                      -1.0   \n",
       "\n",
       "   median_deposit_amount_416A  min_deposit_amount_416A  \\\n",
       "0                        -1.0                     -1.0   \n",
       "1                        -1.0                     -1.0   \n",
       "2                        -1.0                     -1.0   \n",
       "3                        -1.0                     -1.0   \n",
       "4                        -1.0                     -1.0   \n",
       "\n",
       "   count_deposit_amount_416A  sum_deposit_amount_416A  \\\n",
       "0                       -1.0                     -1.0   \n",
       "1                       -1.0                     -1.0   \n",
       "2                       -1.0                     -1.0   \n",
       "3                       -1.0                     -1.0   \n",
       "4                       -1.0                     -1.0   \n",
       "\n",
       "   n_unique_deposit_amount_416A  first_deposit_amount_416A  \\\n",
       "0                          -1.0                       -1.0   \n",
       "1                          -1.0                       -1.0   \n",
       "2                          -1.0                       -1.0   \n",
       "3                          -1.0                       -1.0   \n",
       "4                          -1.0                       -1.0   \n",
       "\n",
       "   last_deposit_amount_416A  ...  requesttype_4525192L_1  \\\n",
       "0                      -1.0  ...                       0   \n",
       "1                      -1.0  ...                       1   \n",
       "2                      -1.0  ...                       0   \n",
       "3                      -1.0  ...                       0   \n",
       "4                      -1.0  ...                       0   \n",
       "\n",
       "   requesttype_4525192L_2  responsedate_1012D_1  responsedate_1012D_2  \\\n",
       "0                       0                     0                     0   \n",
       "1                       0                     0                     0   \n",
       "2                       0                     0                     0   \n",
       "3                       0                     0                     0   \n",
       "4                       0                     1                     0   \n",
       "\n",
       "   responsedate_1012D_3  responsedate_1012D_4  responsedate_1012D_5  \\\n",
       "0                     0                     0                     0   \n",
       "1                     0                     0                     0   \n",
       "2                     0                     0                     0   \n",
       "3                     0                     0                     0   \n",
       "4                     0                     0                     0   \n",
       "\n",
       "   responsedate_1012D_6  responsedate_1012D_7  responsedate_1012D_8  \n",
       "0                     0                     0                     0  \n",
       "1                     0                     0                     0  \n",
       "2                     0                     0                     0  \n",
       "3                     0                     0                     0  \n",
       "4                     0                     0                     0  \n",
       "\n",
       "[5 rows x 66 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocessor(mode='train'):#mode='train'|'test'\n",
    "    #base 文件\n",
    "    print(\"base file\")\n",
    "    feats=pl.read_csv(f\"/kaggle/input/home-credit-credit-risk-model-stability/csv_files/{mode}/{mode}_base.csv\")\n",
    "        \n",
    "    print(\"deposit file num 1\")\n",
    "    deposit=pl.read_csv(f\"/kaggle/input/home-credit-credit-risk-model-stability/csv_files/{mode}/{mode}_deposit_1.csv\")\n",
    "    #数值列的特征工程  从1开始是为了把'case_id'去掉    \n",
    "    for idx in range(1,len(deposit.columns)):\n",
    "        col=deposit.columns[idx]\n",
    "        column_type = deposit[col].dtype\n",
    "        is_numeric = (column_type == pl.datatypes.Int64) or (column_type == pl.datatypes.Float64) \n",
    "        if is_numeric:#数值列构造特征\n",
    "            feat=deposit.group_by('case_id').agg( pl.max(col).alias(f\"max_deposit_{col}\"),\n",
    "                                           pl.mean(col).alias(f\"mean_deposit_{col}\"),\n",
    "                                           pl.median(col).alias(f\"median_deposit_{col}\"),\n",
    "                                           pl.std(col).alias(f\"std_deposit_{col}\"),\n",
    "                                           pl.min(col).alias(f\"min_deposit_{col}\"),\n",
    "                                           pl.count(col).alias(f\"count_deposit_{col}\"),\n",
    "                                           pl.sum(col).alias(f\"sum_deposit_{col}\"),\n",
    "                                           pl.n_unique(col).alias(f\"n_unique_deposit_{col}\"),\n",
    "                                           pl.first(col).alias(f\"first_deposit_{col}\"),\n",
    "                                           pl.last(col).alias(f\"last_deposit_{col}\")\n",
    "                                         )\n",
    "            feats=feats.join(feat,on='case_id',how='left')\n",
    "\n",
    "    #static_cb文件\n",
    "    print(\"static_cb_file num 1\")\n",
    "    static_cb=pl.read_csv(f\"/kaggle/input/home-credit-credit-risk-model-stability/csv_files/{mode}/{mode}_static_cb_0.csv\")\n",
    "    feats=feats.join(static_cb,on='case_id',how='left')\n",
    "    del static_cb\n",
    "    gc.collect()#手动触发垃圾回收,强制回收由垃圾回收器标记为未使用的内存\n",
    "     \n",
    "    return feats\n",
    "\n",
    "print(\"---------Feature Engineer-------------\\n\")\n",
    "train_feats=preprocessor(mode='train')\n",
    "#由于这是时间序列数据,加上数据量太大,构造太多的特征就会超内存了,所以这里考虑就用最后一年的数据来训练模型,以达到最好效果.\n",
    "#这里的时间差不多是从2019年10月初开始.\n",
    "train_feats=train_feats.filter(train_feats['WEEK_NUM']>=40)\n",
    "print(f\"len(train_feats):{len(train_feats)}\")\n",
    "\n",
    "test_feats=preprocessor(mode='test')\n",
    "print(f\"len(test_feats):{len(test_feats)}\")\n",
    "\n",
    "print(\"---------Feature Transformer-------------\\n\")\n",
    "\"\"\"\n",
    "下面是对特征进行处理,提取出来的特征最初是有字符串类型和数值类型.\n",
    "1.先对字符串 类别型变量 进行 one hot encoder\n",
    "2.剩下的字符串直接去掉,一列有唯一值的去掉,缺失值占比>0.95的列选择drop.\n",
    "这样数据中就只有数值列了.\n",
    "3.填充缺失值,这里考虑用-1填充.\n",
    "4.数值列先将相关性高达0.99的列只保留一列,其余去掉.\n",
    "5.对相关性高的那些列进行降维处理.\n",
    "\"\"\"\n",
    "\n",
    "#如果打开的两个文件的相同列一个是浮点数类型,一个是object或者str,就把两个都转成浮点数类型.\n",
    "for col in test_feats.columns:\n",
    "    if (train_feats[col].dtype==pl.datatypes.Float64) or (test_feats[col].dtype==pl.datatypes.Float64):\n",
    "        train_feats.with_columns(train_feats[col].cast(pl.datatypes.Float64))\n",
    "        test_feats.with_columns(test_feats[col].cast(pl.datatypes.Float64))\n",
    "train_feats=train_feats.to_pandas()\n",
    "test_feats=test_feats.to_pandas()\n",
    "\n",
    "#对字符串特征列进行独热编码的转换\n",
    "print(\"----------string one hot encoder ****\")\n",
    "for col in test_feats.columns:\n",
    "    n_unique=train_feats[col].nunique()\n",
    "    #如果是类别型变量的话,独热编码转换\n",
    "    #如果类别是2类,像性别一样,如果是(0,1)了,或者说数值类型的话,没必要转换.如果是字符串类型的话,转换成数值\n",
    "    if n_unique==2 and train_feats[col].dtype=='object':\n",
    "        print(f\"one_hot_2:{col}\")\n",
    "        unique=train_feats[col].unique()\n",
    "        #随便选择一个类别进行转换,比如gender='Female'\n",
    "        train_feats[col]=(train_feats[col]==unique[0]).astype(int)\n",
    "        test_feats[col]=(test_feats[col]==unique[0]).astype(int)\n",
    "    elif (n_unique<10) and train_feats[col].dtype=='object':#由于内存有限 类别型变量的n_unique设置为20\n",
    "        print(f\"one_hot_10:{col}\")\n",
    "        unique=train_feats[col].unique()\n",
    "        for idx in range(len(unique)):\n",
    "            if unique[idx]==unique[idx]:#这里是为了避免字符串中存在nan值的情况\n",
    "                train_feats[col+\"_\"+str(idx)]=(train_feats[col]==unique[idx]).astype(int)\n",
    "                test_feats[col+\"_\"+str(idx)]=(test_feats[col]==unique[idx]).astype(int)\n",
    "        train_feats.drop([col],axis=1,inplace=True)\n",
    "        test_feats.drop([col],axis=1,inplace=True)\n",
    "\n",
    "#如果是字符串的列或者一列只有唯一值,去掉\n",
    "print(\"----------drop other string or unique value full null value ****\")\n",
    "drop_cols=[]\n",
    "for col in test_feats.columns:\n",
    "    if (train_feats[col].dtype=='object') or (test_feats[col].dtype=='object') \\\n",
    "        or (train_feats[col].nunique()==1) or train_feats[col].isna().mean()>0.95:\n",
    "        drop_cols+=[col]\n",
    "#case_id目前看来和id一样没什么用,WEEK_NUM在测试数据中比训练数据大.\n",
    "drop_cols+=['case_id','WEEK_NUM','MONTH']\n",
    "print(f\"len(drop_cols):{len(drop_cols)},drop_cols:{drop_cols}\")\n",
    "train_feats=train_feats.drop(drop_cols,axis=1)\n",
    "test_feats=test_feats.drop(drop_cols,axis=1)\n",
    "\n",
    "print(\"----------fillna value ****\")\n",
    "train_feats.fillna(-1,inplace=True)\n",
    "test_feats.fillna(-1,inplace=True)\n",
    "\n",
    "print(f\"len(drop_cols):{len(drop_cols)},total_features_count:{len(test_feats.columns)}\")\n",
    "train_feats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7972c5f7",
   "metadata": {
    "papermill": {
     "duration": 0.006767,
     "end_time": "2024-03-12T01:57:33.787560",
     "exception": false,
     "start_time": "2024-03-12T01:57:33.780793",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4737accd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-12T01:57:33.803771Z",
     "iopub.status.busy": "2024-03-12T01:57:33.803310Z",
     "iopub.status.idle": "2024-03-12T01:57:34.787295Z",
     "shell.execute_reply": "2024-03-12T01:57:34.786195Z"
    },
    "papermill": {
     "duration": 0.995322,
     "end_time": "2024-03-12T01:57:34.789880",
     "exception": false,
     "start_time": "2024-03-12T01:57:33.794558",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53,\n",
       " ['max_deposit_amount_416A',\n",
       "  'mean_deposit_amount_416A',\n",
       "  'median_deposit_amount_416A',\n",
       "  'min_deposit_amount_416A',\n",
       "  'count_deposit_amount_416A',\n",
       "  'sum_deposit_amount_416A',\n",
       "  'n_unique_deposit_amount_416A',\n",
       "  'first_deposit_amount_416A',\n",
       "  'last_deposit_amount_416A',\n",
       "  'max_deposit_num_group1',\n",
       "  'mean_deposit_num_group1',\n",
       "  'median_deposit_num_group1',\n",
       "  'count_deposit_num_group1',\n",
       "  'sum_deposit_num_group1',\n",
       "  'n_unique_deposit_num_group1',\n",
       "  'first_deposit_num_group1',\n",
       "  'last_deposit_num_group1',\n",
       "  'days120_123L',\n",
       "  'days180_256L',\n",
       "  'days30_165L',\n",
       "  'days360_512L',\n",
       "  'days90_310L',\n",
       "  'description_5085714M',\n",
       "  'firstquarter_103L',\n",
       "  'fourthquarter_440L',\n",
       "  'numberofqueries_373L',\n",
       "  'secondquarter_766L',\n",
       "  'thirdquarter_1082L',\n",
       "  'assignmentdate_238D_1',\n",
       "  'education_1103M_0',\n",
       "  'education_1103M_1',\n",
       "  'education_1103M_2',\n",
       "  'education_1103M_3',\n",
       "  'education_1103M_4',\n",
       "  'education_88M_0',\n",
       "  'education_88M_1',\n",
       "  'education_88M_2',\n",
       "  'education_88M_3',\n",
       "  'maritalst_385M_0',\n",
       "  'maritalst_385M_1',\n",
       "  'maritalst_385M_2',\n",
       "  'maritalst_385M_4',\n",
       "  'maritalst_385M_5',\n",
       "  'maritalst_893M_0',\n",
       "  'maritalst_893M_1',\n",
       "  'maritalst_893M_2',\n",
       "  'maritalst_893M_3',\n",
       "  'maritalst_893M_5',\n",
       "  'requesttype_4525192L_0',\n",
       "  'requesttype_4525192L_1',\n",
       "  'requesttype_4525192L_2',\n",
       "  'responsedate_1012D_4',\n",
       "  'responsedate_1012D_7'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#我们这里就是找相关性特别高的特征对,可以考虑对它们进行降维操作.\n",
    "#计算两组变量的皮尔逊相关系数\n",
    "def pearson_corr(x1,x2):\n",
    "    \"\"\"\n",
    "    x1,x2:np.array\n",
    "    \"\"\"\n",
    "    mean_x1=np.mean(x1)\n",
    "    mean_x2=np.mean(x2)\n",
    "    std_x1=np.std(x1)\n",
    "    std_x2=np.std(x2)\n",
    "    pearson=np.mean((x1-mean_x1)*(x2-mean_x2))/(std_x1*std_x2)\n",
    "    return pearson\n",
    "#有没有和target相关性特别高的特征,拿来做逻辑回归\n",
    "choose_cols=[]\n",
    "for col in train_feats.columns:\n",
    "    if col!='target':\n",
    "        pearson=pearson_corr(train_feats[col].values,train_feats['target'].values) \n",
    "        if abs(pearson)>0.002:\n",
    "            choose_cols.append(col)\n",
    "len(choose_cols),choose_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa3d6e7",
   "metadata": {
    "papermill": {
     "duration": 0.006895,
     "end_time": "2024-03-12T01:57:34.804117",
     "exception": false,
     "start_time": "2024-03-12T01:57:34.797222",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### K-fold and Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a129ce1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-12T01:57:34.820391Z",
     "iopub.status.busy": "2024-03-12T01:57:34.819957Z",
     "iopub.status.idle": "2024-03-12T01:58:24.626846Z",
     "shell.execute_reply": "2024-03-12T01:58:24.624501Z"
    },
    "papermill": {
     "duration": 49.81876,
     "end_time": "2024-03-12T01:58:24.630021",
     "exception": false,
     "start_time": "2024-03-12T01:57:34.811261",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:0\n",
      "fold:1\n",
      "fold:2\n",
      "fold:3\n",
      "fold:4\n",
      "fold:5\n",
      "fold:6\n",
      "fold:7\n",
      "fold:8\n",
      "fold:9\n",
      "mean_gini:0.2948356116504791\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "# 创建逻辑回归模型\n",
    "model = LinearRegression()\n",
    "\n",
    "#保存训练好的树模型,obj是保存的模型,path是需要保存的路径\n",
    "def pickle_dump(obj, path):\n",
    "    #打开指定的路径path,binary write(二进制写入)\n",
    "    with open(path, mode=\"wb\") as f:\n",
    "        #将obj对象保存到f,使用协议版本4进行序列化\n",
    "        dill.dump(obj, f, protocol=4)\n",
    "        \n",
    "X=train_feats[choose_cols].copy()\n",
    "y=train_feats[Config.TARGET_NAME].copy()\n",
    "test_X=test_feats[choose_cols].copy()#.drop([Config.TARGET_NAME],axis=1)\n",
    "oof_pred_pro=np.zeros((len(X)))\n",
    "test_pred_pro=np.zeros((Config.num_folds,len(test_X)))\n",
    "#10折交叉验证\n",
    "skf = StratifiedKFold(n_splits=Config.num_folds,random_state=Config.seed, shuffle=True)\n",
    "\n",
    "for fold, (train_index, valid_index) in (enumerate(skf.split(X, y.astype(str)))):\n",
    "    print(f\"fold:{fold}\")\n",
    "\n",
    "    X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n",
    "    y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n",
    "\n",
    "    model.fit(X_train,y_train)\n",
    "\n",
    "    oof_pred_pro[valid_index]=model.predict(X_valid)\n",
    "    #将数据分批次进行预测.\n",
    "    for idx in range(0,len(test_X),Config.batch_size):\n",
    "        test_pred_pro[fold][idx:idx+Config.batch_size]=model.predict(test_X[idx:idx+Config.batch_size]) \n",
    "    pickle_dump(model, f'/kaggle/working/linear_fold{fold}.model') #保存训练好的模型  \n",
    "\n",
    "gini=2*roc_auc_score(y.values,oof_pred_pro)-1\n",
    "print(f\"mean_gini:{gini}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732c667f",
   "metadata": {
    "papermill": {
     "duration": 0.00866,
     "end_time": "2024-03-12T01:58:24.647484",
     "exception": false,
     "start_time": "2024-03-12T01:58:24.638824",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dea65e6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-12T01:58:24.667466Z",
     "iopub.status.busy": "2024-03-12T01:58:24.667023Z",
     "iopub.status.idle": "2024-03-12T01:58:24.691638Z",
     "shell.execute_reply": "2024-03-12T01:58:24.690415Z"
    },
    "papermill": {
     "duration": 0.03841,
     "end_time": "2024-03-12T01:58:24.694496",
     "exception": false,
     "start_time": "2024-03-12T01:58:24.656086",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57543</td>\n",
       "      <td>0.028631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57549</td>\n",
       "      <td>0.091670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57551</td>\n",
       "      <td>0.011964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>57552</td>\n",
       "      <td>0.029371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57569</td>\n",
       "      <td>0.036168</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   case_id     score\n",
       "0    57543  0.028631\n",
       "1    57549  0.091670\n",
       "2    57551  0.011964\n",
       "3    57552  0.029371\n",
       "4    57569  0.036168"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds=test_pred_pro.mean(axis=0)\n",
    "submission=pd.read_csv(\"/kaggle/input/home-credit-credit-risk-model-stability/sample_submission.csv\")\n",
    "submission['score']=np.clip(np.nan_to_num(test_preds,nan=0.3),0,1)\n",
    "submission.to_csv(\"submission.csv\",index=None)\n",
    "submission.head()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 7921029,
     "sourceId": 50160,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30646,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 77.186803,
   "end_time": "2024-03-12T01:58:25.828448",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-03-12T01:57:08.641645",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
